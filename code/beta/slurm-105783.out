## SLURM PROLOG ###############################################################
##    Job ID : 105783
##  Job Name : dask-worker
##  Nodelist : node1850
##      CPUs : 1
##  Mem/Node : 96256 MB
## Directory : /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta
##   Started : Tue Jan 12 17:16:43 EST 2021
###############################################################################
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:35467'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:33519'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:42044'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:42439'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:44828'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:34738'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:36180'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:41604'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:43528'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:41071'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:40842'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:39531'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:41996'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:38015'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:42536'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:45765'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:41773'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:42316'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:43355'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:35915'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:44600'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:33257'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:43094'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:36895'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:35599'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:34975'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:35131'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:37630'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:34731'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:42481'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:45872'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:36037'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:40285'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:41828'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:43628'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:35363'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:39036'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:45654'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:44170'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:39373'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:33650'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.50:41759'
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:36073
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:36073
distributed.worker - INFO -          dashboard at:        172.20.214.50:43369
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-s307f00a
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:43666
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:43666
distributed.worker - INFO -          dashboard at:        172.20.214.50:44050
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-g51cpil3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:42265
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:42265
distributed.worker - INFO -          dashboard at:        172.20.214.50:37409
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4szue3gn
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:40157
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:40157
distributed.worker - INFO -          dashboard at:        172.20.214.50:39479
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-tjm08nw5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:41624
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:41624
distributed.worker - INFO -          dashboard at:        172.20.214.50:35775
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-297lx3_w
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:41052
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:41052
distributed.worker - INFO -          dashboard at:        172.20.214.50:37264
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-a3li37ee
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:34737
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:34737
distributed.worker - INFO -          dashboard at:        172.20.214.50:40114
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1pkfy75b
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:35350
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:35350
distributed.worker - INFO -          dashboard at:        172.20.214.50:41969
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-a3a175eu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:38328
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:38328
distributed.worker - INFO -          dashboard at:        172.20.214.50:44523
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-0rzi7qtd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:44440
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:40473
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:44440
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:40473
distributed.worker - INFO -          dashboard at:        172.20.214.50:38006
distributed.worker - INFO -          dashboard at:        172.20.214.50:45821
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-g283tyfd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-pv8aofjg
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:35351
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:35351
distributed.worker - INFO -          dashboard at:        172.20.214.50:44961
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-nzlne74w
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:42236
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:42236
distributed.worker - INFO -          dashboard at:        172.20.214.50:39345
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8_ddp242
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:36981
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:36981
distributed.worker - INFO -          dashboard at:        172.20.214.50:44052
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:33864
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:33864
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9136pnp8
distributed.worker - INFO -          dashboard at:        172.20.214.50:42274
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-qidu7f_2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:35356
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:35356
distributed.worker - INFO -          dashboard at:        172.20.214.50:32822
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-kgdai7xo
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:43702
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:43702
distributed.worker - INFO -          dashboard at:        172.20.214.50:33645
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:44855
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5mkggywl
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:44855
distributed.worker - INFO -          dashboard at:        172.20.214.50:46227
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ac99ps_k
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:36557
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:36557
distributed.worker - INFO -          dashboard at:        172.20.214.50:38458
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-k5i1ydj9
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:38299
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:38299
distributed.worker - INFO -          dashboard at:        172.20.214.50:39999
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-88_yil32
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:41416
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:41416
distributed.worker - INFO -          dashboard at:        172.20.214.50:35012
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-0wrtc5dv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:45108
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:45108
distributed.worker - INFO -          dashboard at:        172.20.214.50:35154
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-hftx11dt
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:44680
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:44680
distributed.worker - INFO -          dashboard at:        172.20.214.50:42424
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-71nmmzze
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:44834
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:44834
distributed.worker - INFO -          dashboard at:        172.20.214.50:33748
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-kiqz6h8u
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:46258
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:46258
distributed.worker - INFO -          dashboard at:        172.20.214.50:38240
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5wpg16lr
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:43249
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:43249
distributed.worker - INFO -          dashboard at:        172.20.214.50:36267
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4o_c3307
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:38619
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:38619
distributed.worker - INFO -          dashboard at:        172.20.214.50:43503
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8hrqjtr7
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:43286
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:43286
distributed.worker - INFO -          dashboard at:        172.20.214.50:43862
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-x13930x2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:46194
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:46194
distributed.worker - INFO -          dashboard at:        172.20.214.50:44477
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-gienj95g
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:41551
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:41551
distributed.worker - INFO -          dashboard at:        172.20.214.50:45019
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-evl2ig7o
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:39890
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:39890
distributed.worker - INFO -          dashboard at:        172.20.214.50:36409
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-xygrtfwn
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:36942
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:36942
distributed.worker - INFO -          dashboard at:        172.20.214.50:40999
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:42153
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2r2xz49b
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:42153
distributed.worker - INFO -          dashboard at:        172.20.214.50:34027
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-evdi_aza
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:41287
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:41287
distributed.worker - INFO -          dashboard at:        172.20.214.50:45786
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-phgl4r52
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:34615
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:34615
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:45645
distributed.worker - INFO -          dashboard at:        172.20.214.50:37088
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:45645
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO -          dashboard at:        172.20.214.50:34565
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-t9hkbtgn
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-jqg9lk_i
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:43006
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:43006
distributed.worker - INFO -          dashboard at:        172.20.214.50:42391
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-b3m31qte
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:41027
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:38359
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:41027
distributed.worker - INFO -          dashboard at:        172.20.214.50:39247
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:38359
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO -          dashboard at:        172.20.214.50:41552
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-koobbroj
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ys6i3iyy
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/users/ntolley/anaconda/sbi/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:37101
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:37101
distributed.worker - INFO -          dashboard at:        172.20.214.50:42993
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9za__26r
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:42972
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:42972
distributed.worker - INFO -          dashboard at:        172.20.214.50:33715
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9tjkhy91
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.50:39157
distributed.worker - INFO -          Listening to:  tcp://172.20.214.50:39157
distributed.worker - INFO -          dashboard at:        172.20.214.50:32958
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-akwqnbgk
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 20.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Event loop was unresponsive in Worker for 22.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.core - INFO - Event loop was unresponsive in Worker for 17.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 6.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 25.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 30.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 31.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 37.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 27.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 37.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 37.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 41.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 51.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 38.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Event loop was unresponsive in Worker for 43.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Event loop was unresponsive in Worker for 46.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 37.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 50.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 35.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Event loop was unresponsive in Worker for 26.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 58.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Comm closed
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Event loop was unresponsive in Worker for 41.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 54.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Comm closed
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.212.34:43077
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Event loop was unresponsive in Worker for 76.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 38.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 43.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 20.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 22.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 28.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 28.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd08059f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f14ee44f830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 24.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:40157
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:43702
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:44680
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:41416
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:44440
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:43666
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:36981
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:38328
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:35356
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:44855
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:43249
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:36942
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:44834
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:39890
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:42236
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:43286
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:38299
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:35350
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:42265
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:45645
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:40473
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:41551
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:41287
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:46194
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:42153
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:46258
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:43006
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-g51cpil3' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-g51cpil3'
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4szue3gn' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4szue3gn'
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:34737
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:34615
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:38359
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:41027
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:39157
distributed.nanny - INFO - Worker closed
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:33864
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.worker - WARNING - Heartbeat to scheduler failed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce723c0290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 12.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 35.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 15.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 33.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f520194b7a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Comm closed
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:43528'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:35467'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:43628'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:34731'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:35599'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:43094'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:44828'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:44600'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:36895'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:36037'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:41773'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:37630'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:42316'
distributed.core - INFO - Event loop was unresponsive in Worker for 44.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:34975'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:42481'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:35915'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:45872'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:42044'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:39036'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:42536'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:41071'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:45654'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:42439'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:33257'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:33650'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:43355'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:38015'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:39373'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:41759'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:35363'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:44170'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:39531'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:40842'
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:37101
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:41624
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:45108
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 33.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 36.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:36180'
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 29.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 36.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:33519'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:35131'
distributed.core - INFO - Event loop was unresponsive in Worker for 24.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 20.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Comm closed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4389f55560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f5b74b95560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 15.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Comm closed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8185834d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 9.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:38619
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7efe9baff560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 15.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Comm closed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8b8acbe560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 16.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:42972
distributed.worker - INFO - Comm closed
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:35351
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:36557
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-k5i1ydj9' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-k5i1ydj9'
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.core - INFO - Event loop was unresponsive in Worker for 14.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Comm closed
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:40285'
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:36073
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:45765'
distributed.nanny - INFO - Worker closed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4389f55560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:34738'
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Fatal Python error: This thread state must be current when releasing

Current thread 0x00007fdd2f776700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 58 in simulation_time
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 71 in _simulate_single_trial
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 35 in _clone_and_simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in <genexpr>
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/dipole.py", line 72 in simulate_dipole
  File "<ipython-input-3-2a3cf4ddb92c>", line 18 in __call__
  File "<ipython-input-3-2a3cf4ddb92c>", line 28 in run_simulator
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3318 in execute_task
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3425 in apply_function
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/_concurrent_futures_thread.py", line 65 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 55 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fdd6e808700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fd7cb376700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fd7effff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/selectors.py", line 415 in select
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 921 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 414 in _poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 257 in poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/queues.py", line 104 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/nanny.py", line 748 in watch_stop_q
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fd813fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 95 in updatecache
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 47 in getlines
  File "/users/ntolley/.local/lib/python3.7/site-packages/torch/_fx/graph_module.py", line 27 in patched_getline
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 16 in getline
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 67 in info_frame
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 114 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 103 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 103 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 268 in _watch
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fd836ddd700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 379 in _recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 407 in _recv_bytes
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 250 in recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/process.py", line 143 in monitor_parent
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fdd7a3f7740 (most recent call first):
distributed.nanny - INFO - Worker process 146602 was killed by signal 6
distributed.worker - INFO - Stopping worker at tcp://172.20.214.50:41052
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.core - INFO - Event loop was unresponsive in Worker for 14.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:41828'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.50:41996'
distributed.core - INFO - Event loop was unresponsive in Worker for 17.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 7.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.50:41604 after 10 s
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f4234f2a710>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.212.34:43077 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.50:41604 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f3d93310950>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.50:41604 after 10 s')>)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f4234f2a710>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.212.34:43077 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.50:41604 after 10 s
distributed.worker - INFO - Comm closed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3d74880560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
slurmstepd: error: *** JOB 105783 ON node1850 CANCELLED AT 2021-01-12T17:52:30 ***
