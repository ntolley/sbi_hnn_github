## SLURM PROLOG ###############################################################
##    Job ID : 102026
##  Job Name : dask-worker
##  Nodelist : node1821
##      CPUs : 1
##  Mem/Node : 96256 MB
## Directory : /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta
##   Started : Tue Jan 12 08:29:47 EST 2021
###############################################################################
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:43691'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:33810'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:46535'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:35766'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:45432'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:39963'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:34798'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:35587'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:43049'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:35671'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:33778'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:39381'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:36881'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:44046'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:44256'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:33906'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:46249'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:42761'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:32952'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:46679'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:41062'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:36224'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:44279'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:40632'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:46284'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:46846'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:43012'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:37844'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:34782'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:46074'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:40315'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:35192'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:39914'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:40588'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:34676'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:40547'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:44584'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:41831'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:45965'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:39201'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:35992'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.21:45349'
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-zlet4ylf', purging
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-zlet4ylf' (failed in <built-in function rmdir>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-zlet4ylf'
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-sdxcecxf', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1xjvumx4', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-75x2ddpx', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-haoety_k', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ymcv7im6', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1fbevcqb', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5tnftsf2', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-m9zjskzf', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-vo43bl_g', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8b3o62jt', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-j1tqh2bi', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9d_e6b3q', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-cnir2ngs', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-rjojb40d', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-u7mh4otz', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-mcq9wp0w', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-c4v9250g', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-rs2gj847', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ojrxol50', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ifziyucb', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-237crtnn', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-izxzddmv', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9xt_jh2b', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-p7loz3ds', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-e5_34zpg', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-e23fzl3p', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ya9fecr3', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-lbvvvqkg', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-n1ojkosh', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4mir63ss', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-63pdnn11', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-7c62aguh', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-s78m0uhi', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-eiqq28x9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-kovkykc4', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-x12bmefw', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ctr702xa', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9grhamh7', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-i6kn509w', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fudm4wdr', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-xvlve65l', purging
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:38971
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:38971
distributed.worker - INFO -          dashboard at:        172.20.214.21:43617
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:35894
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:35894
distributed.worker - INFO -          dashboard at:        172.20.214.21:33407
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-yqigr20r
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4gi3rmrm
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:42500
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:42500
distributed.worker - INFO -          dashboard at:        172.20.214.21:41827
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-cgw9p5lu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:45615
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:45615
distributed.worker - INFO -          dashboard at:        172.20.214.21:42523
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-w30ns3nm
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:43607
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:43607
distributed.worker - INFO -          dashboard at:        172.20.214.21:34456
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-uhrrya7p
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:45957
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:45957
distributed.worker - INFO -          dashboard at:        172.20.214.21:36594
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5hafg8h0
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:35733
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:35733
distributed.worker - INFO -          dashboard at:        172.20.214.21:43439
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-7dkjz51a
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:44886
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:44886
distributed.worker - INFO -          dashboard at:        172.20.214.21:41521
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ugjkpkaa
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:36404
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:36404
distributed.worker - INFO -          dashboard at:        172.20.214.21:33807
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8prmpd_r
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:35926
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:41517
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:41517
distributed.worker - INFO -          dashboard at:        172.20.214.21:36625
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-yxibj483
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:35926
distributed.worker - INFO -          dashboard at:        172.20.214.21:43277
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-wrqu8653
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:42001
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:42001
distributed.worker - INFO -          dashboard at:        172.20.214.21:38102
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-11y7bzvg
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:40190
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:40190
distributed.worker - INFO -          dashboard at:        172.20.214.21:43181
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-b9rw2rpp
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:34585
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:34585
distributed.worker - INFO -          dashboard at:        172.20.214.21:36907
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-kmxecys6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:36745
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:36745
distributed.worker - INFO -          dashboard at:        172.20.214.21:44659
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-f3zhniz9
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:46645
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:46645
distributed.worker - INFO -          dashboard at:        172.20.214.21:34187
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-_9qlora2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:42962
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:42962
distributed.worker - INFO -          dashboard at:        172.20.214.21:46418
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-mccvh09i
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:37448
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:37448
distributed.worker - INFO -          dashboard at:        172.20.214.21:41250
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-k7h9d_tg
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:43560
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:43560
distributed.worker - INFO -          dashboard at:        172.20.214.21:43051
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5gvutg4a
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:42144
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:42144
distributed.worker - INFO -          dashboard at:        172.20.214.21:39767
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-0iq92s8z
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:40362
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:40362
distributed.worker - INFO -          dashboard at:        172.20.214.21:38720
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-6e450_vg
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:33518
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:33518
distributed.worker - INFO -          dashboard at:        172.20.214.21:40283
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ndvuschg
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:37554
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:37554
distributed.worker - INFO -          dashboard at:        172.20.214.21:36364
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1k2nj0pw
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:46422
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:46422
distributed.worker - INFO -          dashboard at:        172.20.214.21:44373
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-z06go9et
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:37750
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:37750
distributed.worker - INFO -          dashboard at:        172.20.214.21:41094
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1hkun7e0
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:39062
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:39062
distributed.worker - INFO -          dashboard at:        172.20.214.21:42956
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ao7h4rwl
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:34532
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:34532
distributed.worker - INFO -          dashboard at:        172.20.214.21:44715
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-lz2liogo
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:46149
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:46149
distributed.worker - INFO -          dashboard at:        172.20.214.21:41791
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ha46qnr3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:39520
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:39520
distributed.worker - INFO -          dashboard at:        172.20.214.21:35060
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2bcx4ni3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:45871
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:45871
distributed.worker - INFO -          dashboard at:        172.20.214.21:45192
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:42252
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-wfc4bzs3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:42252
distributed.worker - INFO -          dashboard at:        172.20.214.21:41991
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-tgy8q_2j
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:32946
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:32946
distributed.worker - INFO -          dashboard at:        172.20.214.21:43431
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-md1lnit8
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:38391
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:38391
distributed.worker - INFO -          dashboard at:        172.20.214.21:39089
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-25vk_cg8
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:34019
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:34019
distributed.worker - INFO -          dashboard at:        172.20.214.21:35180
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2ju_cwmq
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:46458
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:46458
distributed.worker - INFO -          dashboard at:        172.20.214.21:43415
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-v8zxii_4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:46106
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:46106
distributed.worker - INFO -          dashboard at:        172.20.214.21:38050
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-wgco3gev
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:34845
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:34845
distributed.worker - INFO -          dashboard at:        172.20.214.21:45520
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-gmobr1gb
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:42544
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:42544
distributed.worker - INFO -          dashboard at:        172.20.214.21:46591
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-3u2zod6f
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:36833
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:36833
distributed.worker - INFO -          dashboard at:        172.20.214.21:41637
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-6p18ue_e
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:39515
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:39515
distributed.worker - INFO -          dashboard at:        172.20.214.21:34546
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-t8tyuxzb
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:35076
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:35076
distributed.worker - INFO -          dashboard at:        172.20.214.21:42814
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-lzmhs1qn
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.21:37583
distributed.worker - INFO -          Listening to:  tcp://172.20.214.21:37583
distributed.worker - INFO -          dashboard at:        172.20.214.21:35639
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-lzuz13uv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:39430
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 22.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 27.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 23.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 27.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 27.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 33.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 30.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 30.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 23.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 5.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 4.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 12.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 9.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 4.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 7.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 47.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 21.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 45.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 3.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 48.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 23.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 54.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 7.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 57.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 56.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 9.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 17.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 37.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 24.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 57.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 23.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 56.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 33.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 50.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 51.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 70.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 70.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 87.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 53.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 57.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 38.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 23.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 61.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 12.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 66.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 67.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 17.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 24.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 33.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 25.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 24.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 46.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 62.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 38.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 42.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 25.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 51.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 53.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 52.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 8.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 51.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 9.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 24.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 24.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 17.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 28.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 35.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 65.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 69.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 24.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 65.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 17.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 23.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 32.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 28.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 17.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 27.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 33.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 37.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 30.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 33.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 53.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 38.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 35.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 41.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 49.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 41.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 58.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 71.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 43.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 63.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 39.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 37.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 50.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 22.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 41.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 37.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 27.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 30.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 17.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 41.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 54.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 41.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 44.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 29.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 56.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 28.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 54.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 73.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 23.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 23.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 43.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 25.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 42.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 29.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 24.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 28.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 17.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 54.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 17.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 57.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 44.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 25.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 25.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 46.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 46.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 59.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 22.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 49.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 23.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 17.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 20.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 23.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 37.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 37.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 22.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 32.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 41.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 32.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 32.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 47.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 47.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 48.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 53.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 41.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 39.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 37.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 50.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 63.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Comm closed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 4.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 64.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 7.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 5.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 4.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 9.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 22.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 12.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 12.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 12.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 13.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 12.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 9.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 70.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 5.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 14.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:35733
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:42252
distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:46645
distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 63.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:34532
distributed.core - INFO - Event loop was unresponsive in Worker for 5.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 11.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:41517
distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:40190
distributed.worker - INFO - Comm closed
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:35926
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 41.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:46422
distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:40362
distributed.core - INFO - Event loop was unresponsive in Worker for 10.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:42962
distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2e876c4b00>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:44886
distributed.core - INFO - Event loop was unresponsive in Worker for 11.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:39520
distributed.core - INFO - Event loop was unresponsive in Worker for 13.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:38391
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ff19cbea8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:34798'
distributed.core - INFO - Event loop was unresponsive in Worker for 9.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 83.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f76a5c69560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 19.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 35.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:35894
distributed.core - INFO - Event loop was unresponsive in Worker for 12.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa017f2f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:39062
distributed.core - INFO - Event loop was unresponsive in Worker for 14.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:33518
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 9.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 7.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:45871
distributed.core - INFO - Event loop was unresponsive in Worker for 12.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - WARNING - Heartbeat to scheduler failed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3c572b9680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:39515
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 9.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:46679 after 10 s
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:46679 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7fd8caca9a10>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:46679 after 10 s')>)
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:46679 after 10 s
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 7.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 45.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f7df846b4d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:34585
distributed.core - INFO - Event loop was unresponsive in Worker for 33.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:46149
distributed.core - INFO - Event loop was unresponsive in Worker for 22.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:37448
distributed.core - INFO - Event loop was unresponsive in Worker for 24.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 12.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:37554
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 14.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Comm closed
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.core - INFO - Event loop was unresponsive in Worker for 10.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:34019
distributed.core - INFO - Event loop was unresponsive in Worker for 32.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 24.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:39381 after 10 s
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:39381 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f4bca8bfc50>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:39381 after 10 s')>)
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:39381 after 10 s
distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
Fatal Python error: This thread state must be current when releasing

Current thread 0x00007f67210cd700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 58 in simulation_time
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 71 in _simulate_single_trial
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 35 in _clone_and_simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in <genexpr>
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/dipole.py", line 72 in simulate_dipole
  File "<ipython-input-3-2a3cf4ddb92c>", line 18 in __call__
  File "<ipython-input-3-2a3cf4ddb92c>", line 28 in run_simulator
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3318 in execute_task
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3425 in apply_function
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/_concurrent_futures_thread.py", line 65 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 55 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f6797012700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f61f3cff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f6217fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/selectors.py", line 415 in select
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 921 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 414 in _poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 257 in poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/queues.py", line 104 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/nanny.py", line 748 in watch_stop_q
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f623bfff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/tokenize.py", line 447 in open
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 136 in updatecache
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 47 in getlines
  File "/users/ntolley/.local/lib/python3.7/site-packages/torch/_fx/graph_module.py", line 27 in patched_getline
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 16 in getline
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 67 in info_frame
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 114 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 103 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 268 in _watch
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f625f627700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 379 in _recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 407 in _recv_bytes
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 250 in recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/process.py", line 143 in monitor_parent
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f67a2c41740 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/_weakrefset.py", line 38 in _remove
distributed.nanny - INFO - Worker process 139546 was killed by signal 6
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f067cadb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 8.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 43.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 41.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:33810'
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.utils - ERROR - Timed out during handshake while connecting to tcp://172.20.214.21:44256 after 10 s
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 320, in connect
    await asyncio.wait_for(comm.write(local_info), time_left())
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 423, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 326, in connect
    ) from exc
OSError: Timed out during handshake while connecting to tcp://172.20.214.21:44256 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f1c0210cf50>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out during handshake while connecting to tcp://172.20.214.21:44256 after 10 s')>)
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 320, in connect
    await asyncio.wait_for(comm.write(local_info), time_left())
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 423, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 326, in connect
    ) from exc
OSError: Timed out during handshake while connecting to tcp://172.20.214.21:44256 after 10 s
distributed.core - INFO - Event loop was unresponsive in Worker for 19.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 37.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 12.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:42144
distributed.core - INFO - Event loop was unresponsive in Worker for 21.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils - ERROR - Timed out during handshake while connecting to tcp://172.20.214.21:43049 after 10 s
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f1d49c45490>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 320, in connect
    await asyncio.wait_for(comm.write(local_info), time_left())
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 423, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 326, in connect
    ) from exc
OSError: Timed out during handshake while connecting to tcp://172.20.214.21:43049 after 10 s
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:46106
distributed.core - INFO - Event loop was unresponsive in Worker for 9.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:38971
distributed.core - INFO - Event loop was unresponsive in Worker for 68.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:40315'
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 43.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:37750
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:46074 after 10 s
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7fa7da2a4b90>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:46074 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7fa337fd2d10>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:46074 after 10 s')>)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7fa7da2a4b90>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:46074 after 10 s
distributed.core - INFO - Event loop was unresponsive in Worker for 11.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f18a6eacd50>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out during handshake while connecting to tcp://172.20.214.21:43049 after 10 s')>)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f1d49c45490>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 320, in connect
    await asyncio.wait_for(comm.write(local_info), time_left())
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 423, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 326, in connect
    ) from exc
OSError: Timed out during handshake while connecting to tcp://172.20.214.21:43049 after 10 s
distributed.core - INFO - Event loop was unresponsive in Worker for 21.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Fatal Python error: This thread state must be current when releasing

Current thread 0x00007f449bd9f700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 58 in simulation_time
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 71 in _simulate_single_trial
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 35 in _clone_and_simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in <genexpr>
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/dipole.py", line 72 in simulate_dipole
  File "<ipython-input-3-2a3cf4ddb92c>", line 18 in __call__
  File "<ipython-input-3-2a3cf4ddb92c>", line 28 in run_simulator
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3318 in execute_task
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3425 in apply_function
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/_concurrent_futures_thread.py", line 65 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 55 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f4511da3700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f3f6bfff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f3f8ffff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/selectors.py", line 415 in select
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 921 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 414 in _poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 257 in poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/queues.py", line 104 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/nanny.py", line 748 in watch_stop_q
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f3fb3fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 269 in _watch
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f3fda3b8700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 379 in _recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 407 in _recv_bytes
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 250 in recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/process.py", line 143 in monitor_parent
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f451d9d2740 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/_weakrefset.py", line 38 in _remove
distributed.nanny - INFO - Worker process 139477 was killed by signal 6
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f054525e7a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 14.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:37583
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Fatal Python error: This thread state must be current when releasing

Current thread 0x00007fbe27b75700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 58 in simulation_time
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 71 in _simulate_single_trial
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 35 in _clone_and_simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in <genexpr>
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/dipole.py", line 72 in simulate_dipole
  File "<ipython-input-3-2a3cf4ddb92c>", line 18 in __call__
  File "<ipython-input-3-2a3cf4ddb92c>", line 28 in run_simulator
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3318 in execute_task
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3425 in apply_function
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/_concurrent_futures_thread.py", line 65 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 55 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fbe9da5c700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fb8f7fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fb91bfff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/selectors.py", line 415 in select
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 921 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 414 in _poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 257 in poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/queues.py", line 104 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/nanny.py", line 748 in watch_stop_q
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fb93ffff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 269 in _watch
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fb966071700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 379 in _recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 407 in _recv_bytes
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 250 in recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/process.py", line 143 in monitor_parent
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fbea968b740 (most recent call first):
distributed.nanny - INFO - Worker process 139548 was killed by signal 6
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Fatal Python error: This thread state must be current when releasing

Current thread 0x00007ff6b3ddd700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 58 in simulation_time
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 71 in _simulate_single_trial
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 35 in _clone_and_simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in <genexpr>
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/dipole.py", line 72 in simulate_dipole
  File "<ipython-input-3-2a3cf4ddb92c>", line 18 in __call__
  File "<ipython-input-3-2a3cf4ddb92c>", line 28 in run_simulator
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3318 in execute_task
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3425 in apply_function
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/_concurrent_futures_thread.py", line 65 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 55 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007ff6f2def700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007ff14fbff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007ff173fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/selectors.py", line 415 in select
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 921 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 414 in _poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 257 in poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/queues.py", line 104 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/nanny.py", line 748 in watch_stop_q
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007ff197fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 269 in _watch
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007ff1bb444700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 379 in _recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 407 in _recv_bytes
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 250 in recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/process.py", line 143 in monitor_parent
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007ff6fea5e740 (most recent call first):
distributed.nanny - INFO - Worker process 139748 was killed by signal 6
distributed.nanny - INFO - Worker closed
distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Fatal Python error: This thread state must be current when releasing

Current thread 0x00007f4137623700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 58 in simulation_time
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 71 in _simulate_single_trial
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 35 in _clone_and_simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in <genexpr>
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/dipole.py", line 72 in simulate_dipole
  File "<ipython-input-3-2a3cf4ddb92c>", line 18 in __call__
  File "<ipython-input-3-2a3cf4ddb92c>", line 28 in run_simulator
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3318 in execute_task
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3425 in apply_function
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/_concurrent_futures_thread.py", line 65 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 55 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f41ad4b8700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f3c07fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f3c2bfff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/selectors.py", line 415 in select
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 921 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 414 in _poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 257 in poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/queues.py", line 104 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/nanny.py", line 748 in watch_stop_q
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f3c4ffff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/tokenize.py", line 447 in open
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 136 in updatecache
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 47 in getlines
  File "/users/ntolley/.local/lib/python3.7/site-packages/torch/_fx/graph_module.py", line 27 in patched_getline
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 16 in getline
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 67 in info_frame
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 114 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 103 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 268 in _watch
  File "/users/ntolley/anaconda/sbi/ldistributed.core - INFO - Event loop was unresponsive in Worker for 26.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
ib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f3c75b0d700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 379 in _recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 407 in _recv_bytes
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 250 in recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/process.py", line 143 in monitor_parent
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f41b9127740 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/_weakrefset.py", line 38 in _remove
distributed.nanny - INFO - Worker process 139468 was killed by signal 6
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Fatal Python error: This thread state must be current when releasing

Current thread 0x00007fb680fcd700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 58 in simulation_time
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 71 in _simulate_single_trial
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 35 in _clone_and_simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in <genexpr>
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/dipole.py", line 72 in simulate_dipole
  File "<ipython-input-3-2a3cf4ddb92c>", line 18 in __call__
  File "<ipython-input-3-2a3cf4ddb92c>", line 28 in run_simulator
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3318 in execute_task
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3425 in apply_function
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/_concurrent_futures_thread.py", line 65 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 55 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fb6f6ee5700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fb15383f700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fb177fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/selectors.py", line 415 in select
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 921 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 414 in _poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 257 in poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/queues.py", line 104 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/nanny.py", line 748 in watch_stop_q
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fb19bfff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 269 in _watch
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fb1bf53a700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 379 in _recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 407 in _recv_bytes
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 250 in recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/process.py", line 143 in monitor_parent
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fb702b54740 (most recent call first):
distributed.nanny - INFO - Worker process 139501 was killed by signal 6
distributed.core - INFO - Event loop was unresponsive in Worker for 9.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 56.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.core - INFO - Event loop was unresponsive in Worker for 4.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 30.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:35587'
distributed.core - INFO - Event loop was unresponsive in Worker for 31.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:35192'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:34676'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:45432'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:33906'
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
distributed.core - INFO - Event loop was unresponsive in Worker for 98.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:32952 after 10 s
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:32952 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7fee456eba10>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:32952 after 10 s')>)
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:32952 after 10 s
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
Simulation time: 380.0 ms...
Fatal Python error: This thread state must be current when releasing

Current thread 0x00007fabbcfcd700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 58 in simulation_time
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 71 in _simulate_single_trial
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 35 in _clone_and_simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in <genexpr>
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/dipole.py", line 72 in simulate_dipole
  File "<ipython-input-3-2a3cf4ddb92c>", line 18 in __call__
  File "<ipython-input-3-2a3cf4ddb92c>", line 28 in run_simulator
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3318 in execute_task
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3425 in apply_function
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/_concurrent_futures_thread.py", line 65 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 55 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fac32f12700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fa68faff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fa6b3fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/selectors.py", line 415 in select
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 921 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 414 in _poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 257 in poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/queues.py", line 104 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/nanny.py", line 748 in watch_stop_q
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fa6d7fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/tokenize.py", line 447 in open
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 136 in updatecache
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 47 in getlines
  File "/users/ntolley/.local/lib/python3.7/site-packages/torch/_fx/graph_module.py", line 27 in patched_getline
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 16 in getline
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 67 in info_frame
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 114 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 103 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 103 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 268 in _watch
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fa6fb527700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 379 in _recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 407 in _recv_bytes
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 250 in recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/process.py", line 143 in monitor_parent
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fac3eb41740 (most recent call first):
distributed.core - INFO - Event loop was unresponsive in Worker for 10.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - INFO - Worker process 139525 was killed by signal 6
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 53.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 25.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Comm closed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 19.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:43691 after 10 s
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7fbbb609f110>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:43691 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7fb7132beb10>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:43691 after 10 s')>)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7fbbb609f110>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:43691 after 10 s
distributed.worker - INFO - Comm closed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 16.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:35671 after 10 s
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:35671 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f11ada05550>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:35671 after 10 s')>)
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:35671 after 10 s
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 96.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 89.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Comm closed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 16.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:40588 after 10 s
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:40588 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f3656836b90>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:40588 after 10 s')>)
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:40588 after 10 s
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 91.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 75.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f336fe314d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:45957
distributed.worker - INFO - Comm closed
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.core - INFO - Event loop was unresponsive in Worker for 43.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:46284 after 10 s
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:46284 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7fa4bed06890>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:46284 after 10 s')>)
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:46284 after 10 s
distributed.worker - INFO - Comm closed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 10.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 88.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed
distributed.worker - INFO - Comm closed
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:40632'
distributed.core - INFO - Event loop was unresponsive in Worker for 108.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 7.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f6cbcc2d560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 18.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:44584 after 10 s
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f3ea27a04d0>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:44584 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f3a00abab10>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:44584 after 10 s')>)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f3ea27a04d0>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:44584 after 10 s
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 27.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 58.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2e876c4b00>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:43607
distributed.worker - INFO - Comm closed
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.core - INFO - Event loop was unresponsive in Worker for 28.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 6.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 50.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f7df846b4d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:36833
distributed.worker - INFO - Comm closed
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:44279 after 10 s
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7fd4e18c5950>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:44279 after 10 s
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:35076
distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 81.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 24.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f067cadb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:42001
distributed.worker - INFO - Comm closed
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.core - INFO - Event loop was unresponsive in Worker for 98.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 3.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:33778'
distributed.core - INFO - Event loop was unresponsive in Worker for 32.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 42.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 51.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:46535'
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 55.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:46249 after 10 s
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:46249 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f07f06a1c90>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:46249 after 10 s')>)
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:46249 after 10 s
distributed.worker - INFO - Comm closed
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:40547'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:36881'
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Comm closed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 38.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.utils - ERROR - Timed out during handshake while connecting to tcp://172.20.214.21:39914 after 10 s
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 320, in connect
    await asyncio.wait_for(comm.write(local_info), time_left())
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 423, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 326, in connect
    ) from exc
OSError: Timed out during handshake while connecting to tcp://172.20.214.21:39914 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f79f4c2d950>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out during handshake while connecting to tcp://172.20.214.21:39914 after 10 s')>)
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 320, in connect
    await asyncio.wait_for(comm.write(local_info), time_left())
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 423, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 326, in connect
    ) from exc
OSError: Timed out during handshake while connecting to tcp://172.20.214.21:39914 after 10 s
distributed.worker - INFO - Comm closed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 33.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.worker - INFO - Comm closed
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.utils - ERROR - Timed out during handshake while connecting to tcp://172.20.214.21:39201 after 10 s
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 320, in connect
    await asyncio.wait_for(comm.write(local_info), time_left())
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 423, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 326, in connect
    ) from exc
OSError: Timed out during handshake while connecting to tcp://172.20.214.21:39201 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7fb4b4bcf150>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out during handshake while connecting to tcp://172.20.214.21:39201 after 10 s')>)
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 320, in connect
    await asyncio.wait_for(comm.write(local_info), time_left())
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 423, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 326, in connect
    ) from exc
OSError: Timed out during handshake while connecting to tcp://172.20.214.21:39201 after 10 s
distributed.core - INFO - Event loop was unresponsive in Worker for 31.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 13.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Comm closed
distributed.utils - ERROR - Timed out during handshake while connecting to tcp://172.20.214.21:39963 after 10 s
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f50a00a4d90>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 320, in connect
    await asyncio.wait_for(comm.write(local_info), time_left())
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 423, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 326, in connect
    ) from exc
OSError: Timed out during handshake while connecting to tcp://172.20.214.21:39963 after 10 s
distributed.core - INFO - Event loop was unresponsive in Worker for 13.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f4bfe74cc90>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out during handshake while connecting to tcp://172.20.214.21:39963 after 10 s')>)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f50a00a4d90>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 320, in connect
    await asyncio.wait_for(comm.write(local_info), time_left())
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 423, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 326, in connect
    ) from exc
OSError: Timed out during handshake while connecting to tcp://172.20.214.21:39963 after 10 s
distributed.worker - INFO - Comm closed
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Fatal Python error: This thread state must be current when releasing

Current thread 0x00007f7194d8e700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 58 in simulation_time
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 71 in _simulate_single_trial
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 35 in _clone_and_simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in <genexpr>
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/dipole.py", line 72 in simulate_dipole
  File "<ipython-input-3-2a3cf4ddb92c>", line 18 in __call__
  File "<ipython-input-3-2a3cf4ddb92c>", line 28 in run_simulator
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3318 in execute_task
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3425 in apply_function
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/_concurrent_futures_thread.py", line 65 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 55 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f7212e72700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f6c6f97f700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f6c93fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/selectors.py", line 415 in select
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 921 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 414 in _poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 257 in poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/queues.py", line 104 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/nanny.py", line 748 in watch_stop_q
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f6cb7fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/tokenize.py", line 447 in open
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 136 in updatecache
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 47 in getlines
  File "/users/ntolley/.local/lib/python3.7/site-packages/torch/_fx/graph_module.py", line 27 in patched_getline
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 16 in getline
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 67 in info_frame
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 114 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 103 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 103 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 103 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 103 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 103 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 268 in _watch
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f6cdb487700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 379 in _recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 407 in _recv_bytes
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 250 in recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/process.py", line 143 in monitor_parent
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f721eaa1740 (most recent call first):
distributed.nanny - INFO - Worker process 139533 was killed by signal 6
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7fcfaa0fed50>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:44279 after 10 s')>)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7fd4e18c5950>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:44279 after 10 s
distributed.core - INFO - Event loop was unresponsive in Worker for 66.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Comm closed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 29.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Comm closed
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:36224'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:41062'
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:32946
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:34782'
distributed.core - INFO - Event loop was unresponsive in Worker for 30.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.21:43012'
distributed.core - INFO - Event loop was unresponsive in Worker for 35.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:34845
distributed.core - INFO - Event loop was unresponsive in Worker for 39.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 39.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:43560
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:45615
distributed.core - INFO - Event loop was unresponsive in Worker for 36.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:46458
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:36745
distributed.core - INFO - Event loop was unresponsive in Worker for 41.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:42544
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:36404
distributed.core - INFO - Event loop was unresponsive in Worker for 39.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 44.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.214.21:42500
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 34.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 23.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 30.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:41831 after 10 s
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7ff137c06d10>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:41831 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7fec994349d0>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:41831 after 10 s')>)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7ff137c06d10>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:41831 after 10 s
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 36.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 34.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 9.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:42761 after 10 s
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7efcef25f990>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:42761 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7ef7b7868b10>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:42761 after 10 s')>)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7efcef25f990>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:42761 after 10 s
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 34.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 38.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:37844 after 10 s
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f1bafc9eb10>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:37844 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f1c1b6b8690>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:37844 after 10 s')>)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f1bafc9eb10>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:37844 after 10 s
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 43.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:45965 after 10 s
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f8c25b30fd0>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:45965 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f87835beb10>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:45965 after 10 s')>)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f8c25b30fd0>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:45965 after 10 s
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 12.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:45349 after 10 s
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7fd39ab2f550>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:45349 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7fce63143c50>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:45349 after 10 s')>)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7fd39ab2f550>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:45349 after 10 s
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 15.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:44046 after 10 s
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7fd8497ee810>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:44046 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7fd387854fd0>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:44046 after 10 s')>)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7fd8497ee810>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:44046 after 10 s
distributed.worker - INFO - Comm closed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 5.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:46846 after 10 s
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f30e15dded0>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:46846 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f30e4736c10>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:46846 after 10 s')>)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f30e15dded0>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:46846 after 10 s
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 8.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:35766 after 10 s
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7fe8ae7d1710>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:35766 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7fe3781450d0>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:35766 after 10 s')>)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7fe8ae7d1710>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:35766 after 10 s
distributed.worker - INFO - Comm closed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.core - INFO - Event loop was unresponsive in Worker for 8.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.comm.tcp - INFO - Connection closed before handshake completed
distributed.utils - ERROR - Timed out trying to connect to tcp://172.20.214.21:35992 after 10 s
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f9d438ef450>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils.py", line 655, in log_errors
    yield
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:35992 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f9866610a50>>, <Task finished coro=<Worker.heartbeat() done, defined at /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py:929> exception=OSError('Timed out trying to connect to tcp://172.20.214.21:35992 after 10 s')>)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 442, in wait_for
    return fut.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 374, in connect
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7f9d438ef450>: ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 939, in heartbeat
    metrics=await self.get_metrics(),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 389, in retry_operation
    operation=operation,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.209.24:39430 after 10 s

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 288, in connect
    timeout=min(intermediate_cap, time_left()),
  File "/users/ntolley/anaconda/sbi/lib/python3.7/asyncio/tasks.py", line 449, in wait_for
    raise futures.TimeoutError()
concurrent.futures._base.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 968, in heartbeat
    await self.close(report=False)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1187, in close
    await r.close_gracefully()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 875, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/core.py", line 1030, in connect
    **self.connection_args,
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/core.py", line 310, in connect
    ) from active_exception
OSError: Timed out trying to connect to tcp://172.20.214.21:35992 after 10 s
distributed.worker - INFO - Comm closed
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fe35855a560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f118eb30560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd368ff54d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f188864e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7ef799009560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1be3843560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bdfb2f8c0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f1bfce634d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fcf8b66e560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fd8ac449560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb6f49fd560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f2b8b375560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa4a04a7560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fee26e8b560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f79d6364290>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f4bac060560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f3637f43830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fa3196f94d0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fec7a8157a0>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f07d1b9e830>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f39e2264320>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fce448e5560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7fb496370680>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f8764d5f560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x7f98462cb560>
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 697, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
