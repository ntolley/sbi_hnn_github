distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:45763'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:43137'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:33337'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:39911'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:33131'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:34973'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:34543'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:33851'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:43415'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:40121'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:40299'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:46191'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:41873'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:36197'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:40503'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:37941'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:35413'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:41153'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:42119'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:34877'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:42067'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:39525'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:42859'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:33153'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:35907'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:42071'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:36171'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:42285'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:46693'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:40663'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:40373'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:34641'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:41943'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:43201'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:33841'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:37479'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:40189'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:35689'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:39207'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:46271'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:41593'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:36461'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:45097'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:42011'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:34341'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:38983'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:40221'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:43765'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:43935'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:36951'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:46231'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:40823'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:33059'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:42751'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:39919'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:35747'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:35173'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:39983'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:44345'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:41327'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:46199'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:36973'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:38565'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:37979'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:40387'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:43645'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:35153'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:42843'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:43273'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:34805'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:41705'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:46609'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:33673'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:36737'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:34797'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:33389'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:33019'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:46281'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:41357'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:46529'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:44671'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:40235'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:33689'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:40805'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:36845'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:34463'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:38629'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:33849'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:35787'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:43089'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:33697'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:35755'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:37153'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:36713'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:39567'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:35329'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:34039'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:46675'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:46203'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.118:45329'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:45369
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:45369
distributed.worker - INFO -          dashboard at:      198.202.103.118:41631
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-f5w_a4eq
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:38767
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:38767
distributed.worker - INFO -          dashboard at:      198.202.103.118:46589
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ztfgk7ut
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:34355
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:34355
distributed.worker - INFO -          dashboard at:      198.202.103.118:37625
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-duv5zxz2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:43413
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:43413
distributed.worker - INFO -          dashboard at:      198.202.103.118:44159
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fbr0k2nx
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:42397
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:42397
distributed.worker - INFO -          dashboard at:      198.202.103.118:35809
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-djvw2vwn
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:38273
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:38273
distributed.worker - INFO -          dashboard at:      198.202.103.118:39725
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ym_2g2ol
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:41151
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:41151
distributed.worker - INFO -          dashboard at:      198.202.103.118:37311
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-96v_x700
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:35873
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:35873
distributed.worker - INFO -          dashboard at:      198.202.103.118:45849
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-rqjr65eq
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:45113
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:34597
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:45113
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:34597
distributed.worker - INFO -          dashboard at:      198.202.103.118:34725
distributed.worker - INFO -          dashboard at:      198.202.103.118:33587
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-f3al5qqi
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-e4lsvd70
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:46539
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:46539
distributed.worker - INFO -          dashboard at:      198.202.103.118:36765
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-t3vye2uu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:38363
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:38363
distributed.worker - INFO -          dashboard at:      198.202.103.118:45961
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-jvigxs0i
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:39621
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:39621
distributed.worker - INFO -          dashboard at:      198.202.103.118:36637
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-vwxo_kge
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:39115
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:39115
distributed.worker - INFO -          dashboard at:      198.202.103.118:37691
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-pc2ahd_z
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:35871
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:35871
distributed.worker - INFO -          dashboard at:      198.202.103.118:47055
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:36661
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:36661
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-df8xv4bs
distributed.worker - INFO -          dashboard at:      198.202.103.118:34653
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-3evsn7lb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:46039
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:46039
distributed.worker - INFO -          dashboard at:      198.202.103.118:39831
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9tdlrfst
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:36549
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:36549
distributed.worker - INFO -          dashboard at:      198.202.103.118:34897
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ephwccha
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:34447
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:34447
distributed.worker - INFO -          dashboard at:      198.202.103.118:45621
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-15_mtejg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:39953
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:39953
distributed.worker - INFO -          dashboard at:      198.202.103.118:34063
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-55y23a1o
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:47023
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:47023
distributed.worker - INFO -          dashboard at:      198.202.103.118:40301
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-hkvkn9nr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:45301
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:45301
distributed.worker - INFO -          dashboard at:      198.202.103.118:46909
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fzb6ifri
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:43969
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:43969
distributed.worker - INFO -          dashboard at:      198.202.103.118:32847
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-mcn4qknx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:39779
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:39779
distributed.worker - INFO -          dashboard at:      198.202.103.118:43999
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-wjscfdbf
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:40469
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:40469
distributed.worker - INFO -          dashboard at:      198.202.103.118:34137
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-yblebbj8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:35823
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:35823
distributed.worker - INFO -          dashboard at:      198.202.103.118:33563
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-82pcblzl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:46063
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:46063
distributed.worker - INFO -          dashboard at:      198.202.103.118:38079
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-p9lp2d6e
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:36223
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:36223
distributed.worker - INFO -          dashboard at:      198.202.103.118:40759
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-wocig_m9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:44273
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:44273
distributed.worker - INFO -          dashboard at:      198.202.103.118:33391
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2qdlisdz
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:32881
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:32881
distributed.worker - INFO -          dashboard at:      198.202.103.118:35669
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2_u3lika
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:42869
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:42869
distributed.worker - INFO -          dashboard at:      198.202.103.118:46929
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1dbh1lox
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:33311
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:33311
distributed.worker - INFO -          dashboard at:      198.202.103.118:42419
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-d33mj06r
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:39105
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:39105
distributed.worker - INFO -          dashboard at:      198.202.103.118:46885
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-82e_ro4p
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:36335
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:36335
distributed.worker - INFO -          dashboard at:      198.202.103.118:44045
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-q20tmiy6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:42627
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:42627
distributed.worker - INFO -          dashboard at:      198.202.103.118:45905
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-687rewy8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:46869
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:46869
distributed.worker - INFO -          dashboard at:      198.202.103.118:40451
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-vy34n2s9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:34813
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:34813
distributed.worker - INFO -          dashboard at:      198.202.103.118:32859
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1dlmkqgq
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:33635
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:33635
distributed.worker - INFO -          dashboard at:      198.202.103.118:35095
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-aa_e1h0a
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:45551
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:45551
distributed.worker - INFO -          dashboard at:      198.202.103.118:34879
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-rrrwgu5x
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:35821
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:35821
distributed.worker - INFO -          dashboard at:      198.202.103.118:37739
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-vjnse5ta
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:42517
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:42517
distributed.worker - INFO -          dashboard at:      198.202.103.118:36615
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-vqlc5ac3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:34057
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:34057
distributed.worker - INFO -          dashboard at:      198.202.103.118:33099
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-xa6m_d46
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:43925
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:43925
distributed.worker - INFO -          dashboard at:      198.202.103.118:39507
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-cav6iw5v
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:38535
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:38535
distributed.worker - INFO -          dashboard at:      198.202.103.118:33847
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ndzxtz1l
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:42629
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:42629
distributed.worker - INFO -          dashboard at:      198.202.103.118:34665
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-dyqf2f0f
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:41505
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:41505
distributed.worker - INFO -          dashboard at:      198.202.103.118:33715
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-mp5lsjk3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:45945
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:45945
distributed.worker - INFO -          dashboard at:      198.202.103.118:33275
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ex1q0reu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:33565
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:33565
distributed.worker - INFO -          dashboard at:      198.202.103.118:44463
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-eksksmmj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:37769
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:37769
distributed.worker - INFO -          dashboard at:      198.202.103.118:44383
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-c38l19pv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:38481
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:38481
distributed.worker - INFO -          dashboard at:      198.202.103.118:43001
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-_aqdjtej
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:35751
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:35751
distributed.worker - INFO -          dashboard at:      198.202.103.118:35391
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-971fh21f
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:42765
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:42765
distributed.worker - INFO -          dashboard at:      198.202.103.118:39297
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8hereqqc
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:34631
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:34631
distributed.worker - INFO -          dashboard at:      198.202.103.118:45205
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-p5v8lh16
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:42783
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:42783
distributed.worker - INFO -          dashboard at:      198.202.103.118:35223
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-q6jetrbf
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:33917
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:33917
distributed.worker - INFO -          dashboard at:      198.202.103.118:43585
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4kt1gnj2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:39533
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:39533
distributed.worker - INFO -          dashboard at:      198.202.103.118:43567
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-c_1od_6p
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:45243
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:45243
distributed.worker - INFO -          dashboard at:      198.202.103.118:37391
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2ay113vv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:45777
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:45777
distributed.worker - INFO -          dashboard at:      198.202.103.118:33301
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1ednbznm
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:38973
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:38973
distributed.worker - INFO -          dashboard at:      198.202.103.118:40803
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-lnr75fvr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:42675
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:42675
distributed.worker - INFO -          dashboard at:      198.202.103.118:44673
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1uqp_7wg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:45513
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:45513
distributed.worker - INFO -          dashboard at:      198.202.103.118:37677
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-j6rum6_u
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:34325
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:34325
distributed.worker - INFO -          dashboard at:      198.202.103.118:38625
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fgppnckl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:36753
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:36753
distributed.worker - INFO -          dashboard at:      198.202.103.118:42809
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-q2svu538
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:33665
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:33665
distributed.worker - INFO -          dashboard at:      198.202.103.118:35415
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9wiu576_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:43723
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:43723
distributed.worker - INFO -          dashboard at:      198.202.103.118:45759
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-mh1d3_2a
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:40653
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:40653
distributed.worker - INFO -          dashboard at:      198.202.103.118:33299
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-sxap9srz
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:44865
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:44865
distributed.worker - INFO -          dashboard at:      198.202.103.118:43323
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-g5bh1rui
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:41463
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:41463
distributed.worker - INFO -          dashboard at:      198.202.103.118:45443
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-zs1ff4y4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:39645
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:39645
distributed.worker - INFO -          dashboard at:      198.202.103.118:35155
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-yj8qizx3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:34301
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:34301
distributed.worker - INFO -          dashboard at:      198.202.103.118:41971
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-wl_wvw82
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:35019
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:35019
distributed.worker - INFO -          dashboard at:      198.202.103.118:42871
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-sl9e4tzn
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:46013
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:46013
distributed.worker - INFO -          dashboard at:      198.202.103.118:37529
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fembsxds
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:33637
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:33637
distributed.worker - INFO -          dashboard at:      198.202.103.118:44989
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-sryjjw0n
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:38879
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:38879
distributed.worker - INFO -          dashboard at:      198.202.103.118:45801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-mw1y3c6_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:45437
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:45437
distributed.worker - INFO -          dashboard at:      198.202.103.118:38935
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-3145kgyk
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:33023
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:33023
distributed.worker - INFO -          dashboard at:      198.202.103.118:39991
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-78_2rock
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:37061
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:37061
distributed.worker - INFO -          dashboard at:      198.202.103.118:33511
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-3q1o237w
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:44121
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:44121
distributed.worker - INFO -          dashboard at:      198.202.103.118:41271
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-iw8ee444
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:40761
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:40761
distributed.worker - INFO -          dashboard at:      198.202.103.118:34791
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-tjwkxu7n
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:34295
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:34295
distributed.worker - INFO -          dashboard at:      198.202.103.118:33521
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-tahe2326
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:45007
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:45007
distributed.worker - INFO -          dashboard at:      198.202.103.118:42647
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-nvmazw6b
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:46301
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:46301
distributed.worker - INFO -          dashboard at:      198.202.103.118:37227
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-dl0fznnt
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:40215
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:40215
distributed.worker - INFO -          dashboard at:      198.202.103.118:38545
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-do77r6g9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:41537
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:41537
distributed.worker - INFO -          dashboard at:      198.202.103.118:46713
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-qmzwdvf5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:33079
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:33079
distributed.worker - INFO -          dashboard at:      198.202.103.118:41103
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-80umvwjt
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:40375
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:40375
distributed.worker - INFO -          dashboard at:      198.202.103.118:37589
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-nt_ii0om
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:36219
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:36219
distributed.worker - INFO -          dashboard at:      198.202.103.118:34103
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-_j9bnjr6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:41847
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:41847
distributed.worker - INFO -          dashboard at:      198.202.103.118:44839
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-k98ajvf4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:34021
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:34021
distributed.worker - INFO -          dashboard at:      198.202.103.118:33735
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-3pe8527z
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:42811
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:42811
distributed.worker - INFO -          dashboard at:      198.202.103.118:32829
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-s19asm1j
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:35485
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:35485
distributed.worker - INFO -          dashboard at:      198.202.103.118:43499
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-0eb3_6qa
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:36575
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:36575
distributed.worker - INFO -          dashboard at:      198.202.103.118:42231
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5o4aoqbg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:44167
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:44167
distributed.worker - INFO -          dashboard at:      198.202.103.118:45149
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-wr_zxnv7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:42795
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:42795
distributed.worker - INFO -          dashboard at:      198.202.103.118:33021
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-k_lnsn12
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:35797
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:35797
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:39573
distributed.worker - INFO -          dashboard at:      198.202.103.118:33891
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:39573
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.103.118:41365
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ep0r8g4g
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-uo5agsb3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:39945
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:39945
distributed.worker - INFO -          dashboard at:      198.202.103.118:34943
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5iuznzdl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:40055
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:40055
distributed.worker - INFO -          dashboard at:      198.202.103.118:33205
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-aonxl0es
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:33811
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:33811
distributed.worker - INFO -          dashboard at:      198.202.103.118:41381
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-akg7z8fb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.118:36669
distributed.worker - INFO -          Listening to: tcp://198.202.103.118:36669
distributed.worker - INFO -          dashboard at:      198.202.103.118:44701
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-_xf09_pf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:43801
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:45763'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:43137'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:34355
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:33337'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:43413
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:39911'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:33131'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:38767
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:45369
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:34973'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:42397
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:34543'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:33851'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:38273
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:43415'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:35873
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:40121'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:41151
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:40299'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:34597
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:46191'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:45113
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:41873'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:39115
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:36197'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:40503'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:38363
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:46539
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:37941'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:39621
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:35413'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:46039
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:41153'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:39953
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:42119'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:36549
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:34877'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:35871
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:42067'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:36661
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:39525'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:34447
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:42859'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:40469
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:33153'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:47023
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:35907'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:42071'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:45301
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:43969
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:36171'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:39779
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:42285'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:35823
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:46693'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:36223
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:40663'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:46063
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:40373'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:44273
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:34641'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:42869
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:41943'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:32881
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:43201'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:33311
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:33841'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:39105
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:37479'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:36335
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:40189'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:42627
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:35689'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:34813
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:39207'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:46869
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:46271'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:41593'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:45551
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:33635
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:36461'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:35821
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:45097'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:42517
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:42011'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:34057
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:43925
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:34341'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:38983'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:41505
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:40221'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:38535
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:43765'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:38481
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:43935'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:36951'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:45945
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:34631
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:46231'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:37769
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:40823'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:35751
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:33059'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:42629
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:42751'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:33565
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:39919'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:33917
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:35747'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:42783
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:35173'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:42675
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:39983'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:44345'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:39533
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:45777
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:41327'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:45243
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:46199'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:40653
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:36973'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:33665
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:38565'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:39645
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:37979'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:34325
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:40387'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:35019
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:43645'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:36753
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:35153'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:45513
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:42843'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:42765
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:43273'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:44865
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:34805'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:41463
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:41705'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:46013
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:46609'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:33637
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:33673'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:43723
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:36737'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:34301
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:34797'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:45437
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:33389'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:38879
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:33019'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:37061
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:46281'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:44121
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:41357'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:40761
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:46529'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:33023
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:44671'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:45007
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:40235'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:46301
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:33689'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:40375
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:40805'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:33079
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:36845'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:40215
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:38973
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:34463'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:38629'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:42795
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:33849'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:41537
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:35787'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:34295
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:43089'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:41847
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:33697'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:34021
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:35755'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:36219
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:37153'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:39945
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:36713'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:35485
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:39567'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:36575
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:35329'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:44167
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:40055
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:34039'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:46675'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:39573
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:46203'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:36669
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.118:45329'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:35797
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:42811
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.118:33811
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 100938 was killed by signal 15
distributed.nanny - INFO - Worker process 100934 was killed by signal 15
distributed.nanny - INFO - Worker process 100955 was killed by signal 15
distributed.nanny - INFO - Worker process 100933 was killed by signal 15
distributed.nanny - INFO - Worker process 100963 was killed by signal 15
distributed.nanny - INFO - Worker process 100960 was killed by signal 15
distributed.nanny - INFO - Worker process 100972 was killed by signal 15
distributed.nanny - INFO - Worker process 100950 was killed by signal 15
distributed.nanny - INFO - Worker process 100965 was killed by signal 15
distributed.nanny - INFO - Worker process 100976 was killed by signal 15
distributed.nanny - INFO - Worker process 100996 was killed by signal 15
distributed.nanny - INFO - Worker process 101014 was killed by signal 15
distributed.nanny - INFO - Worker process 101019 was killed by signal 15
distributed.nanny - INFO - Worker process 100981 was killed by signal 15
distributed.nanny - INFO - Worker process 101065 was killed by signal 15
distributed.nanny - INFO - Worker process 100917 was killed by signal 15
distributed.nanny - INFO - Worker process 100918 was killed by signal 15
distributed.nanny - INFO - Worker process 100930 was killed by signal 15
distributed.nanny - INFO - Worker process 100975 was killed by signal 15
distributed.nanny - INFO - Worker process 101006 was killed by signal 15
distributed.nanny - INFO - Worker process 100942 was killed by signal 15
distributed.nanny - INFO - Worker process 100945 was killed by signal 15
distributed.nanny - INFO - Worker process 100969 was killed by signal 15
distributed.nanny - INFO - Worker process 100989 was killed by signal 15
distributed.nanny - INFO - Worker process 101021 was killed by signal 15
distributed.nanny - INFO - Worker process 100922 was killed by signal 15
distributed.nanny - INFO - Worker process 101054 was killed by signal 15
distributed.nanny - INFO - Worker process 101033 was killed by signal 15
distributed.nanny - INFO - Worker process 101042 was killed by signal 15
distributed.nanny - INFO - Worker process 101058 was killed by signal 15
distributed.nanny - INFO - Worker process 101047 was killed by signal 15
distributed.nanny - INFO - Worker process 101036 was killed by signal 15
distributed.nanny - INFO - Worker process 101050 was killed by signal 15
distributed.nanny - INFO - Worker process 101029 was killed by signal 15
distributed.nanny - INFO - Worker process 101009 was killed by signal 15
distributed.nanny - INFO - Worker process 101060 was killed by signal 15
distributed.nanny - INFO - Worker process 101072 was killed by signal 15
distributed.nanny - INFO - Worker process 101000 was killed by signal 15
distributed.nanny - INFO - Worker process 100957 was killed by signal 15
distributed.nanny - INFO - Worker process 100987 was killed by signal 15
distributed.nanny - INFO - Worker process 100983 was killed by signal 15
distributed.nanny - INFO - Worker process 100995 was killed by signal 15
distributed.nanny - INFO - Worker process 101002 was killed by signal 15
distributed.nanny - INFO - Worker process 101039 was killed by signal 15
distributed.nanny - INFO - Worker process 100921 was killed by signal 15
distributed.nanny - INFO - Worker process 100948 was killed by signal 15
distributed.nanny - INFO - Worker process 101095 was killed by signal 15
distributed.nanny - INFO - Worker process 101099 was killed by signal 15
distributed.nanny - INFO - Worker process 101069 was killed by signal 15
distributed.nanny - INFO - Worker process 101078 was killed by signal 15
distributed.nanny - INFO - Worker process 101103 was killed by signal 15
distributed.nanny - INFO - Worker process 101112 was killed by signal 15
distributed.nanny - INFO - Worker process 101096 was killed by signal 15
distributed.nanny - INFO - Worker process 101125 was killed by signal 15
distributed.nanny - INFO - Worker process 101134 was killed by signal 15
distributed.nanny - INFO - Worker process 101073 was killed by signal 15
distributed.nanny - INFO - Worker process 101085 was killed by signal 15
distributed.nanny - INFO - Worker process 101122 was killed by signal 15
distributed.nanny - INFO - Worker process 101161 was killed by signal 15
distributed.nanny - INFO - Worker process 101115 was killed by signal 15
distributed.nanny - INFO - Worker process 101101 was killed by signal 15
distributed.nanny - INFO - Worker process 101087 was killed by signal 15
distributed.nanny - INFO - Worker process 101127 was killed by signal 15
distributed.nanny - INFO - Worker process 101159 was killed by signal 15
distributed.nanny - INFO - Worker process 101136 was killed by signal 15
distributed.nanny - INFO - Worker process 101080 was killed by signal 15
distributed.nanny - INFO - Worker process 101129 was killed by signal 15
distributed.nanny - INFO - Worker process 101139 was killed by signal 15
distributed.nanny - INFO - Worker process 101146 was killed by signal 15
distributed.nanny - INFO - Worker process 101154 was killed by signal 15
distributed.nanny - INFO - Worker process 101119 was killed by signal 15
distributed.nanny - INFO - Worker process 101143 was killed by signal 15
distributed.nanny - INFO - Worker process 101167 was killed by signal 15
distributed.nanny - INFO - Worker process 101193 was killed by signal 15
distributed.nanny - INFO - Worker process 101171 was killed by signal 15
distributed.nanny - INFO - Worker process 101196 was killed by signal 15
distributed.nanny - INFO - Worker process 101173 was killed by signal 15
distributed.nanny - INFO - Worker process 101210 was killed by signal 15
distributed.nanny - INFO - Worker process 101218 was killed by signal 15
distributed.nanny - INFO - Worker process 101183 was killed by signal 15
distributed.nanny - INFO - Worker process 101208 was killed by signal 15
distributed.nanny - INFO - Worker process 101178 was killed by signal 15
distributed.nanny - INFO - Worker process 100927 was killed by signal 15
distributed.nanny - INFO - Worker process 101224 was killed by signal 15
distributed.nanny - INFO - Worker process 101229 was killed by signal 15
distributed.nanny - INFO - Worker process 101205 was killed by signal 15
distributed.nanny - INFO - Worker process 101220 was killed by signal 15
distributed.nanny - INFO - Worker process 101216 was killed by signal 15
distributed.nanny - INFO - Worker process 101212 was killed by signal 15
distributed.nanny - INFO - Worker process 101186 was killed by signal 15
distributed.nanny - INFO - Worker process 101242 was killed by signal 15
distributed.nanny - INFO - Worker process 101238 was killed by signal 15
distributed.nanny - INFO - Worker process 101227 was killed by signal 15
distributed.nanny - INFO - Worker process 101240 was killed by signal 15
distributed.nanny - INFO - Worker process 101176 was killed by signal 15
distributed.nanny - INFO - Worker process 101236 was killed by signal 15
distributed.nanny - INFO - Worker process 101232 was killed by signal 15
distributed.nanny - INFO - Worker process 101149 was killed by signal 15
distributed.nanny - INFO - Worker process 101190 was killed by signal 15
distributed.nanny - INFO - Worker process 101234 was killed by signal 15
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
