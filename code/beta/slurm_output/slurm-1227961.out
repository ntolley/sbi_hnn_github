distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:35311'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:34577'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:39367'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:45837'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:35097'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:40619'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:42451'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:44151'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:39523'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:34753'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:35519'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:46617'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:38871'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:40481'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:42513'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:37731'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:46859'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:39587'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:37735'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:45827'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:34603'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:44079'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:46243'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:36635'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:44547'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:42935'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:39669'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:40463'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:38519'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:33325'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:42427'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:44141'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:35757'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:33401'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:39625'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:36969'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:33233'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:39091'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:37231'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:37177'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:38019'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:36687'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:37199'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:41843'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:40603'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:34179'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:41025'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:33851'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:40851'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:35013'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:44977'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:35375'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:34919'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:33143'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:43073'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:45671'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:38277'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:42251'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:37485'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:45273'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:42825'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:44839'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:39061'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:44615'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:46659'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:38879'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:41723'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:37609'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:46265'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:45913'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:39245'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:35453'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:44231'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:43449'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:35697'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:45853'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:42237'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:35057'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:37181'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:41903'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:38775'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:45079'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:39007'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:39537'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:39971'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:35001'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:39761'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:36849'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:36767'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:44471'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:39947'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:41763'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:41837'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:36827'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:38537'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:41357'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:40383'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:39345'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:42671'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.143:42899'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:46309
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:36735
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:42203
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:46309
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:36735
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:42203
distributed.worker - INFO -          dashboard at:      198.202.101.143:36275
distributed.worker - INFO -          dashboard at:      198.202.101.143:38451
distributed.worker - INFO -          dashboard at:      198.202.101.143:41265
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8_f5o8ot
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ta9oyvg4
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1qy74piz
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:35807
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:35807
distributed.worker - INFO -          dashboard at:      198.202.101.143:47085
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-a_iu91a8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:40917
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:40917
distributed.worker - INFO -          dashboard at:      198.202.101.143:40015
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-f2he5ev3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:36029
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:36029
distributed.worker - INFO -          dashboard at:      198.202.101.143:45069
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-m8jh9yyh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:45461
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:45461
distributed.worker - INFO -          dashboard at:      198.202.101.143:47035
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1tra14r9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:43123
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:43123
distributed.worker - INFO -          dashboard at:      198.202.101.143:35501
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-psks3c1_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:46701
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:46701
distributed.worker - INFO -          dashboard at:      198.202.101.143:33635
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-u436fzdc
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:40661
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:40661
distributed.worker - INFO -          dashboard at:      198.202.101.143:41521
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-f1bht_y7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:38159
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:38159
distributed.worker - INFO -          dashboard at:      198.202.101.143:46017
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-6bhcpbsp
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:40825
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:40825
distributed.worker - INFO -          dashboard at:      198.202.101.143:39835
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-0j0w9l6v
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:39581
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:39581
distributed.worker - INFO -          dashboard at:      198.202.101.143:38817
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-dpu3cwvz
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:35647
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:35647
distributed.worker - INFO -          dashboard at:      198.202.101.143:38105
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ud78t_se
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:46113
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:46113
distributed.worker - INFO -          dashboard at:      198.202.101.143:46425
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-xkx4cme1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:44563
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:44563
distributed.worker - INFO -          dashboard at:      198.202.101.143:40171
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-f6nbbst6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:38367
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:38367
distributed.worker - INFO -          dashboard at:      198.202.101.143:46089
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fubz9j2q
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:41251
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:41251
distributed.worker - INFO -          dashboard at:      198.202.101.143:35987
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-htplzm2b
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:44175
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:44175
distributed.worker - INFO -          dashboard at:      198.202.101.143:44279
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ivwgbnsn
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:34177
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:34177
distributed.worker - INFO -          dashboard at:      198.202.101.143:39705
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-evif20de
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:39903
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:39903
distributed.worker - INFO -          dashboard at:      198.202.101.143:43303
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-0vve32hr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:43321
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:43321
distributed.worker - INFO -          dashboard at:      198.202.101.143:34593
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-58u3ak9i
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:32945
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:32945
distributed.worker - INFO -          dashboard at:      198.202.101.143:34649
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-nvess1ny
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:40753
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:40753
distributed.worker - INFO -          dashboard at:      198.202.101.143:34063
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-kpyx9g0r
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:46341
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:46341
distributed.worker - INFO -          dashboard at:      198.202.101.143:35699
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-pf4i64ap
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:39583
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:39583
distributed.worker - INFO -          dashboard at:      198.202.101.143:43893
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-n0gxjtrb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:40571
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:40571
distributed.worker - INFO -          dashboard at:      198.202.101.143:37073
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8fnd0bpm
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:40229
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:40229
distributed.worker - INFO -          dashboard at:      198.202.101.143:35569
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-yjs6p3im
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:34857
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:34857
distributed.worker - INFO -          dashboard at:      198.202.101.143:43857
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-hfgr9e40
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:33391
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:33391
distributed.worker - INFO -          dashboard at:      198.202.101.143:33183
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-z0qukoyu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:40567
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:40567
distributed.worker - INFO -          dashboard at:      198.202.101.143:44351
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-047973l9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:41133
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:41133
distributed.worker - INFO -          dashboard at:      198.202.101.143:37469
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9vl9oshz
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:44519
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:44519
distributed.worker - INFO -          dashboard at:      198.202.101.143:46807
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-a2ofz8pz
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:38051
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:38051
distributed.worker - INFO -          dashboard at:      198.202.101.143:40119
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-d_4xn0ac
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:44529
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:44529
distributed.worker - INFO -          dashboard at:      198.202.101.143:34195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-a5z03dci
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:35641
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:35641
distributed.worker - INFO -          dashboard at:      198.202.101.143:40039
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ygwhooyp
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:41591
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:41591
distributed.worker - INFO -          dashboard at:      198.202.101.143:46447
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-yzowd49y
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:42289
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:42289
distributed.worker - INFO -          dashboard at:      198.202.101.143:45049
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-3wumhk98
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:42223
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:42223
distributed.worker - INFO -          dashboard at:      198.202.101.143:38101
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-z0u6uz_j
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:37715
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:37715
distributed.worker - INFO -          dashboard at:      198.202.101.143:44685
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-on0j4x5m
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:37179
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:37179
distributed.worker - INFO -          dashboard at:      198.202.101.143:38471
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-enupwkq7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:43297
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:43297
distributed.worker - INFO -          dashboard at:      198.202.101.143:46055
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-aqrvp8yc
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:37361
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:37361
distributed.worker - INFO -          dashboard at:      198.202.101.143:41509
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-frbj1nsr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:39433
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:39433
distributed.worker - INFO -          dashboard at:      198.202.101.143:43909
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ecemr75f
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:41151
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:41151
distributed.worker - INFO -          dashboard at:      198.202.101.143:43229
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-yxxd21ru
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:33431
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:33431
distributed.worker - INFO -          dashboard at:      198.202.101.143:43353
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-hug1vc7k
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:34165
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:34165
distributed.worker - INFO -          dashboard at:      198.202.101.143:37795
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-kirwlq18
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:45753
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:45753
distributed.worker - INFO -          dashboard at:      198.202.101.143:44181
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-j7iwbkjv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:38959
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:38959
distributed.worker - INFO -          dashboard at:      198.202.101.143:33011
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-3db08_8w
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:41861
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:41861
distributed.worker - INFO -          dashboard at:      198.202.101.143:43547
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-dtg0z6tu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:44415
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:44415
distributed.worker - INFO -          dashboard at:      198.202.101.143:38333
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-twmhfx5c
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:34581
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:34581
distributed.worker - INFO -          dashboard at:      198.202.101.143:37391
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-xpihot5c
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:43225
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:43225
distributed.worker - INFO -          dashboard at:      198.202.101.143:43611
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-sy1sh_td
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:38623
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:38623
distributed.worker - INFO -          dashboard at:      198.202.101.143:35413
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fzlue2fb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:38913
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:38913
distributed.worker - INFO -          dashboard at:      198.202.101.143:42135
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-jcymaju1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:33361
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:33361
distributed.worker - INFO -          dashboard at:      198.202.101.143:33797
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-k85gss7e
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:43103
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:43103
distributed.worker - INFO -          dashboard at:      198.202.101.143:35679
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ax14co6z
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:38809
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:38809
distributed.worker - INFO -          dashboard at:      198.202.101.143:37293
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ds_sp31i
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:39667
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:39667
distributed.worker - INFO -          dashboard at:      198.202.101.143:37713
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8y4k1j91
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:33043
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:33043
distributed.worker - INFO -          dashboard at:      198.202.101.143:46315
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8ed_eytg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:41227
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:41227
distributed.worker - INFO -          dashboard at:      198.202.101.143:33911
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-v78j7po8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:33597
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:33597
distributed.worker - INFO -          dashboard at:      198.202.101.143:37579
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ozw76ult
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:35643
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:35643
distributed.worker - INFO -          dashboard at:      198.202.101.143:45817
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8ivcs2k_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:33179
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:33179
distributed.worker - INFO -          dashboard at:      198.202.101.143:33555
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-b50m2lsw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:33987
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:33987
distributed.worker - INFO -          dashboard at:      198.202.101.143:42723
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-em7cszcg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:39843
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:39843
distributed.worker - INFO -          dashboard at:      198.202.101.143:46639
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8qlkijt7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:38915
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:38915
distributed.worker - INFO -          dashboard at:      198.202.101.143:34253
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-e0s5ztkh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:43853
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:43853
distributed.worker - INFO -          dashboard at:      198.202.101.143:33639
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-bgbiy2dw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:37149
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:37149
distributed.worker - INFO -          dashboard at:      198.202.101.143:34323
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-pq3zpffd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:43189
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:43189
distributed.worker - INFO -          dashboard at:      198.202.101.143:45325
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-la2rxsaw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:46529
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:46529
distributed.worker - INFO -          dashboard at:      198.202.101.143:40803
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-tprlws1j
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:34895
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:34895
distributed.worker - INFO -          dashboard at:      198.202.101.143:32857
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5zhitjxw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:39379
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:39379
distributed.worker - INFO -          dashboard at:      198.202.101.143:42715
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-uou6p1xh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:42299
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:42299
distributed.worker - INFO -          dashboard at:      198.202.101.143:42359
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ak_qx5ag
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:34641
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:34641
distributed.worker - INFO -          dashboard at:      198.202.101.143:42445
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2xxpwxlr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:36393
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:36393
distributed.worker - INFO -          dashboard at:      198.202.101.143:38967
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ld82ktjm
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:45713
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:45713
distributed.worker - INFO -          dashboard at:      198.202.101.143:38343
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-eqqbbri7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:43399
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:43399
distributed.worker - INFO -          dashboard at:      198.202.101.143:37583
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-bxbcuvvj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:38755
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:38755
distributed.worker - INFO -          dashboard at:      198.202.101.143:41235
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-dbsp14ih
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:35637
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:35637
distributed.worker - INFO -          dashboard at:      198.202.101.143:35059
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-7vgyh6qw
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:42125
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:42125
distributed.worker - INFO -          dashboard at:      198.202.101.143:36363
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fk1bmkh8
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:42697
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:42697
distributed.worker - INFO -          dashboard at:      198.202.101.143:46875
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8kyo9abz
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:46321
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:46321
distributed.worker - INFO -          dashboard at:      198.202.101.143:46855
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-7wubrj49
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:44893
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:44893
distributed.worker - INFO -          dashboard at:      198.202.101.143:44061
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-05tmz48_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:41871
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:41871
distributed.worker - INFO -          dashboard at:      198.202.101.143:46393
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-0_i59kfs
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:39255
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:39255
distributed.worker - INFO -          dashboard at:      198.202.101.143:35463
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-6rrokrut
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:43847
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:43847
distributed.worker - INFO -          dashboard at:      198.202.101.143:44499
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-raq_8gz4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:40693
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:40693
distributed.worker - INFO -          dashboard at:      198.202.101.143:37923
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1v4c6fbk
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:42069
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:42069
distributed.worker - INFO -          dashboard at:      198.202.101.143:41439
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9jwnine6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:43079
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:43079
distributed.worker - INFO -          dashboard at:      198.202.101.143:43039
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-gwugjbi1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:38235
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:38235
distributed.worker - INFO -          dashboard at:      198.202.101.143:43647
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-74139jpc
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:36667
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:36667
distributed.worker - INFO -          dashboard at:      198.202.101.143:46569
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-zt_xu0vf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:35089
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:35089
distributed.worker - INFO -          dashboard at:      198.202.101.143:40435
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-wy6103cj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:39287
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:39287
distributed.worker - INFO -          dashboard at:      198.202.101.143:44065
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9ve6cp2v
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:39285
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:39285
distributed.worker - INFO -          dashboard at:      198.202.101.143:35141
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-oxvdpul8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:43423
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:43423
distributed.worker - INFO -          dashboard at:      198.202.101.143:39777
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-lj3wgn15
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:40213
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:40213
distributed.worker - INFO -          dashboard at:      198.202.101.143:35861
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-asbchwv8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:35957
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:35957
distributed.worker - INFO -          dashboard at:      198.202.101.143:44605
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-t1cx9ees
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:36887
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:36887
distributed.worker - INFO -          dashboard at:      198.202.101.143:35971
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-6r5vqkxj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.143:46955
distributed.worker - INFO -          Listening to: tcp://198.202.101.143:46955
distributed.worker - INFO -          dashboard at:      198.202.101.143:43175
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-sfwtho81
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:35311'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:34577'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:38367
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:39367'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:45837'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:43321
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:35097'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:45461
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:40619'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:40661
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:42451'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:38159
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:44151'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:46701
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:39523'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:40571
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:34753'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:32945
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:35519'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:36735
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:46617'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:35647
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:44175
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:38871'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:40917
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:40481'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:42513'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:41133
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:37731'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:43123
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:46859'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:46341
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:39587'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:39581
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:37735'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:39903
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:45827'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:41251
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:34603'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:40825
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:44079'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:34857
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:46243'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:42203
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:36635'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:46113
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:44547'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:46309
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:42935'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:40229
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:39669'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:34177
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:40463'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:35807
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:38519'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:40753
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:33325'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:33391
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:42427'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:39583
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:44141'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:44519
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:35757'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:40567
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:33401'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:38051
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:39625'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:37715
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:36969'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:41591
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:33233'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:44529
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:39091'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:42223
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:37231'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:35641
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:37177'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:37179
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:38019'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:42289
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:36687'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:43297
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:37199'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:39433
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:41843'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:34165
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:33431
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:40603'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:34179'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:41151
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:41025'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:37361
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:33851'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:45753
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:40851'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:36029
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:35013'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:38959
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:44977'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:35375'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:44415
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:34581
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:34919'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:38809
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:33143'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:41861
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:38623
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:43073'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:45671'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:39667
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:43103
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:38277'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:38913
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:42251'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:43225
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:37485'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:45273'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:33361
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:42825'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:41227
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:44839'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:33043
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:39061'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:33597
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:44615'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:39843
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:46659'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:33987
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:38879'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:33179
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:43853
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:41723'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:37609'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:34895
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:46265'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:35643
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:45913'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:42299
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:34641
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:39245'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:35453'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:38915
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:44231'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:43399
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:45713
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:36393
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:43449'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:35697'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:45853'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:46529
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:42237'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:38755
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:35057'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:39379
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:37181'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:35637
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:42697
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:41903'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:38775'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:45079'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:44893
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:39255
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:39007'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:42125
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:39537'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:41871
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:39971'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:46321
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:35001'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:43847
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:39761'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:40693
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:36849'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:42069
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:36767'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:38235
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:44471'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:39287
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:39947'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:35089
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:43079
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:41763'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:41837'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:39285
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:36827'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:43423
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:38537'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:36667
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:41357'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:43189
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:35957
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:40383'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:39345'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:40213
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:42671'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:46955
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.143:42899'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:36887
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:44563
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.143:37149
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 44751 was killed by signal 15
distributed.nanny - INFO - Worker process 44756 was killed by signal 15
distributed.nanny - INFO - Worker process 44768 was killed by signal 15
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 44762 was killed by signal 15
distributed.nanny - INFO - Worker process 44765 was killed by signal 15
distributed.nanny - INFO - Worker process 44912 was killed by signal 15
distributed.nanny - INFO - Worker process 44759 was killed by signal 15
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=45007 parent=44635 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=45005 parent=44635 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=45001 parent=44635 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=45003 parent=44635 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44999 parent=44635 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44997 parent=44635 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44995 parent=44635 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44987 parent=44635 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44991 parent=44635 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44982 parent=44635 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44978 parent=44635 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44971 parent=44635 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44878 parent=44635 started daemon>
