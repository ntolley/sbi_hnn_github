distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:42149'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:39301'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:42003'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:40711'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:38401'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:39493'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:37513'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:39321'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:43025'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:38339'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:44109'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:40315'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:36135'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:44361'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:45631'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:46341'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:41135'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:34389'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:46755'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:41979'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:34737'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:46163'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:36225'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:36653'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:33879'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:39731'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:38449'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:38895'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:43131'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:41205'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:38093'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:38661'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:40039'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:36033'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:36169'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:44511'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:33419'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:33191'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:33285'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:45813'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:36411'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:42859'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:44873'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:33999'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:36071'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:44131'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:36845'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:34065'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:37817'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:43481'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:39897'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:43829'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:36527'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:33989'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:46253'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:44403'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:44931'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:39085'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:39209'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:44209'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:36375'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:38937'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:42869'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:39975'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:35195'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:33927'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:42501'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:42691'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:36915'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:33321'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:35707'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:37139'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:43213'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:42929'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:40553'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:33045'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:39105'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:33825'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:35483'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:36961'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:33993'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:37091'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:34265'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:42117'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:46079'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:44821'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:43399'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:37037'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:39199'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:33475'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:39189'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:41429'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:34953'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:33363'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:43107'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:37309'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:36051'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:43753'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:34547'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.218:42287'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:42467
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:33027
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:42467
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:33027
distributed.worker - INFO -          dashboard at:      198.202.101.218:42791
distributed.worker - INFO -          dashboard at:      198.202.101.218:36365
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-kuvumaag
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-q7372j5j
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:45005
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:45005
distributed.worker - INFO -          dashboard at:      198.202.101.218:37279
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-tto054s0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:40989
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:40989
distributed.worker - INFO -          dashboard at:      198.202.101.218:40145
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-mcril68m
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:36111
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:36111
distributed.worker - INFO -          dashboard at:      198.202.101.218:44961
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-xjpv2s44
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:40565
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:40565
distributed.worker - INFO -          dashboard at:      198.202.101.218:40013
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-6g0myydp
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:43523
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:43523
distributed.worker - INFO -          dashboard at:      198.202.101.218:40753
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-sh15nk3_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:43321
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:43321
distributed.worker - INFO -          dashboard at:      198.202.101.218:35271
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-z0xdeu0d
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:37879
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:37879
distributed.worker - INFO -          dashboard at:      198.202.101.218:43415
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-et44kkc2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:41069
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:41069
distributed.worker - INFO -          dashboard at:      198.202.101.218:36735
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-_v53ns1_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:33165
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:33165
distributed.worker - INFO -          dashboard at:      198.202.101.218:43813
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-41kca6r9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:38935
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:38935
distributed.worker - INFO -          dashboard at:      198.202.101.218:42793
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-bmlzfgw9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:39645
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:39645
distributed.worker - INFO -          dashboard at:      198.202.101.218:43703
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-z5eap0ph
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:44661
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:44661
distributed.worker - INFO -          dashboard at:      198.202.101.218:34543
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-jcwyi4a4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:35009
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:35009
distributed.worker - INFO -          dashboard at:      198.202.101.218:37005
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-t03l5auf
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:35675
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:35675
distributed.worker - INFO -          dashboard at:      198.202.101.218:40293
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-gr3bbokx
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:37987
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:37987
distributed.worker - INFO -          dashboard at:      198.202.101.218:37293
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-s1byniyv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:39021
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:39021
distributed.worker - INFO -          dashboard at:      198.202.101.218:35007
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1lgwpgds
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:37933
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:37933
distributed.worker - INFO -          dashboard at:      198.202.101.218:41659
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-qxusvum0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:40839
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:40839
distributed.worker - INFO -          dashboard at:      198.202.101.218:42111
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-i4we958g
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:43993
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:43993
distributed.worker - INFO -          dashboard at:      198.202.101.218:33299
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-hxtqjqn5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:38635
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:38635
distributed.worker - INFO -          dashboard at:      198.202.101.218:38485
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-d8ir3dtm
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:33681
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:33681
distributed.worker - INFO -          dashboard at:      198.202.101.218:39367
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-dnz2gk91
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:37983
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:37983
distributed.worker - INFO -          dashboard at:      198.202.101.218:44819
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2lncf5p9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:39353
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:39353
distributed.worker - INFO -          dashboard at:      198.202.101.218:33703
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-10drqxw4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:46653
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:46653
distributed.worker - INFO -          dashboard at:      198.202.101.218:40713
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-846t6wbl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:36119
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:36119
distributed.worker - INFO -          dashboard at:      198.202.101.218:46047
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ijw_38xf
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:35475
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:35475
distributed.worker - INFO -          dashboard at:      198.202.101.218:44315
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-6elap8jm
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:39893
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:39893
distributed.worker - INFO -          dashboard at:      198.202.101.218:35703
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-pvj87kwj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:42643
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:42643
distributed.worker - INFO -          dashboard at:      198.202.101.218:33867
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2kqj2imh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:40521
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:40521
distributed.worker - INFO -          dashboard at:      198.202.101.218:38293
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-yf_vwqod
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:41927
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:41927
distributed.worker - INFO -          dashboard at:      198.202.101.218:33701
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-vxk4p05r
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:34681
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:34681
distributed.worker - INFO -          dashboard at:      198.202.101.218:45659
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-kfpayykl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:41459
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:41459
distributed.worker - INFO -          dashboard at:      198.202.101.218:38545
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-v_5letih
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:43877
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:43877
distributed.worker - INFO -          dashboard at:      198.202.101.218:39197
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-awuz5r5r
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:44977
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:44977
distributed.worker - INFO -          dashboard at:      198.202.101.218:36261
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1zj0gb4i
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:35069
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:35069
distributed.worker - INFO -          dashboard at:      198.202.101.218:36655
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-wfiwy1ls
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:45531
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:45531
distributed.worker - INFO -          dashboard at:      198.202.101.218:36383
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-y28nfclt
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:33083
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:33083
distributed.worker - INFO -          dashboard at:      198.202.101.218:46021
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-c4v3g18v
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:37981
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:37981
distributed.worker - INFO -          dashboard at:      198.202.101.218:45665
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-941udt1e
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:42469
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:42469
distributed.worker - INFO -          dashboard at:      198.202.101.218:34263
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-t1zod7ai
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:34307
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:34307
distributed.worker - INFO -          dashboard at:      198.202.101.218:34259
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-bdgnavqs
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:34039
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:34039
distributed.worker - INFO -          dashboard at:      198.202.101.218:43419
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-stgg3nex
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:40797
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:40797
distributed.worker - INFO -          dashboard at:      198.202.101.218:34357
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-16e3cssy
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:39399
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:39399
distributed.worker - INFO -          dashboard at:      198.202.101.218:35295
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ihnvo_x5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:39523
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:39523
distributed.worker - INFO -          dashboard at:      198.202.101.218:43839
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-mqpm4jpq
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:37549
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:37549
distributed.worker - INFO -          dashboard at:      198.202.101.218:41131
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-292e9jqg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:37813
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:37813
distributed.worker - INFO -          dashboard at:      198.202.101.218:44709
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-g_uccyaw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:39233
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:39233
distributed.worker - INFO -          dashboard at:      198.202.101.218:40159
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-nedpbrbe
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:46445
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:46445
distributed.worker - INFO -          dashboard at:      198.202.101.218:41697
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-15g0wooj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:36045
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:36045
distributed.worker - INFO -          dashboard at:      198.202.101.218:34467
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-3xpam076
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:39659
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:39659
distributed.worker - INFO -          dashboard at:      198.202.101.218:40775
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-jvw3v405
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:43287
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:43287
distributed.worker - INFO -          dashboard at:      198.202.101.218:41809
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-w3mrp3mm
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:41539
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:41539
distributed.worker - INFO -          dashboard at:      198.202.101.218:33205
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8q8t5fsz
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:46247
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:46247
distributed.worker - INFO -          dashboard at:      198.202.101.218:45711
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-abwdgu24
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:34309
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:34309
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:38241
distributed.worker - INFO -          dashboard at:      198.202.101.218:34803
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:38241
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.101.218:36303
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-wg9pdia0
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-j7e1zaey
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:36973
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:36973
distributed.worker - INFO -          dashboard at:      198.202.101.218:41181
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ucizy83l
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:45973
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:45973
distributed.worker - INFO -          dashboard at:      198.202.101.218:35397
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-d3f4kkhx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:34237
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:34237
distributed.worker - INFO -          dashboard at:      198.202.101.218:40271
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-cjbr7qa8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:42553
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:42553
distributed.worker - INFO -          dashboard at:      198.202.101.218:42371
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-lv2q2eiz
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:44569
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:44569
distributed.worker - INFO -          dashboard at:      198.202.101.218:33305
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-k5oa4a7_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:42279
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:42279
distributed.worker - INFO -          dashboard at:      198.202.101.218:41047
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-xqi8kxi6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:35215
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:35215
distributed.worker - INFO -          dashboard at:      198.202.101.218:47009
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-mdzmpep0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:43603
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:43603
distributed.worker - INFO -          dashboard at:      198.202.101.218:44415
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-39ye8ndb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:41901
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:41901
distributed.worker - INFO -          dashboard at:      198.202.101.218:37779
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-qngb_6fn
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:36029
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:36029
distributed.worker - INFO -          dashboard at:      198.202.101.218:33457
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-rvxral4b
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:34083
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:34083
distributed.worker - INFO -          dashboard at:      198.202.101.218:33461
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2i_wyavn
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:45589
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:45589
distributed.worker - INFO -          dashboard at:      198.202.101.218:39115
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-msuwp159
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:45215
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:45215
distributed.worker - INFO -          dashboard at:      198.202.101.218:35713
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-0_8dh9iq
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:42219
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:42219
distributed.worker - INFO -          dashboard at:      198.202.101.218:45083
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-xjuvc33p
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:33413
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:33413
distributed.worker - INFO -          dashboard at:      198.202.101.218:40865
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fwc3nyc7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:33145
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:33145
distributed.worker - INFO -          dashboard at:      198.202.101.218:41681
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-_riglwqe
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:46227
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:46227
distributed.worker - INFO -          dashboard at:      198.202.101.218:35969
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ll237isw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:35887
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:35887
distributed.worker - INFO -          dashboard at:      198.202.101.218:34907
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-73rpot7q
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:38897
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:38897
distributed.worker - INFO -          dashboard at:      198.202.101.218:43927
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-tou_o9ub
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:34785
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:34785
distributed.worker - INFO -          dashboard at:      198.202.101.218:34627
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-boc8qmti
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:37221
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:37221
distributed.worker - INFO -          dashboard at:      198.202.101.218:35835
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-rkli015l
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:35259
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:35259
distributed.worker - INFO -          dashboard at:      198.202.101.218:43045
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-03q9jj4u
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:32779
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:32779
distributed.worker - INFO -          dashboard at:      198.202.101.218:44425
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-377g_ybm
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:36049
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:36049
distributed.worker - INFO -          dashboard at:      198.202.101.218:46235
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-g53k0kuf
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:43189
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:43189
distributed.worker - INFO -          dashboard at:      198.202.101.218:40439
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ugln4741
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:33697
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:33697
distributed.worker - INFO -          dashboard at:      198.202.101.218:39737
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-39sr1cf2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:36939
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:36939
distributed.worker - INFO -          dashboard at:      198.202.101.218:41305
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-6sabgfjy
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:45189
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:45189
distributed.worker - INFO -          dashboard at:      198.202.101.218:37261
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-evis77o9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:46427
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:46427
distributed.worker - INFO -          dashboard at:      198.202.101.218:45605
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-3jhp9tds
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:44663
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:44663
distributed.worker - INFO -          dashboard at:      198.202.101.218:39527
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-j0uevn0f
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:41885
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:41885
distributed.worker - INFO -          dashboard at:      198.202.101.218:35845
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-sm3f2i_u
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:43515
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:43515
distributed.worker - INFO -          dashboard at:      198.202.101.218:43815
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9sf4mp2_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:44917
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:44917
distributed.worker - INFO -          dashboard at:      198.202.101.218:40485
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4pazm7s5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:37625
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:37625
distributed.worker - INFO -          dashboard at:      198.202.101.218:46147
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-aryo4mry
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:42337
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:42337
distributed.worker - INFO -          dashboard at:      198.202.101.218:45675
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-s7d53dg5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:37481
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:37481
distributed.worker - INFO -          dashboard at:      198.202.101.218:39821
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-rekd19k7
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:46035
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:46035
distributed.worker - INFO -          dashboard at:      198.202.101.218:39273
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-j_ypmn3l
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:38825
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:38825
distributed.worker - INFO -          dashboard at:      198.202.101.218:35243
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-o1tcwbhb
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:43051
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:43051
distributed.worker - INFO -          dashboard at:      198.202.101.218:33103
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-6a19qfbx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:37591
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:37591
distributed.worker - INFO -          dashboard at:      198.202.101.218:44089
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1xm5vyzs
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:36563
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:36563
distributed.worker - INFO -          dashboard at:      198.202.101.218:44711
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-h4tio5ga
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:46239
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:46239
distributed.worker - INFO -          dashboard at:      198.202.101.218:33403
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-odq3unja
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.218:45025
distributed.worker - INFO -          Listening to: tcp://198.202.101.218:45025
distributed.worker - INFO -          dashboard at:      198.202.101.218:45625
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-dqo87639
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:42149'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:39301'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:42467
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:42003'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:40711'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:40989
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:43523
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:38401'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:33027
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:39493'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:37513'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:36111
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:33165
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:39321'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:43025'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:45005
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:38339'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:40565
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:44109'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:37879
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:41069
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:40315'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:36135'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:43321
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:39645
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:44361'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:45631'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:35009
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:46341'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:38935
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:41135'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:35675
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:34389'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:37987
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:46755'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:44661
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:41979'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:43993
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:34737'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:38635
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:46163'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:40839
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:36225'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:37983
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:36653'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:33681
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:33879'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:39021
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:39731'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:37933
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:38449'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:39353
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:38895'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:46653
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:43131'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:36119
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:41205'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:42643
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:38093'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:39893
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:38661'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:41927
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:40039'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:35475
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:36033'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:34681
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:40521
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:36169'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:44511'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:43877
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:36049
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:33419'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:44977
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:33191'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:33285'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:41459
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:45813'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:33083
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:36411'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:35069
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:42859'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:32779
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:44873'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:45531
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:33999'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:34307
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:37981
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:36071'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:44131'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:42469
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:36845'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:34039
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:34065'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:40797
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:37817'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:37549
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:43481'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:39523
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:39897'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:39399
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:43829'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:37813
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:36527'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:39233
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:33989'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:43287
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:46445
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:46253'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:44403'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:41539
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:44931'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:45189
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:39085'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:42553
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:39209'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:36045
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:44209'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:33697
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:36375'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:39659
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:38937'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:46247
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:42869'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:34309
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:39975'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:38241
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:35195'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:46227
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:33927'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:34237
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:42501'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:36973
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:42691'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:36939
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:45973
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:36915'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:33321'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:42279
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:35707'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:35215
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:37139'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:43603
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:43213'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:35259
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:44569
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:42929'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:40553'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:36029
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:33045'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:42219
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:39105'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:41901
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:34083
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:33825'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:35483'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:43189
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:36961'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:33413
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:33993'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:35887
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:37091'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:45589
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:34265'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:38897
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:42117'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:46427
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:46079'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:33145
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:44821'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:34785
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:43399'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:45215
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:37037'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:44917
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:39199'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:36563
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:33475'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:37221
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:39189'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:42337
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:41429'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:44663
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:34953'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:45025
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:33363'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:43051
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:43107'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:43515
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:37309'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:37481
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:36051'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:37625
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:43753'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:38825
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:34547'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:46239
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.218:42287'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:41885
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:46035
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.218:37591
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46804 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46802 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46800 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46794 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46792 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46787 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46790 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46785 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46782 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46775 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46773 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46778 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46762 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46754 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46747 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46751 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46745 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46737 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46729 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46712 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46522 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46519 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46516 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46511 parent=46417 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46497 parent=46417 started daemon>
