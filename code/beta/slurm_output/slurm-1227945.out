distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:33065'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:44323'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:33097'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:38347'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:42045'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:42669'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:42965'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:40409'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:35217'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:34269'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:45381'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:33059'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:36617'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:40733'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:41577'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:42289'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:39955'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:41201'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:45451'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:36655'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:38859'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:41331'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:33337'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:36339'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:40771'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:34467'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:42229'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:45019'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:45021'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:37153'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:39743'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:43277'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:40517'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:35443'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:36805'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:38029'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:41979'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:40501'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:33897'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:42281'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:34113'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:34255'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:46149'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:45987'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:43339'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:34967'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:46311'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:38991'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:40883'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:40503'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:42037'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:37643'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:44595'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:35677'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:46457'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:40171'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:33667'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:33349'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:32805'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:34215'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:40317'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:44621'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:38831'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:43225'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:39667'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:42397'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:35083'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:44163'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:34923'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:32903'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:44361'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:36505'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:44533'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:39879'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:38473'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:47079'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:43761'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:36963'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:35055'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:43947'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:39451'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:46165'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:41065'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:42367'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:38845'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:37533'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:35537'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:41919'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:37561'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:45389'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:41715'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:40361'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:42609'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:41783'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:41561'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:33561'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:41141'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:38099'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:44907'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.47:45083'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:40095
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:40249
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:42055
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:34371
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:36329
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:40095
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:40249
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:37615
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:42055
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:46841
distributed.worker - INFO -          dashboard at:       198.202.102.47:42445
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:42301
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:36329
distributed.worker - INFO -          dashboard at:       198.202.102.47:45303
distributed.worker - INFO -          dashboard at:       198.202.102.47:33495
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:37615
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:46841
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:42301
distributed.worker - INFO -          dashboard at:       198.202.102.47:37335
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:       198.202.102.47:43175
distributed.worker - INFO -          dashboard at:       198.202.102.47:42517
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:       198.202.102.47:46401
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:34371
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:       198.202.102.47:32941
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-guabgfs5
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-0cc5ngrd
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4tstq8jb
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-0q4uz29m
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fia2x9b3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fftrnq4c
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-r71ntx37
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ius33er6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:46497
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:46497
distributed.worker - INFO -          dashboard at:       198.202.102.47:37317
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4jfevcxg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:35977
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:35977
distributed.worker - INFO -          dashboard at:       198.202.102.47:38973
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ek428k15
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:45541
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:45541
distributed.worker - INFO -          dashboard at:       198.202.102.47:38035
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2ma4nwl9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:37473
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:37473
distributed.worker - INFO -          dashboard at:       198.202.102.47:43267
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-xr_vb52t
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:44997
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:44997
distributed.worker - INFO -          dashboard at:       198.202.102.47:35619
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-dxow27x7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:41229
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:41229
distributed.worker - INFO -          dashboard at:       198.202.102.47:39695
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-32s4rchu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:40757
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:40757
distributed.worker - INFO -          dashboard at:       198.202.102.47:40509
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-pxbkzavt
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:40485
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:40485
distributed.worker - INFO -          dashboard at:       198.202.102.47:45647
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-a2rs_ylo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:40703
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:40703
distributed.worker - INFO -          dashboard at:       198.202.102.47:42501
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2aedy_bn
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:36927
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:36927
distributed.worker - INFO -          dashboard at:       198.202.102.47:37453
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-v7phbv5t
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:46297
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:46297
distributed.worker - INFO -          dashboard at:       198.202.102.47:45731
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ra46ua8r
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:37145
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:37145
distributed.worker - INFO -          dashboard at:       198.202.102.47:39027
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2aoovbn3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:43235
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:43235
distributed.worker - INFO -          dashboard at:       198.202.102.47:37421
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-678tsgi8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:40907
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:40907
distributed.worker - INFO -          dashboard at:       198.202.102.47:43351
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-oqc11kl2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:39183
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:39183
distributed.worker - INFO -          dashboard at:       198.202.102.47:41281
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-xa8q0kf_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:46837
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:46837
distributed.worker - INFO -          dashboard at:       198.202.102.47:38989
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-vj_c9qxt
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:34343
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:34343
distributed.worker - INFO -          dashboard at:       198.202.102.47:45631
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-i3o4i9dy
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:36877
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:36877
distributed.worker - INFO -          dashboard at:       198.202.102.47:34429
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-96cl_icn
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:45537
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:45537
distributed.worker - INFO -          dashboard at:       198.202.102.47:34887
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-o8qembtt
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:46539
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:46539
distributed.worker - INFO -          dashboard at:       198.202.102.47:40765
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-zd3nu5fm
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:42007
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:42007
distributed.worker - INFO -          dashboard at:       198.202.102.47:40065
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-cawxvcnv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:36261
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:36261
distributed.worker - INFO -          dashboard at:       198.202.102.47:43321
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5vinerai
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:39329
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:39329
distributed.worker - INFO -          dashboard at:       198.202.102.47:34257
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-mh5whumi
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:35869
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:35869
distributed.worker - INFO -          dashboard at:       198.202.102.47:34881
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-6lep_2o0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:37251
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:37251
distributed.worker - INFO -          dashboard at:       198.202.102.47:42189
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-30lgzp0i
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:35927
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:35927
distributed.worker - INFO -          dashboard at:       198.202.102.47:44001
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-nbq2xx4y
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:38635
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:38635
distributed.worker - INFO -          dashboard at:       198.202.102.47:45637
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-xg4zliga
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:42371
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:42371
distributed.worker - INFO -          dashboard at:       198.202.102.47:45555
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-o_7h903w
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:44401
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:44401
distributed.worker - INFO -          dashboard at:       198.202.102.47:35673
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-e3e7hn5v
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:41327
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:41327
distributed.worker - INFO -          dashboard at:       198.202.102.47:42409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-709mc9gu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:45281
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:45281
distributed.worker - INFO -          dashboard at:       198.202.102.47:40155
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ry2z9mk9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:44541
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:44541
distributed.worker - INFO -          dashboard at:       198.202.102.47:43637
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-64hsq4ew
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:46269
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:46269
distributed.worker - INFO -          dashboard at:       198.202.102.47:35097
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-v_1r8f1j
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:37151
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:37151
distributed.worker - INFO -          dashboard at:       198.202.102.47:44003
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-okn6wkij
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:44991
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:44991
distributed.worker - INFO -          dashboard at:       198.202.102.47:43433
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:34073
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:34073
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-g1ps27um
distributed.worker - INFO -          dashboard at:       198.202.102.47:45843
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-y0idklui
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:47085
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:47085
distributed.worker - INFO -          dashboard at:       198.202.102.47:45487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-40rsfqvp
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:44495
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:44495
distributed.worker - INFO -          dashboard at:       198.202.102.47:36741
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8xycljvp
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:38065
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:38065
distributed.worker - INFO -          dashboard at:       198.202.102.47:43755
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1qspz54i
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:35095
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:35095
distributed.worker - INFO -          dashboard at:       198.202.102.47:38455
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-n_u03o6l
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:43713
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:43713
distributed.worker - INFO -          dashboard at:       198.202.102.47:41621
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-xiw7az3_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:46375
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:46375
distributed.worker - INFO -          dashboard at:       198.202.102.47:34385
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-7qbue8k0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:34197
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:34197
distributed.worker - INFO -          dashboard at:       198.202.102.47:36475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-r_c0wu0j
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:45807
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:45807
distributed.worker - INFO -          dashboard at:       198.202.102.47:44445
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-h_i6g_o0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:47005
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:47005
distributed.worker - INFO -          dashboard at:       198.202.102.47:41701
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-sc0922gc
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:39933
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:39933
distributed.worker - INFO -          dashboard at:       198.202.102.47:33455
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ek2604k_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:38917
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:38917
distributed.worker - INFO -          dashboard at:       198.202.102.47:37139
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ci66s0e1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:34469
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:34469
distributed.worker - INFO -          dashboard at:       198.202.102.47:44227
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-c6tornmd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:36785
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:36785
distributed.worker - INFO -          dashboard at:       198.202.102.47:46195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-_fmh_mhd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:37613
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:37613
distributed.worker - INFO -          dashboard at:       198.202.102.47:34067
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-6owflwgv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:35417
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:35417
distributed.worker - INFO -          dashboard at:       198.202.102.47:44645
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9dzt5kuf
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:39065
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:39065
distributed.worker - INFO -          dashboard at:       198.202.102.47:37873
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-c4w4huf9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:44591
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:44591
distributed.worker - INFO -          dashboard at:       198.202.102.47:41895
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-nky5vry4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:44409
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:44409
distributed.worker - INFO -          dashboard at:       198.202.102.47:45577
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-vvaowzzs
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:34723
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:34723
distributed.worker - INFO -          dashboard at:       198.202.102.47:38883
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-j9oekd_w
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:34805
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:34805
distributed.worker - INFO -          dashboard at:       198.202.102.47:43159
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:39157
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-lzfqa9gv
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:39157
distributed.worker - INFO -          dashboard at:       198.202.102.47:35643
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-w7phptx3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:39817
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:39817
distributed.worker - INFO -          dashboard at:       198.202.102.47:42647
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-a5zupypf
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:33259
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:33259
distributed.worker - INFO -          dashboard at:       198.202.102.47:36333
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fwlx1v66
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:37295
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:37295
distributed.worker - INFO -          dashboard at:       198.202.102.47:44315
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-47lwpi1n
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:36533
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:36533
distributed.worker - INFO -          dashboard at:       198.202.102.47:46393
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-hxrl8yi7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:44665
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:44665
distributed.worker - INFO -          dashboard at:       198.202.102.47:40469
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-dmughz3u
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:45291
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:45291
distributed.worker - INFO -          dashboard at:       198.202.102.47:38607
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ci1sb16m
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:41005
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:41005
distributed.worker - INFO -          dashboard at:       198.202.102.47:35905
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-sg2yve_1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:37033
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:37033
distributed.worker - INFO -          dashboard at:       198.202.102.47:47031
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-katlx1ms
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:44723
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:44723
distributed.worker - INFO -          dashboard at:       198.202.102.47:35085
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:33023
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:33023
distributed.worker - INFO -          dashboard at:       198.202.102.47:44011
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-v29nsned
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-sv5gplte
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:41389
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:41389
distributed.worker - INFO -          dashboard at:       198.202.102.47:36337
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4beuvlho
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:37663
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:37663
distributed.worker - INFO -          dashboard at:       198.202.102.47:41799
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-aszs4u1p
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:44031
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:44031
distributed.worker - INFO -          dashboard at:       198.202.102.47:38577
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-gz28xq4i
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:44429
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:44429
distributed.worker - INFO -          dashboard at:       198.202.102.47:33883
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-lren1ecv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:43481
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:43481
distributed.worker - INFO -          dashboard at:       198.202.102.47:46979
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5hji2jsh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:37535
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:37535
distributed.worker - INFO -          dashboard at:       198.202.102.47:40511
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5bnq1knj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:34019
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:34019
distributed.worker - INFO -          dashboard at:       198.202.102.47:35795
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-vv2hrfny
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:41321
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:41321
distributed.worker - INFO -          dashboard at:       198.202.102.47:34303
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-s9mul0x_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:35207
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:35207
distributed.worker - INFO -          dashboard at:       198.202.102.47:37477
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2d85tidj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:46865
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:46865
distributed.worker - INFO -          dashboard at:       198.202.102.47:35141
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-iwfvzeaw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:37997
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:37997
distributed.worker - INFO -          dashboard at:       198.202.102.47:38277
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2nc9mldx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:44873
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:44873
distributed.worker - INFO -          dashboard at:       198.202.102.47:40731
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8vpm8qhq
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:37147
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:37147
distributed.worker - INFO -          dashboard at:       198.202.102.47:44661
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-bp3xxqac
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:42265
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:42265
distributed.worker - INFO -          dashboard at:       198.202.102.47:41457
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2zfyarld
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:35763
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:35763
distributed.worker - INFO -          dashboard at:       198.202.102.47:35527
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-dhrpah0b
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:43131
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:43131
distributed.worker - INFO -          dashboard at:       198.202.102.47:40157
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-yog_8fjb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:46483
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:46483
distributed.worker - INFO -          dashboard at:       198.202.102.47:33383
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4a4ihl3s
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:43343
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:43343
distributed.worker - INFO -          dashboard at:       198.202.102.47:39457
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-q_lr2pds
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:44483
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:44483
distributed.worker - INFO -          dashboard at:       198.202.102.47:36493
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-blf9sd9b
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:42195
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:42195
distributed.worker - INFO -          dashboard at:       198.202.102.47:44519
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-g_wdw_9i
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:42687
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:42687
distributed.worker - INFO -          dashboard at:       198.202.102.47:38821
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-489949q5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:38043
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:38043
distributed.worker - INFO -          dashboard at:       198.202.102.47:43397
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-nhi0jklh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:38447
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:38447
distributed.worker - INFO -          dashboard at:       198.202.102.47:41731
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-anahl65o
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:40909
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:40909
distributed.worker - INFO -          dashboard at:       198.202.102.47:42033
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-vf9q1aae
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.47:36081
distributed.worker - INFO -          Listening to: tcp://198.202.102.47:36081
distributed.worker - INFO -          dashboard at:       198.202.102.47:44281
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-swkcz6fz
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:40487
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:33065'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:44323'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:46841
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:33097'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:40249
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:38347'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:42045'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:42055
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:42669'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:37615
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:42965'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:36329
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:40409'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:42301
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:35217'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:34371
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:40095
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:34269'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:45381'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:35977
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:33059'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:45541
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:36617'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:46497
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:40733'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:37473
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:41577'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:44997
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:42289'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:40757
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:39955'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:41229
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:41201'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:40485
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:45451'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:36927
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:36655'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:40703
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:37145
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:38859'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:46297
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:41331'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:43235
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:40907
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:33337'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:36339'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:40771'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:39183
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:34467'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:34343
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:42229'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:46539
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:45019'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:45021'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:46837
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:45537
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:37153'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:36877
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:39743'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:36261
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:43277'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:35869
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:40517'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:42007
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:35443'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:36805'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:37251
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:35927
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:38029'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:39329
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:41979'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:44401
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:40501'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:38635
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:33897'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:42371
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:42281'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:34113'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:45281
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:46269
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:34255'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:44541
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:46149'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:37151
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:45987'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:47085
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:43339'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:44991
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:34967'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:34197
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:46311'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:44495
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:43713
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:35095
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:38991'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:40883'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:40503'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:46375
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:42037'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:37643'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:45807
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:38917
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:44595'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:39933
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:35677'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:36785
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:46457'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:47005
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:40171'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:33667'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:39065
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:34469
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:33349'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:32805'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:35417
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:37613
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:34215'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:44591
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:40317'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:34805
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:44621'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:33259
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:38831'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:34723
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:43225'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:39157
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:39667'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:44409
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:42397'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:37295
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:35083'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:39817
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:44163'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:41005
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:34923'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:45291
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:32903'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:34073
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:44361'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:36505'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:36533
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:41327
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:44533'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:33023
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:39879'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:44665
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:38473'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:37033
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:47079'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:44429
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:43761'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:41389
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:36963'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:44723
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:35055'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:34019
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:43947'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:44031
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:43131
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:39451'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:46165'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:37535
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:41065'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:37663
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:42367'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:43481
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:38845'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:42265
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:37533'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:38447
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:35537'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:38065
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:41919'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:35207
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:37561'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:46865
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:45389'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:44873
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:41715'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:37147
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:40361'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:44483
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:35763
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:37997
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:42609'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:41783'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:41561'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:33561'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:43343
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:41321
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:41141'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:36081
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:38099'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:42687
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:44907'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:38043
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.47:45083'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:46483
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:42195
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.47:40909
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97988 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97986 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97959 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97919 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97916 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97913 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97910 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97908 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97905 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97901 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97899 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97862 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97828 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97761 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97758 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97751 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97756 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97752 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97741 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97738 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97735 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97731 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97665 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97598 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97530 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97596 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97399 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97396 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97393 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97391 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97388 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97316 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97350 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97314 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97319 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97242 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97245 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97233 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97228 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97230 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97237 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97225 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97222 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97207 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97211 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97209 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97195 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97190 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97202 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97192 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97199 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97183 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97181 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97178 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97175 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97170 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97173 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97163 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97158 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97155 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97151 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97147 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97144 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97140 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97134 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97137 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97131 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97129 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97122 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97120 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97115 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97112 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97108 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97106 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97101 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97097 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97092 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97088 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97083 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97081 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97076 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97073 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97070 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97067 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97063 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97059 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97061 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97055 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97052 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97049 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97047 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97044 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97040 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97038 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97034 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97031 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97027 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97022 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97025 parent=96948 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=97020 parent=96948 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
    assert exitcode is not None
AssertionError
