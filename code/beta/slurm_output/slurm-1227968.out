distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:36839'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:33139'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:45177'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:34593'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:40989'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:46555'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:43171'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:42107'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:42779'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:42009'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:36905'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:38113'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:39629'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:34647'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:42777'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:42243'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:39695'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:33883'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:37675'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:47077'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:46875'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:36725'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:43669'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:42099'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:37965'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:33237'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:37285'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:45991'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:41371'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:35921'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:34489'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:44975'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:44195'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:43747'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:41817'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:33575'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:46473'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:39597'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:37625'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:43765'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:42219'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:45747'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:36543'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:34649'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:44263'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:46871'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:35749'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:40777'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:41903'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:36407'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:40577'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:37331'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:40237'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:44565'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:34483'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:37433'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:39319'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:42697'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:42293'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:45763'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:40905'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:37963'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:45351'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:41833'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:41795'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:33851'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:46365'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:46533'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:43985'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:40463'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:45913'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:40743'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:32803'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:44951'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:42737'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:36795'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:43601'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:42095'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:46559'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:45969'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:38501'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:38705'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:38799'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:35495'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:40595'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:39235'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:46773'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:44021'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:39413'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:42587'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:37671'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:42295'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:36397'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:35637'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:47007'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:40735'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:38089'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:34191'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:40423'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.46:43909'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:44593
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:44593
distributed.worker - INFO -          dashboard at:       198.202.102.46:34767
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-bnehk59g
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:34799
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:34799
distributed.worker - INFO -          dashboard at:       198.202.102.46:45831
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-786nhkvx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:33605
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:33605
distributed.worker - INFO -          dashboard at:       198.202.102.46:42175
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fcjxqbbu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:33061
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:33061
distributed.worker - INFO -          dashboard at:       198.202.102.46:41977
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-3p1hz87u
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:37287
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:37287
distributed.worker - INFO -          dashboard at:       198.202.102.46:36133
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-o7mh40pa
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:33171
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:33171
distributed.worker - INFO -          dashboard at:       198.202.102.46:46825
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-atunoh_t
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:43789
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:43789
distributed.worker - INFO -          dashboard at:       198.202.102.46:38693
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5_l48hif
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:46379
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:46379
distributed.worker - INFO -          dashboard at:       198.202.102.46:43443
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-r43wcit6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:47079
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:47079
distributed.worker - INFO -          dashboard at:       198.202.102.46:35147
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-e_8_vcwn
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:39955
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:39955
distributed.worker - INFO -          dashboard at:       198.202.102.46:39787
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-czark0hm
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:46715
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:46715
distributed.worker - INFO -          dashboard at:       198.202.102.46:40409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-dsnk_ywb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:45237
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:45237
distributed.worker - INFO -          dashboard at:       198.202.102.46:45975
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-_f0ycdge
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:32813
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:32813
distributed.worker - INFO -          dashboard at:       198.202.102.46:41733
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-f_yyo1gk
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:39541
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:39541
distributed.worker - INFO -          dashboard at:       198.202.102.46:45721
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-kae1vh7h
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:37519
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:37519
distributed.worker - INFO -          dashboard at:       198.202.102.46:39663
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-rh19q6wa
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:47075
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:47075
distributed.worker - INFO -          dashboard at:       198.202.102.46:38305
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-asnxtf7v
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:33661
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:33661
distributed.worker - INFO -          dashboard at:       198.202.102.46:33487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-59w_gstc
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:40095
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:40095
distributed.worker - INFO -          dashboard at:       198.202.102.46:37217
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-dmw2197j
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:45997
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:45997
distributed.worker - INFO -          dashboard at:       198.202.102.46:38967
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-jw4t5tpb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:36989
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:36989
distributed.worker - INFO -          dashboard at:       198.202.102.46:41107
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-7mz5s2jv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:34257
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:34257
distributed.worker - INFO -          dashboard at:       198.202.102.46:45873
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-daibkrxo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:35965
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:35965
distributed.worker - INFO -          dashboard at:       198.202.102.46:42585
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ux9cjlov
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:33555
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:33555
distributed.worker - INFO -          dashboard at:       198.202.102.46:40205
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4814v845
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:46121
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:46121
distributed.worker - INFO -          dashboard at:       198.202.102.46:33673
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-le2zzik2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:33291
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:33291
distributed.worker - INFO -          dashboard at:       198.202.102.46:42659
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8wol9hj_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:45517
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:45517
distributed.worker - INFO -          dashboard at:       198.202.102.46:34093
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5the5kqx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:34939
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:34939
distributed.worker - INFO -          dashboard at:       198.202.102.46:39179
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-_utt3fpo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:39193
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:39193
distributed.worker - INFO -          dashboard at:       198.202.102.46:39055
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-xmld1w0l
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:43133
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:43133
distributed.worker - INFO -          dashboard at:       198.202.102.46:36595
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-r2jh9v45
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:39685
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:39685
distributed.worker - INFO -          dashboard at:       198.202.102.46:34573
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-gil1xd1b
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:34103
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:34103
distributed.worker - INFO -          dashboard at:       198.202.102.46:35983
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:42353
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:42353
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -          dashboard at:       198.202.102.46:44383
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-t7z3l5d1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ivym2bch
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:40773
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:40773
distributed.worker - INFO -          dashboard at:       198.202.102.46:37403
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-o_vlx94f
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:43095
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:43095
distributed.worker - INFO -          dashboard at:       198.202.102.46:46071
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4n420xor
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:46793
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:46793
distributed.worker - INFO -          dashboard at:       198.202.102.46:45277
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8qnqcawv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:39447
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:39447
distributed.worker - INFO -          dashboard at:       198.202.102.46:33089
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-0i5725s2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:41515
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:41515
distributed.worker - INFO -          dashboard at:       198.202.102.46:40895
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-c9m7qxyy
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:32851
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:32851
distributed.worker - INFO -          dashboard at:       198.202.102.46:36081
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-kbwjcpw0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:46651
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:46651
distributed.worker - INFO -          dashboard at:       198.202.102.46:37069
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-buz_9453
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:35127
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:35127
distributed.worker - INFO -          dashboard at:       198.202.102.46:41019
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-agyg7bng
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:37569
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:37569
distributed.worker - INFO -          dashboard at:       198.202.102.46:33557
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5sbm8f51
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:35303
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:35303
distributed.worker - INFO -          dashboard at:       198.202.102.46:40935
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-stval57g
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:42317
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:42317
distributed.worker - INFO -          dashboard at:       198.202.102.46:38613
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-tpfrf4ka
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:37533
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:37533
distributed.worker - INFO -          dashboard at:       198.202.102.46:43251
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-3e5tftiz
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:41231
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:41231
distributed.worker - INFO -          dashboard at:       198.202.102.46:42865
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-eg9chq5s
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:41341
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:41341
distributed.worker - INFO -          dashboard at:       198.202.102.46:44519
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-zjn74r2k
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:46289
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:46289
distributed.worker - INFO -          dashboard at:       198.202.102.46:35509
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4inoozpl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:33569
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:33569
distributed.worker - INFO -          dashboard at:       198.202.102.46:36847
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-748c6xk1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:40793
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:40793
distributed.worker - INFO -          dashboard at:       198.202.102.46:43085
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-iw4qirx8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:40877
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:40877
distributed.worker - INFO -          dashboard at:       198.202.102.46:34529
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8jwtc1k7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:46673
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:46673
distributed.worker - INFO -          dashboard at:       198.202.102.46:40677
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2vct0fwr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:36409
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:36409
distributed.worker - INFO -          dashboard at:       198.202.102.46:39713
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-gt_ecjpf
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:34459
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:34459
distributed.worker - INFO -          dashboard at:       198.202.102.46:40645
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ynhoi9kg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:45859
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:45859
distributed.worker - INFO -          dashboard at:       198.202.102.46:35139
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-r9tlbjxb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:41747
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:41747
distributed.worker - INFO -          dashboard at:       198.202.102.46:37921
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-h_guuuf6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:35161
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:35161
distributed.worker - INFO -          dashboard at:       198.202.102.46:39109
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9gmsbf3o
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:33253
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:33253
distributed.worker - INFO -          dashboard at:       198.202.102.46:44137
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-rxnyiwms
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:34273
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:34273
distributed.worker - INFO -          dashboard at:       198.202.102.46:35985
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-tedidk47
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:34505
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:34505
distributed.worker - INFO -          dashboard at:       198.202.102.46:33489
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-d__n5lws
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:34301
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:34301
distributed.worker - INFO -          dashboard at:       198.202.102.46:35355
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1l_dk4ex
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:38149
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:38149
distributed.worker - INFO -          dashboard at:       198.202.102.46:40627
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8a_w9f1g
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:43365
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:43365
distributed.worker - INFO -          dashboard at:       198.202.102.46:37915
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-z0sf9lev
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:45657
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:45657
distributed.worker - INFO -          dashboard at:       198.202.102.46:36067
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-lq9ugc55
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:47049
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:47049
distributed.worker - INFO -          dashboard at:       198.202.102.46:46495
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-cxcjob_w
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:44027
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:44027
distributed.worker - INFO -          dashboard at:       198.202.102.46:35731
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-yztut91_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:40515
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:40515
distributed.worker - INFO -          dashboard at:       198.202.102.46:43775
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-10xhq2fv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:38123
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:38123
distributed.worker - INFO -          dashboard at:       198.202.102.46:40505
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9cq2he93
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:40523
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:40523
distributed.worker - INFO -          dashboard at:       198.202.102.46:33527
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-yxr5hvic
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:39129
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:39129
distributed.worker - INFO -          dashboard at:       198.202.102.46:44175
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-kfy_tusw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:43635
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:43635
distributed.worker - INFO -          dashboard at:       198.202.102.46:35321
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-eo8lje8v
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:43885
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:43885
distributed.worker - INFO -          dashboard at:       198.202.102.46:37351
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-w5eqcgh0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:34993
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:34993
distributed.worker - INFO -          dashboard at:       198.202.102.46:39209
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-f3d3q_tt
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:34199
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:34199
distributed.worker - INFO -          dashboard at:       198.202.102.46:41287
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-_v1vww70
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:40741
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:40741
distributed.worker - INFO -          dashboard at:       198.202.102.46:33595
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-isnrjbym
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:36139
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:36139
distributed.worker - INFO -          dashboard at:       198.202.102.46:40447
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-v0_xjaps
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:46043
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:46043
distributed.worker - INFO -          dashboard at:       198.202.102.46:37735
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ezs3epyq
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:41923
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:41923
distributed.worker - INFO -          dashboard at:       198.202.102.46:37041
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-qtkkmbpp
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:44665
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:44665
distributed.worker - INFO -          dashboard at:       198.202.102.46:34309
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-s99hl219
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:44457
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:44457
distributed.worker - INFO -          dashboard at:       198.202.102.46:39697
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-yxh_qd62
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:46687
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:46687
distributed.worker - INFO -          dashboard at:       198.202.102.46:33929
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-s4xlx8rn
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:37701
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:37701
distributed.worker - INFO -          dashboard at:       198.202.102.46:43749
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-wc294fhk
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:33735
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:33735
distributed.worker - INFO -          dashboard at:       198.202.102.46:43573
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-7a3u5ay5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:38565
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:38565
distributed.worker - INFO -          dashboard at:       198.202.102.46:45809
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ty8l38jb
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:38507
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:38507
distributed.worker - INFO -          dashboard at:       198.202.102.46:34009
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5xvuzat9
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:34733
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:34733
distributed.worker - INFO -          dashboard at:       198.202.102.46:38139
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-l7d64wwg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:39925
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:39925
distributed.worker - INFO -          dashboard at:       198.202.102.46:42045
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fhnia1bk
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:44811
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:44811
distributed.worker - INFO -          dashboard at:       198.202.102.46:40753
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-99vry3bg
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:35241
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:35241
distributed.worker - INFO -          dashboard at:       198.202.102.46:38399
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-spr7y5u4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:45367
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:45367
distributed.worker - INFO -          dashboard at:       198.202.102.46:45147
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4mpsjbu8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:33815
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:33815
distributed.worker - INFO -          dashboard at:       198.202.102.46:39839
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5p11rwdk
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:41189
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:41189
distributed.worker - INFO -          dashboard at:       198.202.102.46:41359
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-vufxhw4e
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:41017
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:41017
distributed.worker - INFO -          dashboard at:       198.202.102.46:42053
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-jvd8vk48
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:33129
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:33129
distributed.worker - INFO -          dashboard at:       198.202.102.46:36497
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-v3pwa_em
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:36493
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:36493
distributed.worker - INFO -          dashboard at:       198.202.102.46:37767
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-j5ufsel1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:46427
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:46427
distributed.worker - INFO -          dashboard at:       198.202.102.46:42711
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-_4jefbti
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:42625
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:42625
distributed.worker - INFO -          dashboard at:       198.202.102.46:36639
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-dcnc8iqe
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:39627
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:39627
distributed.worker - INFO -          dashboard at:       198.202.102.46:33125
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-aq73847b
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:34635
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:34635
distributed.worker - INFO -          dashboard at:       198.202.102.46:39801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-zw8msqux
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:44877
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:44877
distributed.worker - INFO -          dashboard at:       198.202.102.46:46077
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-jwiex90a
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.46:43201
distributed.worker - INFO -          Listening to: tcp://198.202.102.46:43201
distributed.worker - INFO -          dashboard at:       198.202.102.46:40699
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-e_pj0ve5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.128:39535
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:36839'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:33139'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:39955
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:45177'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:43789
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:34593'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:46715
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:40989'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:33061
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:46555'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:43171'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:37287
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:42107'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:40095
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:42779'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:39541
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:42009'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:32813
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:47075
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:36905'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:38113'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:46379
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:47079
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:39629'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:33171
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:34647'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:34799
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:44593
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:42777'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:42243'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:39695'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:45237
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:33883'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:37519
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:37675'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:33661
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:47077'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:45997
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:46875'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:36725'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:36989
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:35965
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:43669'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:34939
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:42099'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:45517
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:37965'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:46121
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:33237'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:34103
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:37285'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:34257
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:39193
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:45991'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:41371'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:42353
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:35921'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:39685
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:34489'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:40773
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:44975'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:35303
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:44195'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:33291
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:43747'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:33555
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:41817'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:46793
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:33575'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:46473'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:39447
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:37569
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:39597'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:41515
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:37625'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:35127
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:43765'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:43133
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:42219'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:33605
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:45747'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:32851
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:36543'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:46651
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:34649'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:43095
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:44263'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:34459
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:46871'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:35749'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:40877
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:46289
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:40777'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:33569
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:41903'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:42317
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:40793
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:45859
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:36407'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:40577'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:37331'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:41231
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:40237'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:37533
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:44565'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:34483'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:41747
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:41341
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:37433'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:43365
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:39319'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:46673
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:42697'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:36409
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:42293'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:40523
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:45763'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:38149
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:40905'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:33253
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:37963'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:34505
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:45351'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:41833'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:47049
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:43635
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:41795'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:40515
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:33851'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:34273
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:46365'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:35161
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:46533'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:34301
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:43985'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:46687
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:40463'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:45913'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:44665
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:38123
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:40743'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:40741
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:32803'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:44027
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:44951'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:45657
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:42737'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:36139
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:36795'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:33735
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:43601'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:41923
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:42095'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:46043
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:46559'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:43885
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:45969'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:39925
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:38501'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:34199
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:38705'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:39129
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:38799'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:38565
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:35495'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:45367
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:40595'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:34733
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:39235'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:35241
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:46773'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:38507
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:44021'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:44457
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:39413'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:41189
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:42587'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:44877
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:37671'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:34993
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:42295'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:46427
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:36397'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:33129
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:35637'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:39627
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:47007'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:43201
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:40735'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:36493
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:38089'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:41017
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:33815
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:34191'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:40423'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:37701
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.46:43909'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:42625
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:44811
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.46:34635
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93538 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93536 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93532 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93533 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93526 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93530 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93524 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93522 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93540 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93520 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93516 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93509 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93528 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93506 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93499 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93503 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93513 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93501 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93494 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93487 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93496 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93481 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93489 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93484 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93476 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93472 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93468 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93465 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93461 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93456 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93458 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93454 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93449 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93451 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93446 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93442 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93435 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93438 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93429 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93425 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93420 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93422 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93416 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93413 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93409 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93406 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93403 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93401 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93397 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93392 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93395 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93390 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93382 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93380 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93385 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93371 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93376 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93375 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93368 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93362 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93364 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93358 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93355 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93352 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93349 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93346 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93344 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93339 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93337 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93334 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93332 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93327 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93325 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93320 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93319 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93316 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93313 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93309 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93307 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93301 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93304 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93297 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93295 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93291 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93289 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93286 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93283 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93280 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93277 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93274 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93270 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93264 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93267 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93259 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93263 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93257 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93260 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93255 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93253 parent=93167 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93251 parent=93167 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
    assert exitcode is not None
AssertionError
