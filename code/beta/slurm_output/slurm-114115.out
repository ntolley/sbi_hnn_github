## SLURM PROLOG ###############################################################
##    Job ID : 114115
##  Job Name : dask-worker
##  Nodelist : node1835
##      CPUs : 1
##  Mem/Node : 96256 MB
## Directory : /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta
##   Started : Wed Jan 13 17:28:30 EST 2021
###############################################################################
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:39693'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:33688'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:44552'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:42147'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:42601'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:33268'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:44005'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:35351'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:33849'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:33793'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:45678'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:35128'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:40348'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:40980'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:45504'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:37917'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:42303'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:34932'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:34346'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:36061'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:35278'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:43854'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:35530'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:37665'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:39849'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:36897'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:33684'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:35034'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:38239'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:38967'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:44838'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:40710'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:43187'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:34624'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:37139'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:41729'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:40748'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:37992'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:45747'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:33261'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:43172'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.214.35:44795'
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ff9wgp2y', purging
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ff9wgp2y' (failed in <built-in function rmdir>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ff9wgp2y'
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-w1aeqaw8', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-a4gz5bzk', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-k1hacsyk', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-s3x27_he', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-97pglbuw', purging
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-97pglbuw' (failed in <built-in function rmdir>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-97pglbuw'
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-3apxr4e0', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-98_62c2t', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2tyiv6qf', purging
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2tyiv6qf' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2tyiv6qf'
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-sde88unv', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-7a4mea85', purging
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:38339
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:38339
distributed.worker - INFO -          dashboard at:        172.20.214.35:42139
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-kzukn_kx
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:36746
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:36746
distributed.worker - INFO -          dashboard at:        172.20.214.35:37393
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-puy1e66z
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2cxhmnm7', purging
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:44925
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:44925
distributed.worker - INFO -          dashboard at:        172.20.214.35:37401
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-kx2bzzks
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:34279
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:34279
distributed.worker - INFO -          dashboard at:        172.20.214.35:33649
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-q_g2f9ju
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:33689
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:33689
distributed.worker - INFO -          dashboard at:        172.20.214.35:39202
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-p5gwr5l3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:44975
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:44975
distributed.worker - INFO -          dashboard at:        172.20.214.35:40459
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-48_gfu46
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:36330
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:36330
distributed.worker - INFO -          dashboard at:        172.20.214.35:37823
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-6rh6e1vq
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:40838
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:40838
distributed.worker - INFO -          dashboard at:        172.20.214.35:45043
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-kmb0qdnn
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ccud2bcc', purging
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ccud2bcc' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ccud2bcc'
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-myn161n3', purging
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:34116
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:34116
distributed.worker - INFO -          dashboard at:        172.20.214.35:44036
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2vj834za
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-myn161n3/storage' (failed in <built-in function rmdir>): [Errno 2] No such file or directory: 'storage'
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-myn161n3' (failed in <built-in function rmdir>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-myn161n3'
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-oy7dcjwy', purging
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:37927
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:37927
distributed.worker - INFO -          dashboard at:        172.20.214.35:44350
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-lug3qf8f
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:36501
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:36501
distributed.worker - INFO -          dashboard at:        172.20.214.35:42432
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-golmyibt
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-36j2kza3', purging
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:36726
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:36726
distributed.worker - INFO -          dashboard at:        172.20.214.35:46130
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-sz56z1sj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:32864
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:32864
distributed.worker - INFO -          dashboard at:        172.20.214.35:44006
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-yvclczf9
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-7k1gd5zb', purging
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-7k1gd5zb' (failed in <built-in function rmdir>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-7k1gd5zb'
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-eot12n_o', purging
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:42302
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:42302
distributed.worker - INFO -          dashboard at:        172.20.214.35:41032
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-wqlvqbyv
distributed.worker - INFO - -------------------------------------------------
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-vh1j6vf5', purging
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:34621
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:34621
distributed.worker - INFO -          dashboard at:        172.20.214.35:37890
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-86m4ajr3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:44872
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:44872
distributed.worker - INFO -          dashboard at:        172.20.214.35:39217
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-utchzk5e
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:36912
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:36912
distributed.worker - INFO -          dashboard at:        172.20.214.35:37825
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-_wb2lxik
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:33111
distributed.core - INFO - Starting established connection
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:33111
distributed.worker - INFO -          dashboard at:        172.20.214.35:33679
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-802_z4s6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:40987
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:40987
distributed.worker - INFO -          dashboard at:        172.20.214.35:41244
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-snsu5rjc
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:38908
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:38908
distributed.worker - INFO -          dashboard at:        172.20.214.35:39844
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-qoq_neo1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:44557
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:44557
distributed.worker - INFO -          dashboard at:        172.20.214.35:41805
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-wdpro5u5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:40699
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:40699
distributed.worker - INFO -          dashboard at:        172.20.214.35:42253
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ay9f118n
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:37133
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:37133
distributed.worker - INFO -          dashboard at:        172.20.214.35:41996
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-85u4r77b
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:33677
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:33677
distributed.worker - INFO -          dashboard at:        172.20.214.35:38881
distributed.core - INFO - Starting established connection
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-32c93yrr
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:35082
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:35082
distributed.worker - INFO -          dashboard at:        172.20.214.35:40465
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-k_gq10c_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:46634
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:46634
distributed.worker - INFO -          dashboard at:        172.20.214.35:43255
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-vyfr_zx5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:42528
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:42528
distributed.worker - INFO -          dashboard at:        172.20.214.35:37787
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-b_c2565v
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:43503
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:43503
distributed.worker - INFO -          dashboard at:        172.20.214.35:40263
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-pmg742rj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:46398
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:46398
distributed.worker - INFO -          dashboard at:        172.20.214.35:37470
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-z3tzyrrl
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:37163
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:37163
distributed.worker - INFO -          dashboard at:        172.20.214.35:38860
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:40947
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-wudwxmd0
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:40947
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:        172.20.214.35:42116
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-q1q21jk3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:35515
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:35515
distributed.worker - INFO -          dashboard at:        172.20.214.35:44377
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-2w_4i8lw
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:41084
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:41084
distributed.worker - INFO -          dashboard at:        172.20.214.35:37041
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-e25riui_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:38511
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:38511
distributed.worker - INFO -          dashboard at:        172.20.214.35:35942
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:38854
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:38854
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:        172.20.214.35:41746
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-befsg9p2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9w3h_s1d
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:33753
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:33753
distributed.worker - INFO -          dashboard at:        172.20.214.35:36145
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-x1zdblo3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:34581
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:34581
distributed.worker - INFO -          dashboard at:        172.20.214.35:44364
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-_o0u8yu1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:40221
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:40221
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO -          dashboard at:        172.20.214.35:40929
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-i5l56455
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:38453
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:38453
distributed.worker - INFO -          dashboard at:        172.20.214.35:36562
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-qj9l0mof
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:46683
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:46683
distributed.worker - INFO -          dashboard at:        172.20.214.35:37739
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ux462wnl
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:45903
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:45903
distributed.worker - INFO -          dashboard at:        172.20.214.35:40425
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-w3pj87pi
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/users/ntolley/anaconda/sbi/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:  tcp://172.20.214.35:38730
distributed.worker - INFO -          Listening to:  tcp://172.20.214.35:38730
distributed.worker - INFO -          dashboard at:        172.20.214.35:41005
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    2.38 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ody0xzrh
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.13:46532
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(7300, 7400))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(1500, 1600))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(1700, 1800))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(4000, 4100))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(2700, 2800))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(9900, 10000))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(6600, 6700))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(4200, 4300))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(2300, 2400))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(3500, 3600))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(8900, 9000))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(7800, 7900))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(3100, 3200))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(2900, 3000))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(3800, 3900))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(6300, 6400))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(5500, 5600))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(5000, 5100))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(6900, 7000))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(7900, 8000))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(7000, 7100))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(6700, 6800))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(3300, 3400))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(2500, 2600))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(800, 900))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(7700, 7800))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(8100, 8200))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(400, 500))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(1100, 1200))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(6000, 6100))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(6500, 6600))
kwargs:    {}
Exception: NameError("name 'sub_result' is not defined")

distributed.worker - WARNING -  Compute Failed
Function:  batch
args:      (range(9900, 10000))
kwargs:    {}
Exception: TypeError('append() takes exactly one argument (0 given)')

Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:42528 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:54560': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:40699 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:34376': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:36330 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:51816': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:38730 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:45990': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:46398 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:33111 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:57686': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:41072': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:44975 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:36746 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:41944': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:57614': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:38854 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:53704': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:34116 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:40928': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:36501 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:45854': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:40221 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:36912 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:49182': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:54914': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:38453 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:38200': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:32864 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:57272': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:41084 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:44872 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:46683 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:40990': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:42168': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:40947 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:41832': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:33689 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:57484': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:46826': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:38908 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:33753 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:55908': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:49442': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:45903 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:46976': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:37133 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:44116': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:37927 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:48858': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:46634 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:51730': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:43503 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:40684': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:38339 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:42734': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - ERROR - failed during get data with tcp://172.20.214.35:44557 -> None
Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
TimeoutError: [Errno 110] Connection timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 1347, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 265, in write
    convert_stream_closed_error(self, e)
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/comm/tcp.py", line 124, in convert_stream_closed_error
    ) from exc
distributed.comm.core.CommClosedError: in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.core - INFO - Lost connection to 'tcp://172.20.209.13:45204': in <closed TCP>: TimeoutError: [Errno 110] Connection timed out
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:45903
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:34279
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:36501
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:38453
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:38511
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:46634
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:33689
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:43503
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:40221
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:37927
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:32864
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:38854
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:34581
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:36330
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:37133
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:44975
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:40947
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:36726
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:34116
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:36912
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:41084
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:37163
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:44557
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:35082
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:40838
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:40987
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:40699
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:33753
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:33677
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:44925
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:42302
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:35515
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:46398
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:36746
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:38908
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:38339
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:42528
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:46683
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:44872
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:33111
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:34621
distributed.worker - INFO - Stopping worker at tcp://172.20.214.35:38730
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:45747'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:33793'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:42601'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:40348'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:44838'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:37139'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:37992'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:35530'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:36897'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:33261'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:33688'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:36061'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:35351'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:45504'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:33268'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:34932'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:41729'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:43187'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:40710'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:33684'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:42303'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:44795'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:39693'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:43854'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:37665'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:34624'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:45678'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:34346'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:38239'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:39849'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:40980'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:44005'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:33849'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:35034'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:44552'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:38967'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:35278'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:43172'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:42147'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:37917'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:35128'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.214.35:40748'
distributed.dask_worker - INFO - End worker
