## SLURM PROLOG ###############################################################
##    Job ID : 101843
##  Job Name : dask-worker
##  Nodelist : node1314
##      CPUs : 1
##  Mem/Node : 96256 MB
## Directory : /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta
##   Started : Tue Jan 12 08:02:19 EST 2021
###############################################################################
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.209.14:40757'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.209.14:40912'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.209.14:43991'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.209.14:35500'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.209.14:45667'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.209.14:36552'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.209.14:41067'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.209.14:40716'
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-bvrd_asu', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-pwvaam8w', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-blm0af0h', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-eeht9q5e', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fon5ezzj', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-21equsng', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-87uil43h', purging
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-kezfwtu9', purging
distributed.worker - INFO -       Start worker at:  tcp://172.20.209.14:44202
distributed.worker - INFO -          Listening to:  tcp://172.20.209.14:44202
distributed.worker - INFO -          dashboard at:        172.20.209.14:38748
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:42243
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                   12.50 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-7t1jcg0w
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.209.14:33271
distributed.worker - INFO -          Listening to:  tcp://172.20.209.14:33271
distributed.worker - INFO -          dashboard at:        172.20.209.14:44662
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:42243
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                   12.50 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-91pkxiv0
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.209.14:34910
distributed.worker - INFO -          Listening to:  tcp://172.20.209.14:34910
distributed.worker - INFO -          dashboard at:        172.20.209.14:36353
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:42243
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                   12.50 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-w9mc29aj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.209.14:37217
distributed.worker - INFO -          Listening to:  tcp://172.20.209.14:37217
distributed.worker - INFO -          dashboard at:        172.20.209.14:33468
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:42243
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                   12.50 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-azp4xos8
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:42243
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:42243
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.209.14:37162
distributed.worker - INFO -          Listening to:  tcp://172.20.209.14:37162
distributed.worker - INFO -          dashboard at:        172.20.209.14:35261
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:42243
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                   12.50 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-odm9u66q
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:  tcp://172.20.209.14:42922
distributed.worker - INFO -          Listening to:  tcp://172.20.209.14:42922
distributed.worker - INFO -          dashboard at:        172.20.209.14:38056
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:42243
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                   12.50 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-05cf_iai
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:42243
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.209.14:36169
distributed.worker - INFO -          Listening to:  tcp://172.20.209.14:36169
distributed.worker - INFO -          dashboard at:        172.20.209.14:38680
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:42243
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                   12.50 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-o3a3i1ky
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:42243
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:  tcp://172.20.209.14:45094
distributed.worker - INFO -          Listening to:  tcp://172.20.209.14:45094
distributed.worker - INFO -          dashboard at:        172.20.209.14:33336
distributed.worker - INFO - Waiting to connect to:  tcp://172.20.209.24:42243
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                   12.50 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-hm7f5hx_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:42243
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:42243
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:42243
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:  tcp://172.20.209.24:42243
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 6.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.core - INFO - Event loop was unresponsive in Worker for 5.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Stopping worker at tcp://172.20.209.14:37217
distributed.worker - INFO - Stopping worker at tcp://172.20.209.14:37162
distributed.worker - INFO - Stopping worker at tcp://172.20.209.14:36169
distributed.worker - INFO - Stopping worker at tcp://172.20.209.14:42922
distributed.worker - INFO - Stopping worker at tcp://172.20.209.14:45094
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-azp4xos8' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-azp4xos8'
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-odm9u66q' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-odm9u66q'
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-o3a3i1ky' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-o3a3i1ky'
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-hm7f5hx_' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-hm7f5hx_'
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-05cf_iai' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-05cf_iai'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.209.14:34910
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-w9mc29aj' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-w9mc29aj'
distributed.core - INFO - Event loop was unresponsive in Worker for 12.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.209.14:44202
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-7t1jcg0w' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-7t1jcg0w'
distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Stopping worker at tcp://172.20.209.14:33271
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-91pkxiv0' (failed in <built-in function lstat>): [Errno 2] No such file or directory: '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-91pkxiv0'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.209.14:36552'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.209.14:45667'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.209.14:40716'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.209.14:41067'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.209.14:35500'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Fatal Python error: This thread state must be current when releasing

Current thread 0x00007f32ab92b700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 58 in simulation_time
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 71 in _simulate_single_trial
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 35 in _clone_and_simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in <genexpr>
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/dipole.py", line 72 in simulate_dipole
  File "<ipython-input-3-2a3cf4ddb92c>", line 18 in __call__
  File "<ipython-input-3-2a3cf4ddb92c>", line 28 in run_simulator
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3318 in execute_task
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3425 in apply_function
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/_concurrent_futures_thread.py", line 65 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 55 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f331ffff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f3343fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f3367fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/selectors.py", line 415 in select
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 921 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 414 in _poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 257 in poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/queues.py", line 104 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/nanny.py", line 748 in watch_stop_q
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f338bfff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/tokenize.py", line 447 in open
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 136 in updatecache
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 47 in getlines
  File "/users/ntolley/.local/lib/python3.7/site-packages/torch/_fx/graph_module.py", line 27 in patched_getline
  File "/users/ntolley/anaconda/sbi/lib/python3.7/linecache.py", line 16 in getline
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 67 in info_frame
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 114 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 103 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 103 in process
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 268 in _watch
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f33b016c700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 379 in _recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 407 in _recv_bytes
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 250 in recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/process.py", line 143 in monitor_parent
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f33be3d5740 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/_weakrefset.py", line 38 in _remove
distributed.nanny - INFO - Worker process 232211 was killed by signal 6
Fatal Python error: This thread state must be current when releasing

Current thread 0x00007f506bf1f700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 58 in simulation_time
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 71 in _simulate_single_trial
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 35 in _clone_and_simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in <genexpr>
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/dipole.py", line 72 in simulate_dipole
  File "<ipython-input-3-2a3cf4ddb92c>", line 18 in __call__
  File "<ipython-input-3-2a3cf4ddb92c>", line 28 in run_simulator
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3318 in execute_task
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3425 in apply_function
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/_concurrent_futures_thread.py", line 65 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 55 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f50dffff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f5103fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f5127fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/selectors.py", line 415 in select
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 921 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 414 in _poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 257 in poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/queues.py", line 104 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/nanny.py", line 748 in watch_stop_q
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f514bfff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 269 in _watch
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f51707ec700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 379 in _recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 407 in _recv_bytes
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 250 in recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/process.py", line 143 in monitor_parent
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007f517ea55740 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/_weakrefset.py", line 38 in _remove
distributed.nanny - INFO - Worker process 232214 was killed by signal 6
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Fatal Python error: This thread state must be current when releasing

Current thread 0x00007fd476442700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 58 in simulation_time
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/network_builder.py", line 71 in _simulate_single_trial
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 35 in _clone_and_simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in <genexpr>
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/parallel_backends.py", line 166 in simulate
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/hnn_core/dipole.py", line 72 in simulate_dipole
  File "<ipython-input-3-2a3cf4ddb92c>", line 18 in __call__
  File "<ipython-input-3-2a3cf4ddb92c>", line 28 in run_simulator
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3318 in execute_task
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/worker.py", line 3425 in apply_function
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/_concurrent_futures_thread.py", line 65 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 55 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fd4ebfff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fd50eca0700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 300 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/queue.py", line 179 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/threadpoolexecutor.py", line 51 in _worker
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fd533fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/selectors.py", line 415 in select
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 921 in wait
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 414 in _poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 257 in poll
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/queues.py", line 104 in get
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/nanny.py", line 748 in watch_stop_q
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fd557fff700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/profile.py", line 269 in _watch
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fd57acb2700 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 379 in _recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 407 in _recv_bytes
  File "/users/ntolley/anaconda/sbi/lib/python3.7/multiprocessing/connection.py", line 250 in recv
  File "/users/ntolley/anaconda/sbi/lib/python3.7/site-packages/distributed/process.py", line 143 in monitor_parent
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 870 in run
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 926 in _bootstrap_inner
  File "/users/ntolley/anaconda/sbi/lib/python3.7/threading.py", line 890 in _bootstrap

Thread 0x00007fd588f1b740 (most recent call first):
  File "/users/ntolley/anaconda/sbi/lib/python3.7/_weakrefset.py", line 38 in _remove
distributed.nanny - INFO - Worker process 232208 was killed by signal 6
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.209.14:40912'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.209.14:43991'
distributed.nanny - INFO - Closing Nanny at 'tcp://172.20.209.14:40757'
distributed.dask_worker - INFO - End worker
