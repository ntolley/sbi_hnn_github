## SLURM PROLOG ###############################################################
##    Job ID : 37540
##  Job Name : dask-worker
##  Nodelist : node1126
##      CPUs : 1
##  Mem/Node : 19456 MB
## Directory : /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta
##   Started : Sun Jan 10 16:33:57 EST 2021
###############################################################################
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.20.207.26:33374'
distributed.diskutils - INFO - Found stale lock file and directory '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4teeehq2', purging
distributed.diskutils - ERROR - Failed to remove '/gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4teeehq2/storage' (failed in <built-in function rmdir>): [Errno 2] No such file or directory: 'storage'
distributed.worker - INFO -       Start worker at:  tcp://172.20.207.26:41034
distributed.worker - INFO -          Listening to:  tcp://172.20.207.26:41034
distributed.worker - INFO -          dashboard at:        172.20.207.26:44856
distributed.worker - INFO - Waiting to connect to:   tcp://172.20.209.7:46529
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          8
distributed.worker - INFO -                Memory:                   20.00 GB
distributed.worker - INFO -       Local Directory: /gpfs/home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-glhrs7_t
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.20.209.7:46529
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
slurmstepd: error: *** JOB 37540 ON node1126 CANCELLED AT 2021-01-10T16:35:51 ***
