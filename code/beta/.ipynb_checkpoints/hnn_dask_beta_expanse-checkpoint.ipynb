{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://198.202.102.90:36321</li>\n",
       "  <li><b>Dashboard: </b><a href='http://198.202.102.90:8787/status' target='_blank'>http://198.202.102.90:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://198.202.102.90:36321' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "if 'DISPLAY' in os.environ:\n",
    "    del os.environ['DISPLAY']\n",
    "    \n",
    "user_env = os.environ['USER']\n",
    "job_env = os.environ['SLURM_JOB_ID']\n",
    "\n",
    "import numpy as np\n",
    "import dill\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import dask\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import hnn_core\n",
    "from hnn_core import simulate_dipole, Network, read_params, JoblibBackend, MPIBackend\n",
    "import sbi.utils as utils\n",
    "import datetime\n",
    "import dask.bag as db\n",
    "#time_stamp = datetime.datetime.now().strftime(\"%m%d%Y_%H%M%S\")\n",
    "#import logging\n",
    "#logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)\n",
    "\n",
    "\n",
    "cluster = SLURMCluster(cores = 50,\n",
    "                       processes=50,\n",
    "                       queue='compute',\n",
    "                       memory=\"200GB\",\n",
    "                       walltime=\"48:00:00\",\n",
    "                       job_extra=['-A csd403', '--nodes=1']\n",
    "                       \n",
    ")\n",
    "# local_directory = '/scratch/' + user_env +'/job_' + job_env\n",
    "#'--cpus-per-task=1'\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulations = 100000\n",
    "time_stamp = datetime.datetime.now().strftime(\"%m%d%Y_%H%M%S\")\n",
    "\n",
    "params_fname = '../../data/beta/params/beta_param.param'\n",
    "save_suffix = 'beta_event_expanse_t100000' + '_' + time_stamp\n",
    "save_path = '../../data/beta/prerun_simulations/' + save_suffix  + '/'\n",
    "\n",
    "prior_dict = {'dipole_scalefctr': (60000, 200000),\n",
    " 't_evprox_1': (225, 255),\n",
    " 'sigma_t_evprox_1': (10, 50),\n",
    " 'numspikes_evprox_1': (1, 20),\n",
    " 'gbar_evprox_1_L2Pyr_ampa': (1e-06, 0.0005),\n",
    " 'gbar_evprox_1_L5Pyr_ampa': (1e-06, 0.0005),\n",
    " 't_evdist_1': (235, 255),\n",
    " 'sigma_t_evdist_1': (5, 30),\n",
    " 'numspikes_evdist_1': (1, 20),\n",
    " 'gbar_evdist_1_L2Pyr_ampa': (1e-06, 0.0005),\n",
    " 'gbar_evdist_1_L5Pyr_ampa': (1e-06, 0.0005)}\n",
    "\n",
    "param_low = [float(item[0]) for key, item in prior_dict.items()]\n",
    "param_high = [float(item[1]) for key, item in prior_dict.items()]\n",
    "prior = utils.BoxUniform(low=torch.tensor(param_low), high=torch.tensor(param_high))\n",
    "\n",
    "theta_samples = prior.sample((num_simulations,))\n",
    "\n",
    "def dill_save(save_object, save_prefix, save_suffix, save_path, extension='.pkl'):\n",
    "    save_file = open(save_path + save_prefix + '_' + save_suffix + extension, 'wb')\n",
    "    dill.dump(save_object, save_file)\n",
    "    save_file.close()\n",
    "\n",
    "os.mkdir(save_path)\n",
    "os.mkdir(save_path + 'data/')\n",
    "dill_save(params_fname, 'params_fname', save_suffix, save_path)\n",
    "dill_save(prior, 'prior', save_suffix, save_path)\n",
    "dill_save(prior_dict, 'prior_dict', save_suffix, save_path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HNNSimulator:\n",
    "    def __init__(self, params_fname, prior_dict):\n",
    "        if 'DISPLAY' in os.environ:\n",
    "            del os.environ['DISPLAY']\n",
    "            \n",
    "        import hnn_core\n",
    "        from hnn_core import simulate_dipole, Network, read_params, JoblibBackend, MPIBackend\n",
    "        self.params = read_params(params_fname)\n",
    "        #self.params['tstop'] = 30\n",
    "        self.param_names = list(prior_dict.keys())\n",
    "\n",
    "    def __call__(self, new_param_values):\n",
    "        new_params = dict(zip(self.param_names, new_param_values.detach().cpu().numpy()))\n",
    "        self.params.update(new_params)\n",
    "        self.params['numspikes_evprox_1'] = self.params['numspikes_evprox_1'].astype(int)\n",
    "        self.params['numspikes_evdist_1'] = self.params['numspikes_evdist_1'].astype(int)  \n",
    "\n",
    "        net = Network(self.params, add_drives_from_params=True)\n",
    "        with JoblibBackend(n_jobs=1):\n",
    "            dpl = simulate_dipole(net, n_trials=1)\n",
    "\n",
    "        summstats = dpl[0].data['agg']\n",
    "        spike_times = net.cell_response.spike_times\n",
    "        spike_gids = net.cell_response.spike_gids\n",
    "        spike_types = net.cell_response.spike_types\n",
    "        return summstats, spike_times, spike_gids, spike_types\n",
    "\n",
    "#sbi_simulator, sbi_prior = prepare_for_sbi(hnn_simulator, prior)\n",
    "#params = read_params(params_fname)\n",
    "def run_simulator(theta, params_fname, prior_dict, sim_idx):\n",
    "    hnn_simulator = HNNSimulator(params_fname,prior_dict)\n",
    "    dpl = hnn_simulator(theta)\n",
    "    return dpl\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "client.cluster.scale(500)\n",
    "def batch(seq, theta_samples, params_fname, prior_dict):\n",
    "    res_list= []\n",
    "    for sim_idx in seq:\n",
    "        res = dask.delayed(run_simulator)(theta_samples[sim_idx,:], params_fname, prior_dict, sim_idx)\n",
    "        res_list.append(res)\n",
    "        \n",
    "        \n",
    "\n",
    "    final_res = dask.compute(*res_list)\n",
    "    dpl_list = np.stack([final_res[idx][0] for idx in range(len(seq))])\n",
    "    \n",
    "    dpl_name = save_path + 'data/dpl_' + save_suffix + '_sim{}-{}'.format(seq[0],seq[-1]) + '.csv'\n",
    "    param_name = save_path + 'data/theta_' + save_suffix + '_sim{}-{}'.format(seq[0],seq[-1]) + '.csv'\n",
    "\n",
    "    np.savetxt(dpl_name, dpl_list, delimiter=',')\n",
    "    np.savetxt(param_name, theta_samples[seq,:].detach().cpu().numpy(), delimiter=',')\n",
    "    \n",
    "    #dill_save([final_res[idx][1] for idx in range(len(seq))], 'data/spike_times', save_suffix + '_sim{}-{}'.format(seq[0],seq[-1]), save_path)\n",
    "    #dill_save([final_res[idx][2] for idx in range(len(seq))], 'data/spike_gids', save_suffix + '_sim{}-{}'.format(seq[0],seq[-1]), save_path)\n",
    "\n",
    "batches = []\n",
    "step_size = 500\n",
    "for i in range(0, num_simulations, step_size):\n",
    "    print(i)\n",
    "    batch(list(range(i, i + step_size)),theta_samples, params_fname, prior_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sbi)",
   "language": "python",
   "name": "sbi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
