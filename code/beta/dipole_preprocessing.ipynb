{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Dipole Preprocessing\n",
    "Loading and modifying prerun simulations for dimensionality reduction and/or inference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ntolley/anaconda3/lib/python3.7/site-packages/elephant/pandas_bridge.py:22: DeprecationWarning: pandas_bridge module will be removed in Elephant v0.8.x\n  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if 'DISPLAY' in os.environ:\n",
    "    del os.environ['DISPLAY']\n",
    "import torch\n",
    "import dill\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sbi.utils as utils\n",
    "from sbi.inference.base import infer\n",
    "import multiprocessing\n",
    "import datetime\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "from scipy import interpolate\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import spike_train_functions\n",
    "import hnn_simnets_functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name ='beta_event_basket_ampa_t100000_02222021_131840'\n",
    "data_path = '../../data/beta/prerun_simulations/' + save_name + '/'\n",
    "\n",
    "params_fname_file = open(data_path + 'params_fname_' + save_name + '.pkl', 'rb')\n",
    "params_fname = dill.load(params_fname_file)\n",
    "params_fname_file.close()\n",
    "# params_fname = '../../data/beta/params/beta_param.param'\n",
    "\n",
    "dpl_files = sorted(glob.glob(data_path + 'data/*dpl*sim*'))\n",
    "theta_files = sorted(glob.glob(data_path + 'data/*theta*sim*'))\n",
    "# spike_gids_files = sorted(glob.glob(data_path + 'data/spike_gids*'))\n",
    "# spike_times_files = sorted(glob.glob(data_path + 'data/spike_times*'))\n",
    "# spike_types_files = sorted(glob.glob(data_path + 'data/spike_types*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load downsampled data\n",
    "downsample = 100\n",
    "dpl_all = np.vstack([np.loadtxt(dpl_files[file_idx],delimiter=',')[:,::downsample] for file_idx in range(len(dpl_files))])\n",
    "theta_all = np.vstack([np.loadtxt(theta_files[file_idx],delimiter=',') for file_idx in range(len(theta_files))])\n",
    "\n",
    "sim_length = 500 # in ms\n",
    "\n",
    "sim_times_all = np.linspace(0,sim_length, dpl_all.shape[1])\n",
    "\n",
    "#Filter to subthreshold events\n",
    "threshold = 100000\n",
    "threshold_mask  = np.all(np.abs(dpl_all) < threshold, axis=1)\n",
    "dpl_subthreshold = dpl_all[threshold_mask,:]\n",
    "theta = theta_all[threshold_mask,:]\n",
    "\n",
    "#Crop simulation data \n",
    "sim_tstart, sim_t_end = 50, 500\n",
    "sim_times_mask = np.logical_and(sim_times_all > sim_tstart, sim_times_all < sim_t_end)\n",
    "sim_times = sim_times_all[sim_times_mask]\n",
    "dpl = dpl_subthreshold[:, sim_times_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpl_preprocessed_100x_downsample{\n",
    "    'dpl': dpl,\n",
    "    'theta': theta, \n",
    "    'sim_times': sim_times,\n",
    "    'threshold': threshold,\n",
    "    'subset_included': np.where(threshold_mask)\n",
    "}\n",
    "\n",
    "save_file = open(data_path + 'dpl_preprocessed_100x_downsample.pkl', 'wb')\n",
    "dill.dump(posterior_files, save_file)\n",
    "save_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}