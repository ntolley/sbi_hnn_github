{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Dipole autoencoding\n",
    "Testing autoencoding of simulated current dipoles"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ntolley/anaconda3/lib/python3.7/site-packages/elephant/pandas_bridge.py:22: DeprecationWarning: pandas_bridge module will be removed in Elephant v0.8.x\n  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import dill\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import spike_train_functions\n",
    "import hnn_simnets_functions\n",
    "import numba\n",
    "import sbi_functions\n",
    "import umap\n",
    "import umap.plot\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = 'beta_event_expanse_t100000_02142021_182526'\n",
    "data_path = '/home/ntolley/Jones_Lab/sbi_hnn/data/beta/prerun_simulations/' + save_name + '/'\n",
    "dpl_all = np.loadtxt(data_path + 'dpl_100x_downsample.csv', delimiter=',')\n",
    "theta_all = np.loadtxt(data_path + 'theta_all.csv', delimiter=',')\n",
    "sim_length = 500 # in ms\n",
    "sim_times_all = np.linspace(0,sim_length, dpl_all.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.as_tensor(dpl_all).to(device).unsqueeze(0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "lr=1e-3\n",
    "weight_decay=1e-2\n",
    "dropout=0.8\n",
    "window_size=10\n",
    "input_size = training_set.shape[2] \n",
    "hidden_size = 10\n",
    "step_size = 1\n",
    "latent_dim = 3\n",
    "layer_size = [10,latent_dim]\n",
    "max_epochs=1000\n",
    "\n",
    "#Define model\n",
    "model =  sbi_functions.autoencoder_gru(input_size=input_size, hidden_size=hidden_size, layer_size=layer_size, window_size=window_size, step_size=step_size, dropout=dropout, device=device).to(device)\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loss_array = []\n",
    "model.train()\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    output, latent = model(training_set)\n",
    "    train_loss = criterion(output, training_set)\n",
    "    train_loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "\n",
    "    train_loss.append(train_loss.item())\n",
    "    print('*',end='')\n",
    "    #Print Loss\n",
    "    if (epoch+1)%1 == 0:\n",
    "        print('')\n",
    "        print('Epoch: {}/{} ...'.format(epoch+1, max_epochs), end=' ')\n",
    "        print('Train Loss: ' + str(np.mean(train_loss)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}