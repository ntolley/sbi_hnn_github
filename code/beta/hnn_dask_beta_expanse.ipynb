{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://198.202.103.207:34397</li>\n",
       "  <li><b>Dashboard: </b><a href='http://198.202.103.207:8787/status' target='_blank'>http://198.202.103.207:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://198.202.103.207:34397' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "if 'DISPLAY' in os.environ:\n",
    "    del os.environ['DISPLAY']\n",
    "    \n",
    "user_env = os.environ['USER']\n",
    "job_env = os.environ['SLURM_JOB_ID']\n",
    "\n",
    "import numpy as np\n",
    "import dill\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import dask\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import hnn_core\n",
    "from hnn_core import simulate_dipole, Network, read_params, JoblibBackend, MPIBackend\n",
    "import sbi.utils as utils\n",
    "import datetime\n",
    "import dask.bag as db\n",
    "#time_stamp = datetime.datetime.now().strftime(\"%m%d%Y_%H%M%S\")\n",
    "#import logging\n",
    "#logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)\n",
    "\n",
    "\n",
    "cluster = SLURMCluster(cores = 50,\n",
    "                       processes=50,\n",
    "                       queue='compute',\n",
    "                       memory=\"200GB\",\n",
    "                       walltime=\"48:00:00\",\n",
    "                       job_extra=['-A csd403', '--nodes=1']\n",
    "                       \n",
    ")\n",
    "# local_directory = '/scratch/' + user_env +'/job_' + job_env\n",
    "#'--cpus-per-task=1'\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulations = 100000\n",
    "time_stamp = datetime.datetime.now().strftime(\"%m%d%Y_%H%M%S\")\n",
    "\n",
    "params_fname = '../../data/beta/params/beta_param.param'\n",
    "save_suffix = 'beta_event_t100000' + '_' + time_stamp\n",
    "save_path = '../../data/beta/prerun_simulations/' + save_suffix  + '/'\n",
    "\n",
    "prior_dict = {'dipole_scalefctr': (60000, 200000),\n",
    " 't_evprox_1': (225, 255),\n",
    " 'sigma_t_evprox_1': (10, 50),\n",
    " 'numspikes_evprox_1': (1, 20),\n",
    " 'gbar_evprox_1_L2Pyr_ampa': (1e-06, 0.0005),\n",
    " 'gbar_evprox_1_L5Pyr_ampa': (1e-06, 0.0005),\n",
    " 't_evdist_1': (235, 255),\n",
    " 'sigma_t_evdist_1': (5, 30),\n",
    " 'numspikes_evdist_1': (1, 20),\n",
    " 'gbar_evdist_1_L2Pyr_ampa': (1e-06, 0.0005),\n",
    " 'gbar_evdist_1_L5Pyr_ampa': (1e-06, 0.0005)}\n",
    "\n",
    "param_low = [float(item[0]) for key, item in prior_dict.items()]\n",
    "param_high = [float(item[1]) for key, item in prior_dict.items()]\n",
    "prior = utils.BoxUniform(low=torch.tensor(param_low), high=torch.tensor(param_high))\n",
    "\n",
    "theta_samples = prior.sample((num_simulations,))\n",
    "\n",
    "def dill_save(save_object, save_prefix, save_suffix, save_path, extension='.pkl'):\n",
    "    save_file = open(save_path + save_prefix + '_' + save_suffix + extension, 'wb')\n",
    "    dill.dump(save_object, save_file)\n",
    "    save_file.close()\n",
    "\n",
    "os.mkdir(save_path)\n",
    "os.mkdir(save_path + 'data/')\n",
    "dill_save(params_fname, 'params_fname', save_suffix, save_path)\n",
    "dill_save(prior, 'prior', save_suffix, save_path)\n",
    "dill_save(prior_dict, 'prior_dict', save_suffix, save_path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HNNSimulator:\n",
    "    def __init__(self, params_fname, prior_dict):\n",
    "        if 'DISPLAY' in os.environ:\n",
    "            del os.environ['DISPLAY']\n",
    "            \n",
    "        import hnn_core\n",
    "        from hnn_core import simulate_dipole, Network, read_params, JoblibBackend, MPIBackend\n",
    "        self.params = read_params(params_fname)\n",
    "        #self.params['tstop'] = 30\n",
    "        self.param_names = list(prior_dict.keys())\n",
    "\n",
    "    def __call__(self, new_param_values):\n",
    "        new_params = dict(zip(self.param_names, new_param_values.detach().cpu().numpy()))\n",
    "        self.params.update(new_params)\n",
    "\n",
    "        net = Network(self.params)\n",
    "        with JoblibBackend(n_jobs=1):\n",
    "            dpl = simulate_dipole(net, n_trials=1)\n",
    "\n",
    "        summstats = dpl[0].data['agg']\n",
    "        spike_times = net.cell_response.spike_times\n",
    "        spike_gids = net.cell_response.spike_gids\n",
    "        spike_types = net.cell_response.spike_types\n",
    "        return summstats, spike_times, spike_gids, spike_types\n",
    "\n",
    "#sbi_simulator, sbi_prior = prepare_for_sbi(hnn_simulator, prior)\n",
    "#params = read_params(params_fname)\n",
    "def run_simulator(theta, params_fname, prior_dict, sim_idx):\n",
    "    hnn_simulator = HNNSimulator(params_fname,prior_dict)\n",
    "    dpl = hnn_simulator(theta)\n",
    "    return dpl\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "22000\n",
      "22500\n",
      "23000\n",
      "23500\n",
      "24000\n",
      "24500\n",
      "25000\n",
      "25500\n",
      "26000\n",
      "26500\n",
      "27000\n",
      "27500\n",
      "28000\n",
      "28500\n",
      "29000\n",
      "29500\n",
      "30000\n",
      "30500\n",
      "31000\n",
      "31500\n",
      "32000\n",
      "32500\n",
      "33000\n",
      "33500\n",
      "34000\n",
      "34500\n",
      "35000\n",
      "35500\n",
      "36000\n",
      "36500\n",
      "37000\n",
      "37500\n",
      "38000\n",
      "38500\n",
      "39000\n",
      "39500\n",
      "40000\n",
      "40500\n",
      "41000\n",
      "41500\n",
      "42000\n",
      "42500\n",
      "43000\n",
      "43500\n",
      "44000\n",
      "44500\n",
      "45000\n",
      "45500\n",
      "46000\n",
      "46500\n",
      "47000\n",
      "47500\n",
      "48000\n",
      "48500\n",
      "49000\n",
      "49500\n",
      "50000\n",
      "50500\n",
      "51000\n",
      "51500\n",
      "52000\n",
      "52500\n",
      "53000\n",
      "53500\n",
      "54000\n",
      "54500\n",
      "55000\n",
      "55500\n",
      "56000\n",
      "56500\n",
      "57000\n",
      "57500\n",
      "58000\n",
      "58500\n",
      "59000\n",
      "59500\n",
      "60000\n",
      "60500\n",
      "61000\n",
      "61500\n",
      "62000\n",
      "62500\n",
      "63000\n",
      "63500\n",
      "64000\n",
      "64500\n",
      "65000\n",
      "65500\n",
      "66000\n",
      "66500\n",
      "67000\n",
      "67500\n",
      "68000\n",
      "68500\n",
      "69000\n",
      "69500\n",
      "70000\n",
      "70500\n",
      "71000\n",
      "71500\n",
      "72000\n",
      "72500\n",
      "73000\n"
     ]
    }
   ],
   "source": [
    "client.cluster.scale(500)\n",
    "def batch(seq, theta_samples, params_fname, prior_dict):\n",
    "    res_list= []\n",
    "    for sim_idx in seq:\n",
    "        res = dask.delayed(run_simulator)(theta_samples[sim_idx,:], params_fname, prior_dict, sim_idx)\n",
    "        res_list.append(res)\n",
    "        \n",
    "        \n",
    "\n",
    "    final_res = dask.compute(*res_list)\n",
    "    dpl_list = np.stack([final_res[idx][0] for idx in range(len(seq))])\n",
    "    \n",
    "    dpl_name = save_path + 'data/dpl_' + save_suffix + '_sim{}-{}'.format(seq[0],seq[-1]) + '.csv'\n",
    "    param_name = save_path + 'data/theta_' + save_suffix + '_sim{}-{}'.format(seq[0],seq[-1]) + '.csv'\n",
    "\n",
    "    np.savetxt(dpl_name, dpl_list, delimiter=',')\n",
    "    np.savetxt(param_name, theta_samples[seq,:].detach().cpu().numpy(), delimiter=',')\n",
    "    \n",
    "    #dill_save([final_res[idx][1] for idx in range(len(seq))], 'data/spike_times', save_suffix + '_sim{}-{}'.format(seq[0],seq[-1]), save_path)\n",
    "    #dill_save([final_res[idx][2] for idx in range(len(seq))], 'data/spike_gids', save_suffix + '_sim{}-{}'.format(seq[0],seq[-1]), save_path)\n",
    "\n",
    "batches = []\n",
    "step_size = 500\n",
    "for i in range(0, num_simulations, step_size):\n",
    "    print(i)\n",
    "    batch(list(range(i, i + step_size)),theta_samples, params_fname, prior_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sbi)",
   "language": "python",
   "name": "sbi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
