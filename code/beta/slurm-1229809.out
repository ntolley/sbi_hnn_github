distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:41301'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:40477'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:37151'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:45679'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:42515'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:44443'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:44827'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:43065'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:39691'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:44427'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:42051'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:46339'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:38495'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:38857'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:45419'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:43611'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:41605'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:44661'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:41767'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:36869'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:43599'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:40669'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:46651'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:42015'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:37091'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:39399'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:45933'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:41757'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:41901'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:44073'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:36161'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:43845'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:36795'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:37737'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:41237'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:33437'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:42027'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:34925'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:41349'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:33915'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:36623'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:33005'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:33207'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:41981'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:36775'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:43231'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:44759'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:38451'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:41941'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:44503'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:45247'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:34201'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:41289'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:46973'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:35033'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:42697'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:45471'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:36777'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:37643'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:37219'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:45611'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:37107'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:39471'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:42593'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:45375'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:38869'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:37225'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:34423'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:40283'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:45429'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:46145'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:43163'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:37499'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:46115'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:39473'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:34927'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:42087'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:39543'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:32927'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:47075'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:37775'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:47093'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:34699'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:41163'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:39843'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:34225'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:32961'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:43947'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:34035'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:36879'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:45689'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:34315'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:42853'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:46449'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:45569'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:45981'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:34567'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:41875'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:38559'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.72:34601'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:34843
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:36229
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:45205
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:34843
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:41243
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:36229
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:45727
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:45205
distributed.worker - INFO -          dashboard at:       198.202.103.72:42407
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:41243
distributed.worker - INFO -          dashboard at:       198.202.103.72:35169
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:45727
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:40265
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:32985
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:36409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO -          dashboard at:       198.202.103.72:41177
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:41943
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:       198.202.103.72:39965
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:40265
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:32985
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:36409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO -          dashboard at:       198.202.103.72:41907
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:41943
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:35061
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO -          dashboard at:       198.202.103.72:40649
distributed.worker - INFO -          dashboard at:       198.202.103.72:43955
distributed.worker - INFO -          dashboard at:       198.202.103.72:33441
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:35893
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:       198.202.103.72:44821
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:35061
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:35893
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -          dashboard at:       198.202.103.72:45025
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:       198.202.103.72:40185
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-f0ntsuu6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-_2wa_nnk
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-95g2ogs6
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-0u5jd2kr
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-rworlmwt
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-w8mbn0vi
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-_d8xwj6j
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-44pycq6_
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-p0ia5ri1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-4zepls9b
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-uym342n5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:45765
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:45765
distributed.worker - INFO -          dashboard at:       198.202.103.72:36583
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-m9odv6wb
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:36511
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:36511
distributed.worker - INFO -          dashboard at:       198.202.103.72:38295
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9ubez2zg
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:43795
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:43795
distributed.worker - INFO -          dashboard at:       198.202.103.72:44945
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-73z3vt4v
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:42425
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:42425
distributed.worker - INFO -          dashboard at:       198.202.103.72:36431
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-pfthsmg3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:33435
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:33435
distributed.worker - INFO -          dashboard at:       198.202.103.72:39971
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-nj9o_x4j
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:46417
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:46417
distributed.worker - INFO -          dashboard at:       198.202.103.72:40861
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-aevg41nf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:36065
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:36065
distributed.worker - INFO -          dashboard at:       198.202.103.72:43573
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-tj255_c9
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:40799
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:40799
distributed.worker - INFO -          dashboard at:       198.202.103.72:34851
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-iozum5m5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:35877
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:35877
distributed.worker - INFO -          dashboard at:       198.202.103.72:35481
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-19yp62e0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:38649
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:33045
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:38649
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:33045
distributed.worker - INFO -          dashboard at:       198.202.103.72:34271
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO -          dashboard at:       198.202.103.72:36507
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-b3h_lczg
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-l32klwei
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:40869
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:40869
distributed.worker - INFO -          dashboard at:       198.202.103.72:39283
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8cz1zud7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:46845
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:46845
distributed.worker - INFO -          dashboard at:       198.202.103.72:35585
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-f1rn6__4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:42227
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:42227
distributed.worker - INFO -          dashboard at:       198.202.103.72:41575
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-675pboqj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:35693
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:35693
distributed.worker - INFO -          dashboard at:       198.202.103.72:44871
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-jbiz127d
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:43345
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:43345
distributed.worker - INFO -          dashboard at:       198.202.103.72:34739
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-i0g9itss
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:44887
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:44887
distributed.worker - INFO -          dashboard at:       198.202.103.72:41939
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-i_nzd8zk
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:42367
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:42367
distributed.worker - INFO -          dashboard at:       198.202.103.72:40149
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-6v6r7rw0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:38803
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:38803
distributed.worker - INFO -          dashboard at:       198.202.103.72:38141
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-d_v91iuk
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:40895
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:40895
distributed.worker - INFO -          dashboard at:       198.202.103.72:41887
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-law5ofb1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:37003
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:37003
distributed.worker - INFO -          dashboard at:       198.202.103.72:34547
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-na99y3kx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:40585
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:40585
distributed.worker - INFO -          dashboard at:       198.202.103.72:35049
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-nal5ai14
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:35769
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:35769
distributed.worker - INFO -          dashboard at:       198.202.103.72:42203
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1bl83gch
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:37805
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:37805
distributed.worker - INFO -          dashboard at:       198.202.103.72:37093
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-lfz5s7sn
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:41637
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:41637
distributed.worker - INFO -          dashboard at:       198.202.103.72:37121
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5txfn92s
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:45991
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:45991
distributed.worker - INFO -          dashboard at:       198.202.103.72:38437
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ya1h633y
distributed.worker - INFO - -------------------------------------------------
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:42441
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:42441
distributed.worker - INFO -          dashboard at:       198.202.103.72:40489
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-rywmdrq0
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:44283
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:44283
distributed.worker - INFO -          dashboard at:       198.202.103.72:33253
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-yin9n5e1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:33685
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:33685
distributed.worker - INFO -          dashboard at:       198.202.103.72:41167
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-is8ksdv3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:35321
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:35321
distributed.worker - INFO -          dashboard at:       198.202.103.72:42699
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:34475
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-byco8qzh
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:34475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:       198.202.103.72:40705
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-bm7ccwf7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:43569
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:43569
distributed.worker - INFO -          dashboard at:       198.202.103.72:36373
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-f5o_4q35
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:39545
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:39545
distributed.worker - INFO -          dashboard at:       198.202.103.72:42997
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-00csx0lj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:36741
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:36741
distributed.worker - INFO -          dashboard at:       198.202.103.72:38739
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ywqbbsm0
distributed.worker - INFO - -------------------------------------------------
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:33213
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:33213
distributed.worker - INFO -          dashboard at:       198.202.103.72:34981
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-qeb6aa8t
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:44233
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:44233
distributed.worker - INFO -          dashboard at:       198.202.103.72:36145
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fpuc_jse
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:42551
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:42551
distributed.worker - INFO -          dashboard at:       198.202.103.72:39841
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1mxukk38
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:39069
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:39069
distributed.worker - INFO -          dashboard at:       198.202.103.72:41257
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9yisw9df
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:42965
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:42965
distributed.worker - INFO -          dashboard at:       198.202.103.72:38723
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-quw1wfek
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:39423
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:39423
distributed.worker - INFO -          dashboard at:       198.202.103.72:43787
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-au3dqmgu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:35087
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:35087
distributed.worker - INFO -          dashboard at:       198.202.103.72:46617
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:41983
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:41983
distributed.worker - INFO -          dashboard at:       198.202.103.72:34369
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-f4ew6o9e
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-7grhfagv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:35499
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:35499
distributed.worker - INFO -          dashboard at:       198.202.103.72:41553
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-t9ioz7kw
distributed.worker - INFO - -------------------------------------------------
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:43009
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:43009
distributed.worker - INFO -          dashboard at:       198.202.103.72:34829
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-dnmzd01e
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:45037
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:45037
distributed.worker - INFO -          dashboard at:       198.202.103.72:46493
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-_qv27ah8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:33519
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:33519
distributed.worker - INFO -          dashboard at:       198.202.103.72:40151
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-v_30v9jn
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:46101
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:46101
distributed.worker - INFO -          dashboard at:       198.202.103.72:40519
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-vza6_gux
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:43333
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:43333
distributed.worker - INFO -          dashboard at:       198.202.103.72:46685
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.worker - INFO - -------------------------------------------------
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-dhyby8fy
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:38629
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:38629
distributed.worker - INFO -          dashboard at:       198.202.103.72:36059
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-f3zutwgn
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:39897
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:39897
distributed.worker - INFO -          dashboard at:       198.202.103.72:37771
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-vaiy5r94
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:42687
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:42687
distributed.worker - INFO -          dashboard at:       198.202.103.72:34295
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-njzbcwd9
distributed.worker - INFO - -------------------------------------------------
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:34471
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:34471
distributed.worker - INFO -          dashboard at:       198.202.103.72:37671
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-lv051yni
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:43189
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:43189
distributed.worker - INFO -          dashboard at:       198.202.103.72:42813
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-0mjnxye3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:36823
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:36823
distributed.worker - INFO -          dashboard at:       198.202.103.72:45885
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-bnbq_ozt
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:33007
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:35063
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:33007
distributed.worker - INFO -          dashboard at:       198.202.103.72:45153
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:35063
distributed.worker - INFO -          dashboard at:       198.202.103.72:45697
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-8llh8xdq
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-knhcb78m
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:39935
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:39935
distributed.worker - INFO -          dashboard at:       198.202.103.72:41811
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-cyz8alit
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:38771
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:38771
distributed.worker - INFO -          dashboard at:       198.202.103.72:45355
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-e5e2mqqb
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:36061
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:36061
distributed.worker - INFO -          dashboard at:       198.202.103.72:36899
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-6ybklh1l
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:39881
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:39881
distributed.worker - INFO -          dashboard at:       198.202.103.72:39653
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-9psxzuio
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:35927
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:35927
distributed.worker - INFO -          dashboard at:       198.202.103.72:44403
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-tl75jjb6
distributed.worker - INFO - -------------------------------------------------
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:38561
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:38561
distributed.worker - INFO -          dashboard at:       198.202.103.72:38329
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ynzujmpd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:38347
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:38347
distributed.worker - INFO -          dashboard at:       198.202.103.72:38979
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-trdu2qsf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:33225
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:33225
distributed.worker - INFO -          dashboard at:       198.202.103.72:37191
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-hc591zxx
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:42065
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:42065
distributed.worker - INFO -          dashboard at:       198.202.103.72:42219
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-p3sg7u03
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:39417
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:39417
distributed.worker - INFO -          dashboard at:       198.202.103.72:46901
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-5zmoe1dw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:44967
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:44967
distributed.worker - INFO -          dashboard at:       198.202.103.72:46731
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-svz04l71
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:42667
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:42667
distributed.worker - INFO -          dashboard at:       198.202.103.72:33965
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-y09je_z2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:36713
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:36713
distributed.worker - INFO -          dashboard at:       198.202.103.72:33061
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-7pqilv9s
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:42951
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:42951
distributed.worker - INFO -          dashboard at:       198.202.103.72:40131
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-1qfndn7v
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:37841
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:37841
distributed.worker - INFO -          dashboard at:       198.202.103.72:40713
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-03ydtr32
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:40577
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:40577
distributed.worker - INFO -          dashboard at:       198.202.103.72:44261
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-idtr3z8x
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:43785
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:43785
distributed.worker - INFO -          dashboard at:       198.202.103.72:36889
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-lxsbc9jy
distributed.worker - INFO - -------------------------------------------------
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:42247
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:42247
distributed.worker - INFO -          dashboard at:       198.202.103.72:38421
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-6jeyvksh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:44111
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:44111
distributed.worker - INFO -          dashboard at:       198.202.103.72:46595
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-fdarh7gm
distributed.worker - INFO - -------------------------------------------------
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:41411
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:41411
distributed.worker - INFO -          dashboard at:       198.202.103.72:38835
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-zm4wvpvu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:39573
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:39573
distributed.worker - INFO -          dashboard at:       198.202.103.72:35119
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-x93kr7ol
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:42365
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:42365
distributed.worker - INFO -          dashboard at:       198.202.103.72:42321
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-piw2krrs
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:45661
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:45661
distributed.worker - INFO -          dashboard at:       198.202.103.72:36881
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-adyfuw8_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:46871
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:46871
distributed.worker - INFO -          dashboard at:       198.202.103.72:42675
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-i0xyqknc
distributed.worker - INFO - -------------------------------------------------
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:36291
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:36291
distributed.worker - INFO -          dashboard at:       198.202.103.72:45207
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-0_9nqjef
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:43571
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:43571
distributed.worker - INFO -          dashboard at:       198.202.103.72:34049
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-kb161ojp
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:33227
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:33227
distributed.worker - INFO -          dashboard at:       198.202.103.72:40121
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-jwi0hs7j
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:43937
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:43937
distributed.worker - INFO -          dashboard at:       198.202.103.72:46025
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-hmjgkl6p
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:42353
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:42353
distributed.worker - INFO -          dashboard at:       198.202.103.72:39091
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-ivzwd8s2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:36809
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:36809
distributed.worker - INFO -          dashboard at:       198.202.103.72:37227
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-a1tu3t0o
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:38199
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:38199
distributed.worker - INFO -          dashboard at:       198.202.103.72:34343
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-cwe7xb7h
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:44525
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:44525
distributed.worker - INFO -          dashboard at:       198.202.103.72:36659
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-mxm2o2r9
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.72:42995
distributed.worker - INFO -          Listening to: tcp://198.202.103.72:42995
distributed.worker - INFO -          dashboard at:       198.202.103.72:39385
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/beta/dask-worker-space/dask-worker-space/worker-yski41_i
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.234:40475
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
Warning: no DISPLAY environment variable.
--No graphics will be displayed.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 17.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 22.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 20.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 20.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 23.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 24.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 22.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 23.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 29.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 29.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 38.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 41.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 46.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 46.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 48.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 51.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 53.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 51.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 49.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 49.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 51.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 53.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 50.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 54.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 55.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 55.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 57.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 56.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 54.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 61.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 58.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 62.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 63.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 61.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 64.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 67.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 59.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 67.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 64.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 62.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 58.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 66.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 66.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 64.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 64.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 64.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 66.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 66.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 67.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 67.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 57.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 69.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 67.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 71.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 56.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 72.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 67.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 58.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 66.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 37.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 74.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 54.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 69.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 73.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 69.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 73.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 76.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 73.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 75.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 76.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 75.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 76.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 80.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 74.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 74.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 82.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 83.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 67.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 83.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 63.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 86.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 81.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 76.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 83.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 81.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 85.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 78.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 86.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 89.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 42.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 70.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 92.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 81.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 76.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 93.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 73.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 66.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 46.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 94.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 63.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 85.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 29.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 90.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 82.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 74.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 81.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 48.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 36.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 88.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 59.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 37.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 29.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 54.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 82.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 63.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 53.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 46.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 57.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 89.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 48.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 62.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 22.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 49.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 69.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 51.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 50.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 94.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 51.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 24.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 38.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 82.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 61.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 42.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 53.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 44.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 42.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 55.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 61.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 49.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 47.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 70.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 25.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 44.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 63.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 46.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 69.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 98.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 56.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 77.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 65.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 25.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Comm closed
distributed.batched - INFO - Batched Comm Closed: 
distributed.core - INFO - Event loop was unresponsive in Worker for 63.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 47.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 48.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 47.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 32.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 46.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 52.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Event loop was unresponsive in Worker for 23.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 93.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 56.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 37.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 39.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 50.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 57.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 33.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 105.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 25.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 51.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 60.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 58.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 35.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 51.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 43.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 73.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 17.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 58.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 22.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 54.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 42.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 36.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 39.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 61.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 62.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 58.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 29.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 60.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 43.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 76.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 47.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 49.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 33.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 38.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 59.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 17.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 9.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 24.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 29.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 22.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 30.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 36.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 35.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 33.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 35.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 32.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 38.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 41.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 40.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 45.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 43.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 43.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 32.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 43.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 43.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 48.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 46.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 38.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 49.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 46.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 48.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 51.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 53.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 47.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 49.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 55.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 44.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 48.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 50.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 53.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 46.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 55.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 53.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 58.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 52.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 53.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 55.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 55.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 57.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 49.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 49.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 48.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 61.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 53.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 60.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 56.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 58.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 62.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 49.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 56.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 61.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 57.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 53.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 54.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 57.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 56.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 68.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 62.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 62.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 48.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 61.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 43.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 46.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 72.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 8.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 69.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 62.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 53.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 59.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 33.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 55.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 48.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 29.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 57.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 36.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Comm closed
distributed.core - INFO - Event loop was unresponsive in Worker for 65.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 71.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 20.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 36.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 25.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 54.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 20.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 68.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 44.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 51.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 35.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 50.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 78.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 23.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 71.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 49.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 56.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 38.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 33.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 49.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 27.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 60.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 53.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 47.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 46.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 41.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 54.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 57.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 37.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 36.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 55.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 43.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 47.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 61.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 28.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 25.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 35.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 32.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 46.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 30.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 41.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 35.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 32.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 32.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 43.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 50.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 41.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 39.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 34.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 20.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 30.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 24.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 21.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 36.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 32.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 26.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 17.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 22.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 20.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 18.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 31.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 22.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 27.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 24.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 19.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 12.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 13.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 14.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 16.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 15.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 17.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 10.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 11.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 7.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2641' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2615' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2625' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-3097' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2665' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2619' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2661' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2465' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2470' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2645' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2687' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2662' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-3102' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-3088' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2696' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2715' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2701' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2610' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2471' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2628' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba30>>, <Task finished name='Task-2475' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba60>>, <Task finished name='Task-2652' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2830' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2698' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2670' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2695' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2633' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2634' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2436' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2629' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba30>>, <Task finished name='Task-2472' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2618' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2674' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2705' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 867, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/iostream.py", line 1140, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 491, in wait_for
    return fut.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 202, in read
    convert_stream_closed_error(self, e)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/tcp.py", line 122, in convert_stream_closed_error
    raise CommClosedError(
distributed.comm.core.CommClosedError: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x1554c7cd9c10>
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 702, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x1554c7caef70>
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 702, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x1554c7cc1550>
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 702, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x1554c7caef70>
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 702, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x1554c7cc61f0>
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 702, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x1554c7caef70>
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 702, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x1554c7caef70>
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 702, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x1554c7cc5f70>
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 702, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x1554c7cd9a60>
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 702, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x1554c7cc5f70>
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 702, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x1554c7cd9c10>
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 702, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x1554c7cc5f70>
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 702, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:44967
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:39881
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:39897
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:36061
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:37841
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:35321
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:35063
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:44111
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:39935
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:35927
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:46101
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:33007
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:45037
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:43009
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:38629
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:33045
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:42367
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:42687
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:37805
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:44233
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:38649
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:41637
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:45991
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:38561
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:38803
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:42551
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:40585
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:40869
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:35769
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:35693
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2892' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:41983
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:39423
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:39069
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:40799
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:43569
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:42667
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:42227
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:43345
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:39545
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:36065
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:43937
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:33435
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2681' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:35877
tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x1554c9a5ba00>>, <Task finished name='Task-2710' coro=<Worker.heartbeat() done, defined at /home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py:930> exception=OSError('Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s')>)
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 319, in connect
    handshake = await asyncio.wait_for(comm.read(), time_left())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 741, in _run_callback
    ret = callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 765, in _discard_future_result
    future.result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 976, in heartbeat
    raise e
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 936, in heartbeat
    response = await retry_operation(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 384, in retry_operation
    return await retry(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/utils_comm.py", line 369, in retry
    return await coro()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 855, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 1006, in connect
    comm = await connect(
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/comm/core.py", line 324, in connect
    raise IOError(
OSError: Timed out during handshake while connecting to tcp://198.202.103.234:40475 after 10 s
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:46417
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:32985
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:41943
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:43795
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:34475
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:41243
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:45205
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:42425
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:35061
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:35893
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:36511
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:36229
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:45765
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:40265
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:36409
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:33685
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:45727
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:34843
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:37003
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x1554c7a321f0>
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 702, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:39573
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:46871
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:42065
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:42365
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:45661
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:42441
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:33227
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:43189
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:38199
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:42995
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:44283
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:35499
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:33225
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:36713
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:36823
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:44525
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:42353
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:36741
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:43333
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:42951
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:44887
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:43785
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:39417
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:33213
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:43571
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:40577
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:36809
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:46845
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:34471
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:41411
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:38771
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:42965
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:40895
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:42247
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x1554c7caef70>
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 702, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x1554c7caef70>
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 702, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
tornado.application - ERROR - Exception in callback <function Worker.__init__.<locals>.<lambda> at 0x1554c7caef70>
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 905, in _run
    return self.callback()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/worker.py", line 702, in <lambda>
    lambda: self.batched_stream.send({"op": "keep-alive"}), 60000
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/batched.py", line 136, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.core - INFO - Event loop was unresponsive in Nanny for 3.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 3.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 3.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:36291
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:38347
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.worker - INFO - Stopping worker at tcp://198.202.103.72:33519
distributed.nanny - INFO - Worker closed
joblib will run over 1 jobs
Loading custom mechanism files from /home/ntolley/.local/lib/python3.8/site-packages/hnn_core/mod/x86_64/.libs/libnrnmech.so
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
joblib will run over 1 jobs
Building the NEURON model
[Done]
running trial 1 on 1 cores
Simulation time: 0.05 ms...
Simulation time: 10.0 ms...
Simulation time: 20.0 ms...
Simulation time: 30.0 ms...
Simulation time: 40.0 ms...
Simulation time: 50.0 ms...
Simulation time: 60.0 ms...
Simulation time: 70.0 ms...
Simulation time: 80.0 ms...
Simulation time: 90.0 ms...
Simulation time: 100.0 ms...
Simulation time: 110.0 ms...
Simulation time: 120.0 ms...
Simulation time: 130.0 ms...
Simulation time: 140.0 ms...
Simulation time: 150.0 ms...
Simulation time: 160.0 ms...
Simulation time: 170.0 ms...
Simulation time: 180.0 ms...
Simulation time: 190.0 ms...
Simulation time: 200.0 ms...
Simulation time: 210.0 ms...
Simulation time: 220.0 ms...
Simulation time: 230.0 ms...
Simulation time: 240.0 ms...
Simulation time: 250.0 ms...
Simulation time: 260.0 ms...
Simulation time: 270.0 ms...
Simulation time: 280.0 ms...
Simulation time: 290.0 ms...
Simulation time: 300.0 ms...
Simulation time: 310.0 ms...
Simulation time: 320.0 ms...
Simulation time: 330.0 ms...
Simulation time: 340.0 ms...
Simulation time: 350.0 ms...
Simulation time: 360.0 ms...
Simulation time: 370.0 ms...
Simulation time: 380.0 ms...
Simulation time: 390.0 ms...
Simulation time: 400.0 ms...
Simulation time: 410.0 ms...
Simulation time: 420.0 ms...
Simulation time: 430.0 ms...
Simulation time: 440.0 ms...
Simulation time: 450.0 ms...
Simulation time: 460.0 ms...
Simulation time: 470.0 ms...
Simulation time: 480.0 ms...
Simulation time: 490.0 ms...
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:46115'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:43947'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:46651'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:37225'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:41237'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:45429'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:38451'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:40669'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:41757'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:37219'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:34927'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:33207'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:47093'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:40477'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:41163'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:34201'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:45933'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:37737'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:44759'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:43611'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:45679'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:41981'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:41901'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:38869'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:44827'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:42593'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:36795'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:42027'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:32927'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:39399'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:46339'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:44427'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:46973'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:36161'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:42697'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:43599'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:41349'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:45419'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:42515'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:43065'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:39691'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:37091'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:43845'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:41289'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:39543'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:37107'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:41605'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:45375'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:43231'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:36869'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:39471'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:45247'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:33915'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:41767'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:42051'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:38857'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:45981'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:44661'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:40283'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:33005'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:42087'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:37151'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:36879'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:45471'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:34225'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:46145'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:34315'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:45611'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:47075'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:34925'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:39843'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:42853'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:37643'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:38559'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:44443'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:46449'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:42015'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:41941'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:32961'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:41301'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:38495'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:41875'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:34567'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:43163'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:45569'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:37775'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:35033'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:33437'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:44503'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:39473'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:45689'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:34035'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:36623'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:34423'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:44073'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:34699'
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:34601'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:37499'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.72:36777'
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.234:40475
slurmstepd: error: *** JOB 1229809 ON exp-4-03 CANCELLED AT 2021-02-10T03:05:48 ***
