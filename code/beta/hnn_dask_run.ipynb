{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://172.20.207.31:46096</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.20.207.31:8787/status' target='_blank'>http://172.20.207.31:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.20.207.31:46096' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "if 'DISPLAY' in os.environ:\n",
    "    del os.environ['DISPLAY']\n",
    "\n",
    "import numpy as np\n",
    "import dill\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import dask\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import hnn_core\n",
    "from hnn_core import simulate_dipole, Network, read_params, JoblibBackend, MPIBackend\n",
    "import sbi.utils as utils\n",
    "import datetime\n",
    "import dask.bag as db\n",
    "time_stamp = datetime.datetime.now().strftime(\"%m%d%Y_%H%M%S\")\n",
    "#import logging\n",
    "#logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)\n",
    "\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "                       cores=46,\n",
    "                       processes=46,\n",
    "                       memory=\"100GB\",\n",
    "                       walltime=\"24:00:00\",\n",
    "                       job_extra=['-A carney-sjones-condo']\n",
    ")\n",
    "\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulations = 10000\n",
    "\n",
    "params_fname = '/users/ntolley/Jones_Lab/sbi_hnn_github/data/beta/params/beta_param.param'\n",
    "save_suffix = 'beta_event_t10000' + '_' + time_stamp\n",
    "save_path = '/users/ntolley/Jones_Lab/sbi_hnn_github/data/beta/prerun_simulations/' + save_suffix  + '/'\n",
    "\n",
    "prior_dict = {'dipole_scalefctr': (60000, 200000),\n",
    " 't_evprox_1': (225, 255),\n",
    " 'sigma_t_evprox_1': (10, 50),\n",
    " 'numspikes_evprox_1': (1, 20),\n",
    " 'gbar_evprox_1_L2Pyr_ampa': (1e-06, 0.0005),\n",
    " 'gbar_evprox_1_L5Pyr_ampa': (1e-06, 0.0005),\n",
    " 't_evdist_1': (235, 255),\n",
    " 'sigma_t_evdist_1': (5, 30),\n",
    " 'numspikes_evdist_1': (1, 20),\n",
    " 'gbar_evdist_1_L2Pyr_ampa': (1e-06, 0.0005),\n",
    " 'gbar_evdist_1_L5Pyr_ampa': (1e-06, 0.0005)}\n",
    "\n",
    "param_low = [float(item[0]) for key, item in prior_dict.items()]\n",
    "param_high = [float(item[1]) for key, item in prior_dict.items()]\n",
    "prior = utils.BoxUniform(low=torch.tensor(param_low), high=torch.tensor(param_high))\n",
    "\n",
    "theta_samples = prior.sample((num_simulations,))\n",
    "\n",
    "def dill_save(save_object, save_prefix, save_suffix, save_path, extension='.pkl'):\n",
    "    save_file = open(save_path + save_prefix + '_' + save_suffix + extension, 'wb')\n",
    "    dill.dump(save_object, save_file)\n",
    "    save_file.close()\n",
    "\n",
    "os.mkdir(save_path)\n",
    "os.mkdir(save_path + 'data/')\n",
    "dill_save(params_fname, 'params_fname', save_suffix, save_path)\n",
    "dill_save(prior, 'prior', save_suffix, save_path)\n",
    "dill_save(prior_dict, 'prior_dict', save_suffix, save_path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HNNSimulator:\n",
    "    def __init__(self, params_fname, prior_dict):\n",
    "        if 'DISPLAY' in os.environ:\n",
    "            del os.environ['DISPLAY']\n",
    "            \n",
    "        import hnn_core\n",
    "        from hnn_core import simulate_dipole, Network, read_params, JoblibBackend, MPIBackend\n",
    "        self.params = read_params(params_fname)\n",
    "        #self.params['tstop'] = 30\n",
    "        self.param_names = list(prior_dict.keys())\n",
    "\n",
    "    def __call__(self, new_param_values):\n",
    "        new_params = dict(zip(self.param_names, new_param_values.detach().cpu().numpy()))\n",
    "        self.params.update(new_params)\n",
    "\n",
    "        net = Network(self.params)\n",
    "        with JoblibBackend(n_jobs=1):\n",
    "            dpl = simulate_dipole(net, n_trials=1)\n",
    "\n",
    "        summstats = dpl[0].data['agg']\n",
    "        return summstats\n",
    "\n",
    "\n",
    "#sbi_simulator, sbi_prior = prepare_for_sbi(hnn_simulator, prior)\n",
    "#params = read_params(params_fname)\n",
    "def run_simulator(theta, params_fname, prior_dict, sim_idx):\n",
    "    hnn_simulator = HNNSimulator(params_fname,prior_dict)\n",
    "    dpl = hnn_simulator(theta)\n",
    "    return dpl\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "client.cluster.scale(100)\n",
    "def batch(seq, theta_samples, params_fname, prior_dict):\n",
    "    sub_results = []\n",
    "    for sim_idx in seq:\n",
    "        result = dask.delayed(run_simulator)(theta_samples[sim_idx,:], params_fname, prior_dict, sim_idx)\n",
    "        sub_results.append(result)\n",
    "    dpl_list = dask.compute(*sub_results)\n",
    "    dpl_list = np.stack(dpl_list)\n",
    "    \n",
    "    \n",
    "    dpl_name = save_path + 'data/' + save_suffix + '_dpl_sim{}-{}'.format(seq[0],seq[-1]) + '.csv'\n",
    "    param_name = save_path + 'data/' + save_suffix + '_theta_sim{}-{}'.format(seq[0],seq[-1]) + '.csv'\n",
    "\n",
    "    np.savetxt(dpl_name, dpl_list, delimiter=',')\n",
    "    np.savetxt(param_name, theta_samples[seq,:].detach().cpu().numpy(), delimiter=',')\n",
    "\n",
    "batches = []\n",
    "step_size = 1000\n",
    "for i in range(0, num_simulations, step_size):\n",
    "    print(i)\n",
    "    batch(list(range(i, i + step_size)),theta_samples, params_fname, prior_dict)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del client\n",
    "del cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi_kernel",
   "language": "python",
   "name": "sbi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
