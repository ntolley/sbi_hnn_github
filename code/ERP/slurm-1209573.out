distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:44747'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:38141'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:42267'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:40603'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:37077'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:42795'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:47065'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:35899'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:37037'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:44657'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:33801'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:44463'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:32837'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:39891'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:34991'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:36149'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:45075'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:32971'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:46693'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:35799'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:44401'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:42063'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:39749'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:46653'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:41249'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:38717'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:42625'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:42135'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:44213'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:42067'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:35481'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:33975'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:46739'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:39865'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:40389'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:38245'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:33609'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:45505'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:45905'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:34191'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:35363'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:44951'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:45495'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:45515'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:35441'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:34299'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:44599'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:38857'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:39603'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:34097'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:42413'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:37623'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:45861'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:34925'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:38877'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:35063'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:43123'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:33385'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:43105'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:35083'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:41539'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:46211'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:36495'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:45937'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:33161'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:38165'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:36565'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:42257'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:34433'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:43655'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:33731'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:35913'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:46997'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:45785'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:33667'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:42333'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:44767'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:45823'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:42115'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:45805'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:42721'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:42091'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:35929'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:38465'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:38393'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:42433'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:44407'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:33289'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:35129'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:46713'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:36053'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:39115'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:37161'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:42265'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:39549'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:41451'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:46559'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:46387'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:43999'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.65:44211'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:39197
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:39197
distributed.worker - INFO -          dashboard at:       198.202.102.65:33845
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:40267
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:42783
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:40267
distributed.worker - INFO -                Memory:                 1000.00 MB
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:39059
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5urlz9pf
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:41361
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:33699
distributed.worker - INFO -          dashboard at:       198.202.102.65:47025
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:45967
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:42783
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:45967
distributed.worker - INFO -          dashboard at:       198.202.102.65:35341
distributed.worker - INFO -          dashboard at:       198.202.102.65:38449
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:33699
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:39059
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:41361
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -          dashboard at:       198.202.102.65:36797
distributed.worker - INFO -          dashboard at:       198.202.102.65:33817
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -          dashboard at:       198.202.102.65:44229
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-y4q1i9av
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ta_u8p8_
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-996quiju
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-d5hgzki4
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6y2sgg1a
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8xa989rd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:37381
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:37381
distributed.worker - INFO -          dashboard at:       198.202.102.65:46503
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3ola3jj8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:33383
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:33383
distributed.worker - INFO -          dashboard at:       198.202.102.65:42675
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-eo53azgd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:37383
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:37383
distributed.worker - INFO -          dashboard at:       198.202.102.65:40871
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-acqgttx3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:35791
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:35791
distributed.worker - INFO -          dashboard at:       198.202.102.65:40133
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-elee6a37
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:43921
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:43921
distributed.worker - INFO -          dashboard at:       198.202.102.65:46311
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-eqpgut9s
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:45201
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:45201
distributed.worker - INFO -          dashboard at:       198.202.102.65:35365
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:36361
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:36361
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:       198.202.102.65:44613
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-yd5cb9ls
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gek8r8zx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:46939
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:46939
distributed.worker - INFO -          dashboard at:       198.202.102.65:40221
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-f5zpver7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:36127
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:36127
distributed.worker - INFO -          dashboard at:       198.202.102.65:35467
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_zfyare7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:39479
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:39479
distributed.worker - INFO -          dashboard at:       198.202.102.65:38535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-e_ravx_x
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:46673
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:46673
distributed.worker - INFO -          dashboard at:       198.202.102.65:34071
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5z3kijxj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:36121
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:36121
distributed.worker - INFO -          dashboard at:       198.202.102.65:36531
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-unag1h4v
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:41343
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:41343
distributed.worker - INFO -          dashboard at:       198.202.102.65:38681
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-e8p5fkw5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:36773
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:36773
distributed.worker - INFO -          dashboard at:       198.202.102.65:38443
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xjk714n1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:36161
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:36161
distributed.worker - INFO -          dashboard at:       198.202.102.65:34597
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-d8g3wjg9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:32849
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:32849
distributed.worker - INFO -          dashboard at:       198.202.102.65:40493
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-al1pfn6m
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:37027
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:37027
distributed.worker - INFO -          dashboard at:       198.202.102.65:38235
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0k4oibnl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:43611
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:43611
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:45907
distributed.worker - INFO -          dashboard at:       198.202.102.65:34633
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:45907
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:       198.202.102.65:33677
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ge1z_h70
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-t3s8pmzp
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:34255
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:34255
distributed.worker - INFO -          dashboard at:       198.202.102.65:45947
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4ikhlrxl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:40929
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:40929
distributed.worker - INFO -          dashboard at:       198.202.102.65:32993
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-mxw_9q3o
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:40985
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:40985
distributed.worker - INFO -          dashboard at:       198.202.102.65:43347
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-sismmcap
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:37683
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:37683
distributed.worker - INFO -          dashboard at:       198.202.102.65:46137
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-c5zy0iw0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:39295
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:39295
distributed.worker - INFO -          dashboard at:       198.202.102.65:41699
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:43791
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:43791
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:       198.202.102.65:40865
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gn16v1mb
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tqwao95w
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:39811
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:39811
distributed.worker - INFO -          dashboard at:       198.202.102.65:38079
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-cl1a1nb8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:35659
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:35659
distributed.worker - INFO -          dashboard at:       198.202.102.65:45539
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ec50sn8r
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:32913
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:32913
distributed.worker - INFO -          dashboard at:       198.202.102.65:43619
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-881lg43q
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:46781
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:46781
distributed.worker - INFO -          dashboard at:       198.202.102.65:45333
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qqdb500b
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:46841
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:46841
distributed.worker - INFO -          dashboard at:       198.202.102.65:40661
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-eremd5cx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:44781
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:44781
distributed.worker - INFO -          dashboard at:       198.202.102.65:34189
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-wpwyk6xu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:35257
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:35257
distributed.worker - INFO -          dashboard at:       198.202.102.65:46229
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:36843
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-kmieyj2l
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:36843
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:       198.202.102.65:46937
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-z5w_9q4a
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:38237
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:38237
distributed.worker - INFO -          dashboard at:       198.202.102.65:40401
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hg86romh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:36273
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:36273
distributed.worker - INFO -          dashboard at:       198.202.102.65:34603
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6zdh1b_e
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:36647
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:36647
distributed.worker - INFO -          dashboard at:       198.202.102.65:42747
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-grlzeaz7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:41933
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:41933
distributed.worker - INFO -          dashboard at:       198.202.102.65:38243
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-t468x_m2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:41363
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:41363
distributed.worker - INFO -          dashboard at:       198.202.102.65:44845
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0rytb3fc
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:39721
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:39721
distributed.worker - INFO -          dashboard at:       198.202.102.65:34719
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-q3m6_6rg
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:44031
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:44031
distributed.worker - INFO -          dashboard at:       198.202.102.65:38811
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zzm1v7lr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:36541
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:36541
distributed.worker - INFO -          dashboard at:       198.202.102.65:34831
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5axk8xgc
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:44753
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:44753
distributed.worker - INFO -          dashboard at:       198.202.102.65:42693
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-em2pfknd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:42387
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:42387
distributed.worker - INFO -          dashboard at:       198.202.102.65:36325
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-bfg7mc_6
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:44747'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:38141'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:42267'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:33383
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:40603'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:37077'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:42795'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:47065'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:33699
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:35899'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:39059
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:37037'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:43921
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:44657'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:41363
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:33801'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:44463'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:42783
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:44781
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:32837'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:46841
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:38123
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:39891'
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:38123
distributed.worker - INFO -          dashboard at:       198.202.102.65:47009
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0gedgbbx
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:34991'
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:43791
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:36149'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:46781
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:45075'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:36273
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:32971'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:46673
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:39811
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:46693'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:35799'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:32913
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:44401'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:42063'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:39749'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:41933
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:46653'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:41249'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:38717'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:42625'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:32849
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:37027
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:42135'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:44213'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:42067'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:35481'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:33975'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:46739'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:39865'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:40389'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:38245'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:38237
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:33609'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:45505'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:45905'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:35659
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:34191'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:44753
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:35363'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:44031
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:44951'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:45495'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:42387
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:45515'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:34255
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:35441'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:34299'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:44599'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:38857'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:36843
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:39603'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:36647
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:34097'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:42413'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:36541
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:37623'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:45861'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:36361
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:36773
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:34925'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:38877'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:41361
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:35063'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:36121
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:43123'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:36161
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:35791
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:33385'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:43105'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:35083'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:41539'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:37683
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:46211'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:39295
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:36495'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:41343
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:38123
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:45937'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:33161'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:37383
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:38165'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:36565'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:42257'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:45967
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:34433'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:43655'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:33731'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:39197
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:35913'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:46997'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:45785'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:33667'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:40985
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:42333'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:44767'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:45823'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:45201
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:42115'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:45805'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:40929
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:42721'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:42091'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:35929'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:38465'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:38393'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:42433'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:46939
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:40267
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:44407'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:33289'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:45907
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:35129'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:46713'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:37381
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:36053'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:43611
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:39115'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:37161'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:42265'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:36127
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:39549'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:41451'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:46559'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:46387'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:39479
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:43999'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:39721
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:35257
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.65:44211'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:34965
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:34965
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:46595
distributed.worker - INFO -          dashboard at:       198.202.102.65:34599
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:46595
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:       198.202.102.65:36305
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-g5k_2_hq
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vuyscd58
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:46595
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:34965
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:41929
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:41929
distributed.worker - INFO -          dashboard at:       198.202.102.65:47005
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-he21th3t
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:41929
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:34227
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:34227
distributed.worker - INFO -          dashboard at:       198.202.102.65:45335
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-i2nbhhxl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:42677
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:34881
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:42677
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:34881
distributed.worker - INFO -          dashboard at:       198.202.102.65:44521
distributed.worker - INFO -          dashboard at:       198.202.102.65:43241
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5urv_gvx
distributed.worker - INFO -                Memory:                 1000.00 MB
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:40049
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3ug6ccj8
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:34227
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:40049
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO -          dashboard at:       198.202.102.65:37417
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-jhtwcpou
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:34881
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:42677
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:40049
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:35819
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:35819
distributed.worker - INFO -          dashboard at:       198.202.102.65:38355
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-94244t61
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:36041
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:36041
distributed.worker - INFO -          dashboard at:       198.202.102.65:34061
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:42953
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-irvhmahe
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:42953
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:       198.202.102.65:45683
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:42349
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-jg2zro2w
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:42349
distributed.worker - INFO -          dashboard at:       198.202.102.65:37093
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0awjnr0_
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:35819
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:36041
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:47067
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:47067
distributed.worker - INFO -          dashboard at:       198.202.102.65:33779
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6zqg19wm
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:42349
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:42953
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:47067
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO - Stopping worker
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:33023
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:33023
distributed.worker - INFO -          dashboard at:       198.202.102.65:41535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-q5eipvus
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:41473
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:33023
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:41473
distributed.worker - INFO -          dashboard at:       198.202.102.65:35205
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-sitxx07_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.65:44637
distributed.worker - INFO -          Listening to: tcp://198.202.102.65:44637
distributed.worker - INFO -          dashboard at:       198.202.102.65:38043
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-dgxn9ujt
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:41473
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.65:44637
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5707 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5705 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5711 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5708 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5703 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5699 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5697 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5701 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5695 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5693 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5691 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5689 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5683 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5681 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5675 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5672 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5667 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5669 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5662 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5660 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5658 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5654 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5651 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5647 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5649 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5640 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5644 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5642 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5636 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5630 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5621 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5624 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5614 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5617 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5619 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5609 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5611 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5602 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5600 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5606 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5596 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5587 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5590 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5580 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5582 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5578 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5576 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5572 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5568 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5563 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5561 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5565 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5559 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5551 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5555 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5547 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5544 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5540 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5536 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5538 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5528 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5529 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5533 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5526 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5520 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5518 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5515 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5510 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5508 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5505 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5502 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5499 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5496 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5493 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5489 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5486 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5484 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5481 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5472 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5468 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5463 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5460 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5457 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5454 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5450 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5448 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5444 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5442 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5439 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5421 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5433 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5434 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5431 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5425 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5427 parent=5340 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=5422 parent=5340 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
    assert exitcode is not None
AssertionError
