distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:35629'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:46889'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:35713'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:40363'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:34577'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:44277'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:44647'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:43519'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:41881'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:46055'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:41385'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:39591'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:39007'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:41617'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:46689'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:47081'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:44065'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:33047'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:40483'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:44631'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:37817'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:34551'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:37549'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:42597'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:41025'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:44683'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:45587'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:41495'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:37179'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:41337'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:46475'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:41799'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:45835'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:46875'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:33703'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:42361'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:40839'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:34587'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:45293'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:43173'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:42745'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:34543'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:35729'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:37721'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:34917'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:46489'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:40657'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:35181'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:39521'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.56:41613'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:41005
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:41905
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:46457
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:41005
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:41905
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:43521
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:46457
distributed.worker - INFO -          dashboard at:       198.202.102.56:33937
distributed.worker - INFO -          dashboard at:       198.202.102.56:41483
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:43521
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO -          dashboard at:       198.202.102.56:37649
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:43411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:       198.202.102.56:45237
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:43411
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:       198.202.102.56:43085
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:43597
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:43597
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qbdhaj0p
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-i7sepxo4
distributed.worker - INFO -          dashboard at:       198.202.102.56:39427
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ko5vx59h
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tdpyvmhq
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-bq7a9ii6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-yn8i1ztv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:42439
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:42439
distributed.worker - INFO -          dashboard at:       198.202.102.56:41099
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-yk_8c4sw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:40551
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:40551
distributed.worker - INFO -          dashboard at:       198.202.102.56:35969
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-x3hfbcnk
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:39185
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:39185
distributed.worker - INFO -          dashboard at:       198.202.102.56:41517
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gj1067tk
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:43703
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:43703
distributed.worker - INFO -          dashboard at:       198.202.102.56:42009
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-bklne_xd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:38845
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:38845
distributed.worker - INFO -          dashboard at:       198.202.102.56:40765
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-yfs6l9fo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:36703
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:36703
distributed.worker - INFO -          dashboard at:       198.202.102.56:40945
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-bcxdbc8k
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:46923
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:46923
distributed.worker - INFO -          dashboard at:       198.202.102.56:33875
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ewjfzx3m
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:38367
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:38367
distributed.worker - INFO -          dashboard at:       198.202.102.56:45945
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hyrk7v_1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:40269
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:40269
distributed.worker - INFO -          dashboard at:       198.202.102.56:39113
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-v9xbts9z
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:35479
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:35479
distributed.worker - INFO -          dashboard at:       198.202.102.56:36643
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pu2xf3ar
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:37333
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:37333
distributed.worker - INFO -          dashboard at:       198.202.102.56:43567
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-eqzsoopu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:37943
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:37943
distributed.worker - INFO -          dashboard at:       198.202.102.56:36847
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-iotnruv1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:33609
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:33609
distributed.worker - INFO -          dashboard at:       198.202.102.56:41953
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-t47pm0b0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:41549
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:41549
distributed.worker - INFO -          dashboard at:       198.202.102.56:39969
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ew584emy
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:42947
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:42947
distributed.worker - INFO -          dashboard at:       198.202.102.56:43467
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-x_27fzdl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:43577
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:43577
distributed.worker - INFO -          dashboard at:       198.202.102.56:41563
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-2mj8k114
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:42583
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:42583
distributed.worker - INFO -          dashboard at:       198.202.102.56:45493
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4onft_vj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:41767
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:41767
distributed.worker - INFO -          dashboard at:       198.202.102.56:46997
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-k_2gr90_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:45135
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:45135
distributed.worker - INFO -          dashboard at:       198.202.102.56:43707
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-rjspq8by
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:38419
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:38419
distributed.worker - INFO -          dashboard at:       198.202.102.56:42585
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-wgnamb7c
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:36133
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:36133
distributed.worker - INFO -          dashboard at:       198.202.102.56:43741
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-dwhhgdcx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:43541
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:43541
distributed.worker - INFO -          dashboard at:       198.202.102.56:37135
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-anlo4u7l
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:39929
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:39929
distributed.worker - INFO -          dashboard at:       198.202.102.56:41477
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-36efjfc7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:46853
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:46853
distributed.worker - INFO -          dashboard at:       198.202.102.56:36447
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_rn102w2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:38583
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:38583
distributed.worker - INFO -          dashboard at:       198.202.102.56:38397
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-cm732iv_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:42187
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:42187
distributed.worker - INFO -          dashboard at:       198.202.102.56:33013
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-w_le23om
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:44609
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:44609
distributed.worker - INFO -          dashboard at:       198.202.102.56:34061
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1ltbpnz0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:33495
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:33495
distributed.worker - INFO -          dashboard at:       198.202.102.56:43159
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0f63lksh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:33265
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:33265
distributed.worker - INFO -          dashboard at:       198.202.102.56:45359
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-l6gmwplc
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:43517
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:43517
distributed.worker - INFO -          dashboard at:       198.202.102.56:33767
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-r5qcwi5o
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:40535
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:40535
distributed.worker - INFO -          dashboard at:       198.202.102.56:36935
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-uigbro1p
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:37869
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:37869
distributed.worker - INFO -          dashboard at:       198.202.102.56:46843
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-v30uu8km
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:43825
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:43825
distributed.worker - INFO -          dashboard at:       198.202.102.56:39295
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-nsh26h41
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:44675
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:44675
distributed.worker - INFO -          dashboard at:       198.202.102.56:33727
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0fbp5moy
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:35415
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:35415
distributed.worker - INFO -          dashboard at:       198.202.102.56:38597
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-e_6g82f0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:37055
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:37055
distributed.worker - INFO -          dashboard at:       198.202.102.56:43951
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-97iws141
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:37509
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:37509
distributed.worker - INFO -          dashboard at:       198.202.102.56:45741
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-k5wjdvtp
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:44387
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:44387
distributed.worker - INFO -          dashboard at:       198.202.102.56:40785
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1cx0ftbw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:46933
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:46933
distributed.worker - INFO -          dashboard at:       198.202.102.56:38413
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7ru23qsd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:41867
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:41867
distributed.worker - INFO -          dashboard at:       198.202.102.56:38877
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7ipiemen
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:44431
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:44431
distributed.worker - INFO -          dashboard at:       198.202.102.56:34611
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-oc0mc_az
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:44257
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:44257
distributed.worker - INFO -          dashboard at:       198.202.102.56:44983
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-t4xyf3cv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:39823
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:39823
distributed.worker - INFO -          dashboard at:       198.202.102.56:42957
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-wdoffyhg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.56:42209
distributed.worker - INFO -          Listening to: tcp://198.202.102.56:42209
distributed.worker - INFO -          dashboard at:       198.202.102.56:44501
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-r78ity4k
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.103.184:34547
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - WARNING - Heartbeat to scheduler failed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:37055
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:40535
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:44675
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:44387
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:33265
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:44257
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:43517
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:43825
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:37869
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:33495
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:39929
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:41867
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:37509
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:38419
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:39823
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:42947
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:45135
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:46853
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:46933
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:44431
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:41767
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:42187
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:37333
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:42583
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:36703
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:42209
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:35415
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:40269
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:44609
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:43577
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:43703
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:39185
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:46457
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:36133
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:38583
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:43411
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:41905
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:41005
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:38845
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:43541
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:40551
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:37943
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:33609
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:43521
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:35479
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:46923
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:38367
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:41549
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:43597
distributed.worker - INFO - Stopping worker at tcp://198.202.102.56:42439
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.core - INFO - Event loop was unresponsive in Nanny for 3.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 3.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 3.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 3.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Nanny for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:41495'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:46055'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:34917'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:34587'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:34551'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:42597'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:35629'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:41799'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:42745'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:41617'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:46889'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:33703'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:35713'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:34543'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:42361'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:43519'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:39007'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:44631'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:46689'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:40657'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:45587'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:33047'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:46489'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:40839'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:35729'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:44277'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:37817'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:37549'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:41881'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:46875'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:39521'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:39591'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:44065'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:40363'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:37721'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:41385'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:43173'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:41025'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:40483'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:35181'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:34577'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:44683'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:37179'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:41337'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:45293'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:47081'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:44647'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:46475'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:41613'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.56:45835'
distributed.dask_worker - INFO - End worker
