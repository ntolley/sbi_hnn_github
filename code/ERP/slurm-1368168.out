distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:43017'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:39981'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:33233'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:38601'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:36543'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:34975'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:36639'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:36515'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:45175'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:34797'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:39891'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:36247'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:37297'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:42373'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:43773'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:43861'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:46225'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:33173'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:39797'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:35241'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:42101'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:43935'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:33013'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:43685'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:40347'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:41783'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:45275'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:34255'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:36961'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:44375'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:45851'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:39117'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:37409'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:39043'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:35865'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:41801'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:42953'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:38849'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:35387'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:44929'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:36549'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:33103'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:42625'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:41305'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:35315'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:36113'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:34775'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:39955'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:39703'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.171:42981'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:40733
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:46177
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:44623
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:37259
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:40733
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:36959
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:46177
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:44623
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:36611
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:43255
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:37259
distributed.worker - INFO -          dashboard at:      198.202.101.171:46451
distributed.worker - INFO -          dashboard at:      198.202.101.171:37543
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:46317
distributed.worker - INFO -          dashboard at:      198.202.101.171:46335
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:36959
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:36611
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:41809
distributed.worker - INFO -          dashboard at:      198.202.101.171:35899
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:35237
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:43255
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:38533
distributed.worker - INFO -          dashboard at:      198.202.101.171:41295
distributed.worker - INFO -          dashboard at:      198.202.101.171:36785
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:40105
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:46317
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:45545
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:44219
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:45099
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:41809
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:33825
distributed.worker - INFO -          dashboard at:      198.202.101.171:33699
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:35237
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:38993
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:38533
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -          dashboard at:      198.202.101.171:46067
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:40105
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:45545
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.101.171:40729
distributed.worker - INFO -          dashboard at:      198.202.101.171:40379
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:45099
distributed.worker - INFO -          dashboard at:      198.202.101.171:34859
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:33825
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:38993
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -          dashboard at:      198.202.101.171:33333
distributed.worker - INFO -          dashboard at:      198.202.101.171:32879
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:44219
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -          dashboard at:      198.202.101.171:35205
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.101.171:35453
distributed.worker - INFO -          dashboard at:      198.202.101.171:34637
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xlkbdmhg
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.101.171:44465
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-81pgvjx_
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qs3vctli
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-k6wgua3r
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-aljtwess
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-dx1c6mbi
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-89bcg_aw
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-jodyo1s6
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-igxjifq1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8a1v5xbi
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-dc2ih6x4
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7775y711
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-wcqjyiqf
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1rqkin4j
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4edx1zru
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-s2ma9_oc
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ufja47vc
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:38587
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:38587
distributed.worker - INFO -          dashboard at:      198.202.101.171:35991
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-znk34lia
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:43225
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:43225
distributed.worker - INFO -          dashboard at:      198.202.101.171:41795
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-jqnlod3w
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:44041
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:44041
distributed.worker - INFO -          dashboard at:      198.202.101.171:34703
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0d1519m8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:39397
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:39397
distributed.worker - INFO -          dashboard at:      198.202.101.171:44113
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-jh1wl47p
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:42573
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:42573
distributed.worker - INFO -          dashboard at:      198.202.101.171:41959
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-meahb6c0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:35283
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:35283
distributed.worker - INFO -          dashboard at:      198.202.101.171:36065
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-p3cljp_m
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:39171
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:39171
distributed.worker - INFO -          dashboard at:      198.202.101.171:42903
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-legyix4n
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:45457
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:45457
distributed.worker - INFO -          dashboard at:      198.202.101.171:40785
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vhkyw3w5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:39923
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:39923
distributed.worker - INFO -          dashboard at:      198.202.101.171:44457
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zbf89hnm
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:35695
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:35695
distributed.worker - INFO -          dashboard at:      198.202.101.171:40665
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-h7luy3ti
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:38213
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:38213
distributed.worker - INFO -          dashboard at:      198.202.101.171:42103
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-k1djowfb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:42125
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:42125
distributed.worker - INFO -          dashboard at:      198.202.101.171:41233
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-n5xqp34z
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:35039
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:44673
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:44673
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:35039
distributed.worker - INFO -          dashboard at:      198.202.101.171:43455
distributed.worker - INFO -          dashboard at:      198.202.101.171:45127
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-h2o5r8z8
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-lfcuiqsy
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:33205
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:33205
distributed.worker - INFO -          dashboard at:      198.202.101.171:44243
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-t9cfsgl0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:42829
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:42829
distributed.worker - INFO -          dashboard at:      198.202.101.171:46815
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-lda2_rit
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:44037
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:44037
distributed.worker - INFO -          dashboard at:      198.202.101.171:35557
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-o7qfcy2z
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:40807
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:40807
distributed.worker - INFO -          dashboard at:      198.202.101.171:32955
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-i4g49b9z
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:41147
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:41147
distributed.worker - INFO -          dashboard at:      198.202.101.171:41343
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3_un6lmb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:36591
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:36591
distributed.worker - INFO -          dashboard at:      198.202.101.171:36525
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7bqbvn5l
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:44495
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:44495
distributed.worker - INFO -          dashboard at:      198.202.101.171:43509
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1iydv3r4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:40777
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:40777
distributed.worker - INFO -          dashboard at:      198.202.101.171:40851
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-mdg38y84
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:43587
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:43587
distributed.worker - INFO -          dashboard at:      198.202.101.171:46063
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8mkepqyb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:36003
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:36003
distributed.worker - INFO -          dashboard at:      198.202.101.171:46629
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-sxvprair
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:36777
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:36777
distributed.worker - INFO -          dashboard at:      198.202.101.171:41091
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-s2w6jw2l
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:46703
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:46703
distributed.worker - INFO -          dashboard at:      198.202.101.171:36595
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3x7oqkle
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:40143
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:40143
distributed.worker - INFO -          dashboard at:      198.202.101.171:44291
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-emujeb0o
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:46015
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:46015
distributed.worker - INFO -          dashboard at:      198.202.101.171:46759
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-423kc7hk
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:44467
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:44467
distributed.worker - INFO -          dashboard at:      198.202.101.171:35397
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ie39xt3l
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:38569
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:38569
distributed.worker - INFO -          dashboard at:      198.202.101.171:45841
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ommtpefq
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:36641
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:36641
distributed.worker - INFO -          dashboard at:      198.202.101.171:33491
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-esyyvy3u
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:39709
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:39709
distributed.worker - INFO -          dashboard at:      198.202.101.171:41251
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-f01dognv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.171:35331
distributed.worker - INFO -          Listening to: tcp://198.202.101.171:35331
distributed.worker - INFO -          dashboard at:      198.202.101.171:38349
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-he_uepwb
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
slurmstepd: error: *** JOB 1368168 ON exp-10-56 CANCELLED AT 2021-02-26T07:00:40 ***
