distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:46093'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:36469'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:38371'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:36367'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:39037'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:37325'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:33901'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:43517'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:33167'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:32987'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:37603'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:45263'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:37227'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:33355'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:37061'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:41751'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:37131'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:40905'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:38743'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:47041'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:36779'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:44661'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:43313'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:39995'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:36097'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:41549'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:39005'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:33277'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:42469'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:41477'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:38715'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:44247'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:39973'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:38821'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:33751'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:45531'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:36079'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:37125'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:44197'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:38803'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:33933'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:37223'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:33035'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:42873'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:38285'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:33493'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:33807'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:39993'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:37999'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.172:36275'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:34207
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:40725
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:37451
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:40193
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:40993
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:34207
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:40725
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:45023
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:37451
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:44279
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:41415
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:40193
distributed.worker - INFO -          dashboard at:      198.202.101.172:44485
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:46677
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:40993
distributed.worker - INFO -          dashboard at:      198.202.101.172:35323
distributed.worker - INFO -          dashboard at:      198.202.101.172:35635
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:39553
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:45023
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:45913
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:34083
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:35009
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:44279
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:43575
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:42555
distributed.worker - INFO -          dashboard at:      198.202.101.172:38827
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -          dashboard at:      198.202.101.172:36763
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:41415
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:46677
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:38909
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:39553
distributed.worker - INFO -          dashboard at:      198.202.101.172:37575
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:45913
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:34083
distributed.worker - INFO -          dashboard at:      198.202.101.172:38771
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:35009
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:43575
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:39397
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:42555
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:43085
distributed.worker - INFO -          dashboard at:      198.202.101.172:36695
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.101.172:35127
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:38909
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -          dashboard at:      198.202.101.172:46613
distributed.worker - INFO -          dashboard at:      198.202.101.172:37393
distributed.worker - INFO -          dashboard at:      198.202.101.172:44907
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -          dashboard at:      198.202.101.172:37707
distributed.worker - INFO -          dashboard at:      198.202.101.172:43951
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:39397
distributed.worker - INFO -          dashboard at:      198.202.101.172:34923
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:43085
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:      198.202.101.172:37625
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:      198.202.101.172:36597
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -          dashboard at:      198.202.101.172:38423
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-2to5cxj_
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-t1wcf5mh
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-aj1ar77p
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-w11w_vfs
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qnmwwr1r
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qwz1wlqt
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-q19pllhs
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ssadzo3l
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-cfd5jk63
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-64vcvf9b
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-x0yn9sk_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-kgaj4cj7
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8q007z60
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5ywofhvx
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-nsi3_f5p
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0o_z61uq
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ecd9cfjq
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-l8zmg066
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:41971
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:41971
distributed.worker - INFO -          dashboard at:      198.202.101.172:40867
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ves0e0vb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:38401
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:38401
distributed.worker - INFO -          dashboard at:      198.202.101.172:43193
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-yrt63w3x
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:35245
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:35245
distributed.worker - INFO -          dashboard at:      198.202.101.172:33541
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-rsteq4o1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:34267
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:34267
distributed.worker - INFO -          dashboard at:      198.202.101.172:34919
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-984bgp9d
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:35541
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:35541
distributed.worker - INFO -          dashboard at:      198.202.101.172:36787
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vx1v3xez
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:39575
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:39575
distributed.worker - INFO -          dashboard at:      198.202.101.172:41651
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pre_91ni
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:41591
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:41591
distributed.worker - INFO -          dashboard at:      198.202.101.172:41271
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zm8qc9jd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:43285
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:43285
distributed.worker - INFO -          dashboard at:      198.202.101.172:38719
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-a1xrbjmo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:44463
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:44463
distributed.worker - INFO -          dashboard at:      198.202.101.172:35221
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-jb59smnv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:34659
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:34659
distributed.worker - INFO -          dashboard at:      198.202.101.172:33275
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0c340nck
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:40181
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:40181
distributed.worker - INFO -          dashboard at:      198.202.101.172:44867
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-y2kh6d60
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:34169
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:34169
distributed.worker - INFO -          dashboard at:      198.202.101.172:37113
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-s2wo6jlo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:35901
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:35901
distributed.worker - INFO -          dashboard at:      198.202.101.172:36371
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-a3549yx5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:34431
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:35573
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:34431
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:35573
distributed.worker - INFO -          dashboard at:      198.202.101.172:34705
distributed.worker - INFO -          dashboard at:      198.202.101.172:41191
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-iimx5gdw
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-etmnr03a
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:45215
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:45215
distributed.worker - INFO -          dashboard at:      198.202.101.172:46385
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-es3ql27d
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:41075
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:41075
distributed.worker - INFO -          dashboard at:      198.202.101.172:35765
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-dmanc4w4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:39913
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:39913
distributed.worker - INFO -          dashboard at:      198.202.101.172:40717
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-l7zfbqwy
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:38397
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:38397
distributed.worker - INFO -          dashboard at:      198.202.101.172:34453
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qb3ou_bn
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:39269
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:39269
distributed.worker - INFO -          dashboard at:      198.202.101.172:39747
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vz6h7jzd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:44423
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:44423
distributed.worker - INFO -          dashboard at:      198.202.101.172:46921
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5sv13_f8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:41519
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:41519
distributed.worker - INFO -          dashboard at:      198.202.101.172:41175
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-v88t1xxt
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:37939
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:37939
distributed.worker - INFO -          dashboard at:      198.202.101.172:34049
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-k0fjsvoo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:34897
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:34897
distributed.worker - INFO -          dashboard at:      198.202.101.172:45091
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qndp4ljj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:38943
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:38943
distributed.worker - INFO -          dashboard at:      198.202.101.172:33685
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-v44sysvn
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:41001
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:41001
distributed.worker - INFO -          dashboard at:      198.202.101.172:37409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-w6y0327_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:41703
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:41703
distributed.worker - INFO -          dashboard at:      198.202.101.172:33759
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-sz9_kjzt
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:42649
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:42649
distributed.worker - INFO -          dashboard at:      198.202.101.172:34691
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-63g6eg2y
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:43203
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:43203
distributed.worker - INFO -          dashboard at:      198.202.101.172:33207
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0gk7loqz
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:34573
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:34573
distributed.worker - INFO -          dashboard at:      198.202.101.172:35349
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-2h2zvvt4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:44521
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:44521
distributed.worker - INFO -          dashboard at:      198.202.101.172:41185
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qm3w_p6s
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.172:45747
distributed.worker - INFO -          Listening to: tcp://198.202.101.172:45747
distributed.worker - INFO -          dashboard at:      198.202.101.172:45233
distributed.worker - INFO - Waiting to connect to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.00 GB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-s3ky08yp
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to: tcp://198.202.102.253:39519
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
slurmstepd: error: *** JOB 1368167 ON exp-10-55 CANCELLED AT 2021-02-26T07:00:40 ***
