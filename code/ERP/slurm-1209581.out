distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38477'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36589'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:33077'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:45381'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:33479'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:45033'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:45979'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:44955'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38029'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:42123'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:46711'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:37647'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:44225'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:32921'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36789'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:40619'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:35615'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:34463'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38499'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:39877'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:34911'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36049'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38583'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:44099'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:44241'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:44445'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:41965'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38949'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:33955'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:40375'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:37307'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38315'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:42447'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:42127'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:43833'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:41709'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:46983'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:33329'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38003'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:34019'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:35683'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38625'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:35403'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:37355'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36129'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36249'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:33863'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:40071'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:46443'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:40041'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:37473'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:43995'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:32809'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:37141'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:46279'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:37751'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:40285'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:34105'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:39303'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36897'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:35259'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:44221'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:44787'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:43389'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:42259'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36669'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:41557'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:46209'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:45067'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36951'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:33037'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:46569'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38857'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:45811'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:34171'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36027'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:44163'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38659'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:39511'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:37789'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36309'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:40695'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36551'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38597'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:34315'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:39567'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:46171'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:42673'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38193'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36585'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:41187'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36445'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:44261'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:43991'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:34701'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:46489'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:34727'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:37295'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:41661'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:37347'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:36819
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:36403
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:36819
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:35465
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:36403
distributed.worker - INFO -          dashboard at:      198.202.103.148:44801
distributed.worker - INFO -          dashboard at:      198.202.103.148:41607
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:35465
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:      198.202.103.148:36035
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_q1pcufv
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ngrz69w_
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-m63odc4p
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:41101
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:41101
distributed.worker - INFO -          dashboard at:      198.202.103.148:44079
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-r8967749
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:35009
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:35009
distributed.worker - INFO -          dashboard at:      198.202.103.148:33635
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-fl94q445
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39827
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39827
distributed.worker - INFO -          dashboard at:      198.202.103.148:38289
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vuhkpa1d
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:32977
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:32977
distributed.worker - INFO -          dashboard at:      198.202.103.148:46201
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9syzqkg3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:40629
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:40629
distributed.worker - INFO -          dashboard at:      198.202.103.148:34869
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-iugx5z89
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:35221
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:35221
distributed.worker - INFO -          dashboard at:      198.202.103.148:40567
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:44331
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xpq0jrxk
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:44331
distributed.worker - INFO -          dashboard at:      198.202.103.148:44641
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pwwpvh43
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39135
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39135
distributed.worker - INFO -          dashboard at:      198.202.103.148:46193
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-cbfyu0am
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:36341
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:36341
distributed.worker - INFO -          dashboard at:      198.202.103.148:34177
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-f0af4gpg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:34749
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:34749
distributed.worker - INFO -          dashboard at:      198.202.103.148:41309
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-za3p8k3w
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:46021
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:46021
distributed.worker - INFO -          dashboard at:      198.202.103.148:37249
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1b_rm64g
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:38987
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:38987
distributed.worker - INFO -          dashboard at:      198.202.103.148:33057
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9osgufa6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:43351
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:43351
distributed.worker - INFO -          dashboard at:      198.202.103.148:41093
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-n5qe95_s
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:37491
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:37491
distributed.worker - INFO -          dashboard at:      198.202.103.148:41907
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5dmoez_v
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:46467
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:46467
distributed.worker - INFO -          dashboard at:      198.202.103.148:44889
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-rig2tx0_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:34603
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:34603
distributed.worker - INFO -          dashboard at:      198.202.103.148:46113
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-nfn_j139
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:33717
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:33717
distributed.worker - INFO -          dashboard at:      198.202.103.148:33023
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-lr653nhv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:34083
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:34083
distributed.worker - INFO -          dashboard at:      198.202.103.148:39711
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-bt7iucoa
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:42865
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:42865
distributed.worker - INFO -          dashboard at:      198.202.103.148:37767
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9sqj49ay
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:42467
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:42467
distributed.worker - INFO -          dashboard at:      198.202.103.148:35637
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3prbekg0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39983
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39983
distributed.worker - INFO -          dashboard at:      198.202.103.148:35935
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_yfz1487
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:44759
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:44759
distributed.worker - INFO -          dashboard at:      198.202.103.148:43727
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_c98njzo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39195
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39195
distributed.worker - INFO -          dashboard at:      198.202.103.148:44155
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xj1v_fhx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:43313
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:35535
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:35535
distributed.worker - INFO -          dashboard at:      198.202.103.148:42783
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:43313
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.103.148:33555
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8iesang9
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-dhfa0p2_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:34467
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:34467
distributed.worker - INFO -          dashboard at:      198.202.103.148:46469
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vs2v53sx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:44063
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:44063
distributed.worker - INFO -          dashboard at:      198.202.103.148:42603
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hr41k4v5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39437
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39437
distributed.worker - INFO -          dashboard at:      198.202.103.148:35959
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vd7d7g4j
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:41729
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:41729
distributed.worker - INFO -          dashboard at:      198.202.103.148:39633
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4cabfb3f
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:36399
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:36399
distributed.worker - INFO -          dashboard at:      198.202.103.148:34619
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-rtjqscye
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39469
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39469
distributed.worker - INFO -          dashboard at:      198.202.103.148:38703
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6gb37d59
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:41807
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:41807
distributed.worker - INFO -          dashboard at:      198.202.103.148:39381
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-iq4cycur
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:42455
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:42455
distributed.worker - INFO -          dashboard at:      198.202.103.148:45073
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39705
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39705
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.103.148:39159
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zk6d9kvd
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4ztiofpj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:45925
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:45925
distributed.worker - INFO -          dashboard at:      198.202.103.148:41567
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-32nglaho
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:40889
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:40889
distributed.worker - INFO -          dashboard at:      198.202.103.148:42425
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-q471ql4p
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:45637
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:45637
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:37519
distributed.worker - INFO -          dashboard at:      198.202.103.148:43663
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:37519
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:      198.202.103.148:42645
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-oeb57g8h
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-f2q7do20
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:42417
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:42417
distributed.worker - INFO -          dashboard at:      198.202.103.148:44407
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ey65cc_m
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:46169
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:46169
distributed.worker - INFO -          dashboard at:      198.202.103.148:45183
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-kcom2plr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:42263
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:42263
distributed.worker - INFO -          dashboard at:      198.202.103.148:39933
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5kn_i6nu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39993
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39993
distributed.worker - INFO -          dashboard at:      198.202.103.148:36523
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ax3ww8py
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:41417
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:41417
distributed.worker - INFO -          dashboard at:      198.202.103.148:41083
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3pz1mtly
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39737
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39737
distributed.worker - INFO -          dashboard at:      198.202.103.148:45329
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-x3jnx15w
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39873
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39873
distributed.worker - INFO -          dashboard at:      198.202.103.148:41731
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-itvx_tx7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:35783
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:35783
distributed.worker - INFO -          dashboard at:      198.202.103.148:40441
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:36755
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6gm3uyga
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:36755
distributed.worker - INFO -          dashboard at:      198.202.103.148:44917
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-muxwnbb1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:42055
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:42055
distributed.worker - INFO -          dashboard at:      198.202.103.148:38025
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:38963
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:38963
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -          dashboard at:      198.202.103.148:38313
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-n0g6orh1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-lkawn2wg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:45199
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:45199
distributed.worker - INFO -          dashboard at:      198.202.103.148:38271
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ocbb6e83
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:45919
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:45919
distributed.worker - INFO -          dashboard at:      198.202.103.148:35373
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-j5gh7vm1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:43957
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:43957
distributed.worker - INFO -          dashboard at:      198.202.103.148:45863
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-py3l6f3f
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:44175
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:44175
distributed.worker - INFO -          dashboard at:      198.202.103.148:44157
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-jvtxkr7r
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:46519
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:46519
distributed.worker - INFO -          dashboard at:      198.202.103.148:33283
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qvlp3myx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:33107
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:33107
distributed.worker - INFO -          dashboard at:      198.202.103.148:44289
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6682kv4g
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:46893
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:46893
distributed.worker - INFO -          dashboard at:      198.202.103.148:41897
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1iuz37rb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39587
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39587
distributed.worker - INFO -          dashboard at:      198.202.103.148:44551
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-lzvdiy3x
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:35801
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:44049
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:35801
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:44049
distributed.worker - INFO -          dashboard at:      198.202.103.148:45769
distributed.worker - INFO -          dashboard at:      198.202.103.148:43587
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-b0i9ux3_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-68yit_1v
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:46287
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:46287
distributed.worker - INFO -          dashboard at:      198.202.103.148:46883
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-dic8nsv1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39515
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39515
distributed.worker - INFO -          dashboard at:      198.202.103.148:34499
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9mjoi0kc
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:47051
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:47051
distributed.worker - INFO -          dashboard at:      198.202.103.148:44611
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gds2saf1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:36431
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:36431
distributed.worker - INFO -          dashboard at:      198.202.103.148:40313
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ki5q35n_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:35519
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:35519
distributed.worker - INFO -          dashboard at:      198.202.103.148:43939
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-2reqb5yb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:34143
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:34143
distributed.worker - INFO -          dashboard at:      198.202.103.148:42725
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4fwbxyls
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39383
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39383
distributed.worker - INFO -          dashboard at:      198.202.103.148:35651
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-k0z6iee5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39513
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39513
distributed.worker - INFO -          dashboard at:      198.202.103.148:43569
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8kzaxu6d
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:47025
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:47025
distributed.worker - INFO -          dashboard at:      198.202.103.148:34043
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-k1lqg99p
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:46103
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:46103
distributed.worker - INFO -          dashboard at:      198.202.103.148:32937
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zl9z03t_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:35101
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:35101
distributed.worker - INFO -          dashboard at:      198.202.103.148:41935
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-r649ddut
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:41589
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:41589
distributed.worker - INFO -          dashboard at:      198.202.103.148:43127
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-mwipybzu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:42347
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:42347
distributed.worker - INFO -          dashboard at:      198.202.103.148:34153
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-i6wh4hno
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:40159
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:40159
distributed.worker - INFO -          dashboard at:      198.202.103.148:38823
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ne741yxq
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:33989
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:33989
distributed.worker - INFO -          dashboard at:      198.202.103.148:34969
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hcvswy5o
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:46683
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:46683
distributed.worker - INFO -          dashboard at:      198.202.103.148:39349
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-u_6m9uo1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:35787
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:35787
distributed.worker - INFO -          dashboard at:      198.202.103.148:41075
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-skxlkh_1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:35025
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:35025
distributed.worker - INFO -          dashboard at:      198.202.103.148:40591
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-e4e13oj6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:36753
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:36753
distributed.worker - INFO -          dashboard at:      198.202.103.148:33939
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5j1fqpmr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:43095
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:43095
distributed.worker - INFO -          dashboard at:      198.202.103.148:33733
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4g1o6kw0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:43673
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:43673
distributed.worker - INFO -          dashboard at:      198.202.103.148:39151
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-v6v_wi32
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:43335
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:43335
distributed.worker - INFO -          dashboard at:      198.202.103.148:41065
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9e83_29c
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:40749
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:40749
distributed.worker - INFO -          dashboard at:      198.202.103.148:45379
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zdaa5nb6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:44495
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:44495
distributed.worker - INFO -          dashboard at:      198.202.103.148:44459
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4i41rtos
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:35161
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:35161
distributed.worker - INFO -          dashboard at:      198.202.103.148:39879
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-if5_rxi2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:36535
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:36535
distributed.worker - INFO -          dashboard at:      198.202.103.148:42641
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-49zrq5jv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39881
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39881
distributed.worker - INFO -          dashboard at:      198.202.103.148:36437
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6cmibrxd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:34951
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:34951
distributed.worker - INFO -          dashboard at:      198.202.103.148:33695
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7r4segxl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:34573
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:34573
distributed.worker - INFO -          dashboard at:      198.202.103.148:37595
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-yf5ifrd3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:46603
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:46603
distributed.worker - INFO -          dashboard at:      198.202.103.148:35401
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0bt4d2dl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:46765
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:46765
distributed.worker - INFO -          dashboard at:      198.202.103.148:37439
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-yz_gway_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:41115
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:41115
distributed.worker - INFO -          dashboard at:      198.202.103.148:36867
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3lx20lcw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:36733
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:36733
distributed.worker - INFO -          dashboard at:      198.202.103.148:46635
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tv0wl9yf
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:43027
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:43027
distributed.worker - INFO -          dashboard at:      198.202.103.148:43353
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hqzul9gj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:34131
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:34131
distributed.worker - INFO -          dashboard at:      198.202.103.148:41623
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-jid_6nzh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:42439
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:42439
distributed.worker - INFO -          dashboard at:      198.202.103.148:34875
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-w1be5oqb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:33217
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:33217
distributed.worker - INFO -          dashboard at:      198.202.103.148:40191
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-eyq3xmlh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:34659
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:34659
distributed.worker - INFO -          dashboard at:      198.202.103.148:46481
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-h7yghdls
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38477'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36589'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39827
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:33077'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:32977
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:45381'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:33479'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:35009
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:45033'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:36403
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:41101
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:45979'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:44955'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:35465
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38029'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:36819
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:42123'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:44331
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:46711'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:35221
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:37647'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:40629
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:44225'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39135
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:32921'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:36341
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36789'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:34749
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:40619'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:38987
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:35615'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:46021
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:34463'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:37491
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:43351
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38499'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:39877'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:33717
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:34911'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:46467
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36049'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38583'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:42865
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:34083
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:44099'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:34603
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:44241'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:42467
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:44445'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39983
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:41965'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:44759
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38949'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:34467
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:33955'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:43313
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:40375'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:35535
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:41807
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:37307'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38315'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39437
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:42447'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:42127'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:41729
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:36399
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:46169
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:43833'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:41709'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39705
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:37519
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:46983'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:33329'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:45925
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38003'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:42455
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:34019'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:45637
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:35683'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:42417
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39469
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38625'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:35403'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:42263
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:37355'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:42055
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36129'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39993
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36249'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:40889
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39737
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:33863'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:40071'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:38963
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:46443'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:41417
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:40041'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:44049
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:45919
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:37473'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:43995'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:35783
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:32809'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:43957
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:37141'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:45199
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:46279'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:33107
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:37751'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:36755
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:40285'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39587
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:34105'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:46519
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:39303'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:44175
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36897'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:46287
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:35801
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:35259'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:44221'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:46893
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:44787'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:47025
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:43389'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39873
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:42259'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39515
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36669'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39513
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39383
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:41557'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:46209'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:35519
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:36431
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:34143
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:45067'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36951'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:33037'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:46569'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:33989
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:41589
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38857'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:47051
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:45811'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:46103
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:34171'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36027'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:35101
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:40159
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:44163'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:42347
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38659'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:36753
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:39511'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:35025
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:37789'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:43095
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36309'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:46683
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:40695'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:35161
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36551'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:43673
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38597'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39195
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:34315'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:43335
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:39567'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:35787
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:46171'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39881
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:42673'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:46765
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38193'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:44495
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36585'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:40749
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:41187'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:36733
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36445'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:41115
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:44261'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:34573
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:43991'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:34951
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:34701'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:44063
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:46489'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:36535
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:34727'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:34659
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:37295'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:46603
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:41661'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:43027
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:37347'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:42439
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:34131
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:33217
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 79993 was killed by signal 15
distributed.nanny - INFO - Worker process 79960 was killed by signal 15
distributed.nanny - INFO - Worker process 79996 was killed by signal 15
distributed.nanny - INFO - Worker process 79956 was killed by signal 15
distributed.nanny - INFO - Worker process 80043 was killed by signal 15
distributed.nanny - INFO - Worker process 79945 was killed by signal 15
distributed.nanny - INFO - Worker process 79926 was killed by signal 15
distributed.nanny - INFO - Worker process 79966 was killed by signal 15
distributed.nanny - INFO - Worker process 79942 was killed by signal 15
distributed.nanny - INFO - Worker process 80040 was killed by signal 15
distributed.nanny - INFO - Worker process 80002 was killed by signal 15
distributed.nanny - INFO - Worker process 79951 was killed by signal 15
distributed.nanny - INFO - Worker process 80021 was killed by signal 15
distributed.nanny - INFO - Worker process 80073 was killed by signal 15
distributed.nanny - INFO - Worker process 80057 was killed by signal 15
distributed.nanny - INFO - Worker process 79975 was killed by signal 15
distributed.nanny - INFO - Worker process 80065 was killed by signal 15
distributed.nanny - INFO - Worker process 80052 was killed by signal 15
distributed.nanny - INFO - Worker process 79929 was killed by signal 15
distributed.nanny - INFO - Worker process 80036 was killed by signal 15
distributed.nanny - INFO - Worker process 80025 was killed by signal 15
distributed.nanny - INFO - Worker process 79968 was killed by signal 15
distributed.nanny - INFO - Worker process 79933 was killed by signal 15
distributed.nanny - INFO - Worker process 80016 was killed by signal 15
distributed.nanny - INFO - Worker process 80075 was killed by signal 15
distributed.nanny - INFO - Worker process 80033 was killed by signal 15
distributed.nanny - INFO - Worker process 79999 was killed by signal 15
distributed.nanny - INFO - Worker process 79981 was killed by signal 15
distributed.nanny - INFO - Worker process 80028 was killed by signal 15
distributed.nanny - INFO - Worker process 79977 was killed by signal 15
distributed.nanny - INFO - Worker process 80055 was killed by signal 15
distributed.nanny - INFO - Worker process 79939 was killed by signal 15
distributed.nanny - INFO - Worker process 79948 was killed by signal 15
distributed.nanny - INFO - Worker process 79987 was killed by signal 15
distributed.nanny - INFO - Worker process 80070 was killed by signal 15
distributed.nanny - INFO - Worker process 79936 was killed by signal 15
distributed.nanny - INFO - Worker process 79954 was killed by signal 15
distributed.nanny - INFO - Worker process 80077 was killed by signal 15
distributed.nanny - INFO - Worker process 80117 was killed by signal 15
distributed.nanny - INFO - Worker process 80019 was killed by signal 15
distributed.nanny - INFO - Worker process 80048 was killed by signal 15
distributed.nanny - INFO - Worker process 80101 was killed by signal 15
distributed.nanny - INFO - Worker process 80086 was killed by signal 15
distributed.nanny - INFO - Worker process 80089 was killed by signal 15
distributed.nanny - INFO - Worker process 79971 was killed by signal 15
distributed.nanny - INFO - Worker process 80107 was killed by signal 15
distributed.nanny - INFO - Worker process 80009 was killed by signal 15
distributed.nanny - INFO - Worker process 79990 was killed by signal 15
distributed.nanny - INFO - Worker process 80092 was killed by signal 15
distributed.nanny - INFO - Worker process 79982 was killed by signal 15
distributed.nanny - INFO - Worker process 79928 was killed by signal 15
distributed.nanny - INFO - Worker process 79962 was killed by signal 15
distributed.nanny - INFO - Worker process 80067 was killed by signal 15
distributed.nanny - INFO - Worker process 80113 was killed by signal 15
distributed.nanny - INFO - Worker process 80109 was killed by signal 15
distributed.nanny - INFO - Worker process 80096 was killed by signal 15
distributed.nanny - INFO - Worker process 80099 was killed by signal 15
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 80195 was killed by signal 15
distributed.nanny - INFO - Worker process 80209 was killed by signal 15
distributed.nanny - INFO - Worker process 80216 was killed by signal 15
distributed.nanny - INFO - Worker process 80202 was killed by signal 15
distributed.nanny - INFO - Worker process 80187 was killed by signal 15
distributed.nanny - INFO - Worker process 80158 was killed by signal 15
distributed.nanny - INFO - Worker process 80207 was killed by signal 15
distributed.nanny - INFO - Worker process 80166 was killed by signal 15
distributed.nanny - INFO - Worker process 80626 was killed by signal 15
distributed.nanny - INFO - Worker process 80163 was killed by signal 15
distributed.nanny - INFO - Worker process 80538 was killed by signal 15
distributed.nanny - INFO - Worker process 80541 was killed by signal 15
distributed.nanny - INFO - Worker process 80683 was killed by signal 15
distributed.nanny - INFO - Worker process 80155 was killed by signal 15
distributed.nanny - INFO - Worker process 80623 was killed by signal 15
distributed.nanny - INFO - Worker process 80145 was killed by signal 15
distributed.nanny - INFO - Worker process 80133 was killed by signal 15
distributed.nanny - INFO - Worker process 80142 was killed by signal 15
distributed.nanny - INFO - Worker process 80463 was killed by signal 15
distributed.nanny - INFO - Worker process 80227 was killed by signal 15
distributed.nanny - INFO - Worker process 80199 was killed by signal 15
distributed.nanny - INFO - Worker process 80212 was killed by signal 15
distributed.nanny - INFO - Worker process 80543 was killed by signal 15
distributed.nanny - INFO - Worker process 80175 was killed by signal 15
distributed.nanny - INFO - Worker process 80624 was killed by signal 15
distributed.nanny - INFO - Worker process 80125 was killed by signal 15
distributed.nanny - INFO - Worker process 80106 was killed by signal 15
distributed.nanny - INFO - Worker process 80218 was killed by signal 15
distributed.nanny - INFO - Worker process 80135 was killed by signal 15
distributed.nanny - INFO - Worker process 80185 was killed by signal 15
distributed.nanny - INFO - Worker process 80693 was killed by signal 15
distributed.nanny - INFO - Worker process 80138 was killed by signal 15
distributed.nanny - INFO - Worker process 80182 was killed by signal 15
distributed.nanny - INFO - Worker process 80131 was killed by signal 15
distributed.nanny - INFO - Worker process 80190 was killed by signal 15
distributed.nanny - INFO - Worker process 80766 was killed by signal 15
distributed.nanny - INFO - Worker process 80768 was killed by signal 15
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
