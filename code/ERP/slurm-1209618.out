distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:35741'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:45705'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:39409'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:38969'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:36521'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:34451'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:44013'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:46471'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:33001'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:34863'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:46347'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:46117'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:41729'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:35771'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:35795'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:38739'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:42475'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:38097'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:34453'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:45225'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:36339'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:41227'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:44325'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:41849'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:41259'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:37699'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:36599'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:44971'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:38915'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:36435'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:35979'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:40459'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:33471'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:44513'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:32945'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:42113'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:46661'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:45583'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:44539'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:34089'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:40359'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:44795'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:39591'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:46345'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:42189'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:37195'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:41015'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:42785'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:38631'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:33731'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:34751'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:36929'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:46173'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:37705'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:44805'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:47049'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:41815'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:33839'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:40155'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:47089'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:40885'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:46503'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:38699'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:33723'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:34903'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:38823'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:35623'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:43463'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:44347'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:39929'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:36691'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:43305'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:32879'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:44127'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:39999'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:36143'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:43447'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:44099'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:42077'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:35451'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:45791'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:41303'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:41871'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:37351'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:42551'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:33625'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:43617'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:47041'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:40993'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:40121'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:39127'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:45891'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:33157'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:36379'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:35387'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:33899'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:37313'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:41379'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:34303'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.36:33073'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:45611
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:45611
distributed.worker - INFO -          dashboard at:       198.202.102.36:34499
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-14l7bpe0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:46311
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:46311
distributed.worker - INFO -          dashboard at:       198.202.102.36:40189
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xv3_6lz7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:33247
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:33247
distributed.worker - INFO -          dashboard at:       198.202.102.36:43333
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-e8pqvck4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:42605
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:42605
distributed.worker - INFO -          dashboard at:       198.202.102.36:44159
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-t17_qpgu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:41309
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:41309
distributed.worker - INFO -          dashboard at:       198.202.102.36:45243
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gppmsm1j
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:43255
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:43255
distributed.worker - INFO -          dashboard at:       198.202.102.36:40775
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-13kjwpug
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:45745
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:45745
distributed.worker - INFO -          dashboard at:       198.202.102.36:40197
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-k3obe2pl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:39429
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:39429
distributed.worker - INFO -          dashboard at:       198.202.102.36:38943
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-rstgup1i
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:37041
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:37041
distributed.worker - INFO -          dashboard at:       198.202.102.36:42041
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8mnesn88
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:46127
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:46127
distributed.worker - INFO -          dashboard at:       198.202.102.36:46885
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tfmcpb1c
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:33331
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:33331
distributed.worker - INFO -          dashboard at:       198.202.102.36:39477
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qi4nqt9q
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:34661
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:34661
distributed.worker - INFO -          dashboard at:       198.202.102.36:35595
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-q7mtyde0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:41257
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:41257
distributed.worker - INFO -          dashboard at:       198.202.102.36:45527
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-t0oqa8c2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:45861
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:45861
distributed.worker - INFO -          dashboard at:       198.202.102.36:40777
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-h0epi67j
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:43989
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:43989
distributed.worker - INFO -          dashboard at:       198.202.102.36:40691
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xaudj0ys
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:38397
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:38397
distributed.worker - INFO -          dashboard at:       198.202.102.36:42093
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-81x1527i
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:34943
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:34943
distributed.worker - INFO -          dashboard at:       198.202.102.36:43497
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-i47g32x3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:35133
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:35133
distributed.worker - INFO -          dashboard at:       198.202.102.36:39117
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-npbto6xk
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:32951
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:32951
distributed.worker - INFO -          dashboard at:       198.202.102.36:43115
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-devwo1be
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:33075
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:33075
distributed.worker - INFO -          dashboard at:       198.202.102.36:38189
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xyedmqd_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:44541
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:44541
distributed.worker - INFO -          dashboard at:       198.202.102.36:32959
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1d4kid9d
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:35765
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:35765
distributed.worker - INFO -          dashboard at:       198.202.102.36:35435
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-fy3wud4w
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:43171
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:43171
distributed.worker - INFO -          dashboard at:       198.202.102.36:45011
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0g0hlzsc
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:40517
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:40517
distributed.worker - INFO -          dashboard at:       198.202.102.36:35257
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5nnmcpv5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:39025
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:39025
distributed.worker - INFO -          dashboard at:       198.202.102.36:36365
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0b628_10
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:34813
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:34813
distributed.worker - INFO -          dashboard at:       198.202.102.36:37199
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ihbgevof
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:38755
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:38755
distributed.worker - INFO -          dashboard at:       198.202.102.36:38881
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zw1vy0rh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:38963
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:38963
distributed.worker - INFO -          dashboard at:       198.202.102.36:41293
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-d0f7xn4b
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:46335
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:46335
distributed.worker - INFO -          dashboard at:       198.202.102.36:40641
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-625fgicz
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:36295
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:36295
distributed.worker - INFO -          dashboard at:       198.202.102.36:46579
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-x9na37ja
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:38807
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:38807
distributed.worker - INFO -          dashboard at:       198.202.102.36:39811
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ohsr6s9r
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:35741'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:45705'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:39409'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:39429
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:38969'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:42605
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:36521'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:37041
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:34451'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:41309
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:44013'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:46311
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:46471'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:43255
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:33001'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:45745
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:34863'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:45611
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:46347'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:41257
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:46117'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:46127
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:41729'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:34661
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:35771'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:33331
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:35795'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:38397
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:32951
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:38739'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:42475'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:45861
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:38097'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:35133
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:34453'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:33075
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:45225'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:43989
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:36339'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:34943
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:41227'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:40517
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:44541
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:44325'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:41849'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:35765
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:41259'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:43171
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:37699'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:39025
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:38963
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:36599'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:44971'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:38755
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:38915'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:36435'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:46335
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:35979'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:34813
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:40459'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:36295
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:33471'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:38807
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:44513'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:32945'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:42113'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:33247
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:46661'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:45583'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:44539'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:34089'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:40359'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:44795'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:39591'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:46345'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:42189'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:37195'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:41015'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:42785'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:38631'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:33731'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:34751'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:36929'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:46173'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:37705'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:44805'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:47049'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:41815'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:33839'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:40155'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:47089'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:40885'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:46503'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:38699'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:33723'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:34903'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:38823'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:35623'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:43463'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:44347'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:39929'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:36691'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:43305'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:32879'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:44127'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:39999'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:36143'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:43447'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:44099'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:42077'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:35451'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:45791'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:41303'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:41871'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:37351'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:42551'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:33625'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:43617'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:47041'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:40993'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:40121'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:39127'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:45891'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:33157'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:36379'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:35387'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:33899'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:37313'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:41379'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:34303'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.36:33073'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:43351
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:43351
distributed.worker - INFO -          dashboard at:       198.202.102.36:45671
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zejt53_b
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:43351
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.36:33601
distributed.worker - INFO -          Listening to: tcp://198.202.102.36:33601
distributed.worker - INFO -          dashboard at:       198.202.102.36:41345
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-s63rqjie
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.102.36:33601
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 93220 was killed by signal 15
distributed.nanny - INFO - Worker process 93238 was killed by signal 15
distributed.nanny - INFO - Worker process 93244 was killed by signal 15
distributed.nanny - INFO - Worker process 93240 was killed by signal 15
distributed.nanny - INFO - Worker process 93228 was killed by signal 15
distributed.nanny - INFO - Worker process 93206 was killed by signal 15
distributed.nanny - INFO - Worker process 93224 was killed by signal 15
distributed.nanny - INFO - Worker process 93125 was killed by signal 15
distributed.nanny - INFO - Worker process 93232 was killed by signal 15
distributed.nanny - INFO - Worker process 93123 was killed by signal 15
distributed.nanny - INFO - Worker process 93137 was killed by signal 15
distributed.nanny - INFO - Worker process 93130 was killed by signal 15
distributed.nanny - INFO - Worker process 93217 was killed by signal 15
distributed.nanny - INFO - Worker process 93140 was killed by signal 15
distributed.nanny - INFO - Worker process 93188 was killed by signal 15
distributed.nanny - INFO - Worker process 93118 was killed by signal 15
distributed.nanny - INFO - Worker process 93155 was killed by signal 15
distributed.nanny - INFO - Worker process 93133 was killed by signal 15
distributed.nanny - INFO - Worker process 93152 was killed by signal 15
distributed.nanny - INFO - Worker process 93163 was killed by signal 15
distributed.nanny - INFO - Worker process 93117 was killed by signal 15
distributed.nanny - INFO - Worker process 93165 was killed by signal 15
distributed.nanny - INFO - Worker process 93143 was killed by signal 15
distributed.nanny - INFO - Worker process 93170 was killed by signal 15
distributed.nanny - INFO - Worker process 93148 was killed by signal 15
distributed.nanny - INFO - Worker process 93168 was killed by signal 15
distributed.nanny - INFO - Worker process 93147 was killed by signal 15
distributed.nanny - INFO - Worker process 93120 was killed by signal 15
distributed.nanny - INFO - Worker process 93157 was killed by signal 15
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO - Stopping worker
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Worker process 93127 was killed by signal 15
distributed.nanny - INFO - Worker process 93176 was killed by signal 15
distributed.nanny - INFO - Worker process 93169 was killed by signal 15
distributed.nanny - INFO - Worker process 93191 was killed by signal 15
distributed.nanny - INFO - Worker process 93194 was killed by signal 15
distributed.nanny - INFO - Worker process 93185 was killed by signal 15
distributed.nanny - INFO - Worker process 93234 was killed by signal 15
distributed.nanny - INFO - Worker process 93203 was killed by signal 15
distributed.nanny - INFO - Worker process 93201 was killed by signal 15
distributed.nanny - INFO - Worker process 93213 was killed by signal 15
distributed.nanny - INFO - Worker process 93243 was killed by signal 15
distributed.nanny - INFO - Worker process 93181 was killed by signal 15
distributed.nanny - INFO - Worker process 93208 was killed by signal 15
distributed.nanny - INFO - Worker process 93196 was killed by signal 15
distributed.nanny - INFO - Worker process 93214 was killed by signal 15
distributed.nanny - INFO - Worker process 93178 was killed by signal 15
distributed.nanny - INFO - Worker process 93248 was killed by signal 15
distributed.nanny - INFO - Worker process 93255 was killed by signal 15
distributed.nanny - INFO - Worker process 93251 was killed by signal 15
distributed.nanny - INFO - Worker process 93257 was killed by signal 15
distributed.nanny - INFO - Worker process 93260 was killed by signal 15
distributed.nanny - INFO - Worker process 93264 was killed by signal 15
distributed.nanny - INFO - Worker process 93277 was killed by signal 15
distributed.nanny - INFO - Worker process 93271 was killed by signal 15
distributed.nanny - INFO - Worker process 93279 was killed by signal 15
distributed.nanny - INFO - Worker process 93280 was killed by signal 15
distributed.nanny - INFO - Worker process 93274 was killed by signal 15
distributed.nanny - INFO - Worker process 93269 was killed by signal 15
distributed.nanny - INFO - Worker process 93284 was killed by signal 15
distributed.nanny - INFO - Worker process 93287 was killed by signal 15
distributed.nanny - INFO - Worker process 93292 was killed by signal 15
distributed.nanny - INFO - Worker process 93295 was killed by signal 15
distributed.nanny - INFO - Worker process 93300 was killed by signal 15
distributed.nanny - INFO - Worker process 93303 was killed by signal 15
distributed.nanny - INFO - Worker process 93307 was killed by signal 15
distributed.nanny - INFO - Worker process 93320 was killed by signal 15
distributed.nanny - INFO - Worker process 93309 was killed by signal 15
distributed.nanny - INFO - Worker process 93330 was killed by signal 15
distributed.nanny - INFO - Worker process 93314 was killed by signal 15
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93412 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93410 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93408 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93406 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93404 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93402 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93400 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93398 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93396 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93394 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93392 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93388 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93386 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93383 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93375 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93372 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93369 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93377 parent=93042 started daemon>
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO - Stopping worker
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93367 parent=93042 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=93360 parent=93042 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
    assert exitcode is not None
AssertionError
