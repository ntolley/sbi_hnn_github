distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:43713'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:36325'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:36935'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:37205'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:45705'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:44797'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:36689'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:42825'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:32859'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:46681'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:33597'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:46919'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:32813'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:45083'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:40133'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:45737'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:42091'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:46145'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:39201'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:38399'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:46909'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:40099'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:43971'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:45329'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:40023'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:43917'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:34617'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:46117'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:34817'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:44749'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:45349'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:44469'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:41995'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:43843'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:37769'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:34255'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:37629'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:44185'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:42401'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:39541'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:44011'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:42945'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:43995'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:40061'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:41961'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:43307'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:45781'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:47079'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:37891'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:42313'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:36335'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:36693'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:37141'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:38017'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:43103'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:34777'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:41707'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:34195'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:37889'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:45127'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:33561'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:33453'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:38191'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:38135'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:43405'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:42813'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:46297'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:39845'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:33427'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:44445'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:40979'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:35157'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:46617'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:43407'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:42195'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:46149'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:38855'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:38931'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:36981'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:34863'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:34369'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:39511'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:33973'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:40305'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:37637'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:41625'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:33423'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:46983'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:37113'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:40427'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:43465'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:45047'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:45035'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:37297'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:46647'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:33529'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:38873'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:40541'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:45399'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.147:39241'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:38735
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:45553
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:38735
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:45553
distributed.worker - INFO -          dashboard at:      198.202.103.147:34327
distributed.worker - INFO -          dashboard at:      198.202.103.147:39077
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-h8pci18n
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xy0pvemd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:41883
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:41883
distributed.worker - INFO -          dashboard at:      198.202.103.147:38025
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-bl077xxj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:41221
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:41221
distributed.worker - INFO -          dashboard at:      198.202.103.147:42331
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pveo1ixp
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:32777
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:32777
distributed.worker - INFO -          dashboard at:      198.202.103.147:37471
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3kr1728l
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:34973
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:39991
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:39991
distributed.worker - INFO -          dashboard at:      198.202.103.147:35845
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:34973
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:      198.202.103.147:33207
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4yxz9kgw
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8ii44xlo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:46605
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:46605
distributed.worker - INFO -          dashboard at:      198.202.103.147:38825
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:45821
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:45027
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:45821
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:45027
distributed.worker - INFO -          dashboard at:      198.202.103.147:44683
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:      198.202.103.147:35001
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7gmd_4l7
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-yzqk3_bu
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-2nc55ab_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:33267
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:33267
distributed.worker - INFO -          dashboard at:      198.202.103.147:40395
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-b3hpat7m
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:44119
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:44119
distributed.worker - INFO -          dashboard at:      198.202.103.147:47003
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-a1xabr_z
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:39005
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:39005
distributed.worker - INFO -          dashboard at:      198.202.103.147:45495
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-mocsa59p
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:38927
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:38927
distributed.worker - INFO -          dashboard at:      198.202.103.147:35945
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-l1icliul
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:37317
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:37317
distributed.worker - INFO -          dashboard at:      198.202.103.147:40067
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-b4j49aeo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:34735
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:34735
distributed.worker - INFO -          dashboard at:      198.202.103.147:39495
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9kzw8hbs
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:43953
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:43953
distributed.worker - INFO -          dashboard at:      198.202.103.147:44077
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-yw61eg_i
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:35493
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:35493
distributed.worker - INFO -          dashboard at:      198.202.103.147:40887
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-v58p6v4g
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:46655
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:46655
distributed.worker - INFO -          dashboard at:      198.202.103.147:35287
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-bwa026sd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:41243
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:41243
distributed.worker - INFO -          dashboard at:      198.202.103.147:40703
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gyh324vz
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:35015
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:35015
distributed.worker - INFO -          dashboard at:      198.202.103.147:38203
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-fc1wj6s2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:37363
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:37363
distributed.worker - INFO -          dashboard at:      198.202.103.147:36599
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-be2wuu7z
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:32811
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:32811
distributed.worker - INFO -          dashboard at:      198.202.103.147:44341
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-__x3186_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:40391
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:40391
distributed.worker - INFO -          dashboard at:      198.202.103.147:37941
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-em6xvqmq
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.147:39977
distributed.worker - INFO -          Listening to: tcp://198.202.103.147:39977
distributed.worker - INFO -          dashboard at:      198.202.103.147:45735
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-kj0dq4qo
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:43713'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:36325'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:36935'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:34735
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:37205'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:39977
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:45705'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:46605
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:44797'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:41221
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:45553
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:36689'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:42825'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:35493
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:32859'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:41883
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:46681'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:45027
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:33597'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:39005
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:46919'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:37363
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:32813'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:45821
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:45083'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:34973
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:40133'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:38735
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:45737'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:42091'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:46145'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:40391
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:39201'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:44119
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:38399'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:33267
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:46909'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:37317
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:40099'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:43953
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:43971'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:41243
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:45329'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:35015
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:40023'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:43917'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:32777
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:39991
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:34617'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:32811
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:46117'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:34817'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:44749'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:45349'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:44469'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:41995'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:43843'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:37769'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:34255'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:37629'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:44185'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:42401'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:39541'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:44011'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:42945'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:43995'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:40061'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:41961'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:43307'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:45781'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:47079'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:38927
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:37891'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:42313'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:36335'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:36693'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:37141'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:38017'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:43103'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:34777'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:41707'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:34195'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:37889'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:45127'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:33561'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:33453'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:38191'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:38135'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:43405'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:42813'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:46297'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:39845'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:33427'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:44445'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:40979'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:35157'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:46617'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:43407'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:42195'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:46149'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:38855'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:38931'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:36981'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:34863'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:34369'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:39511'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:33973'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:40305'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO - Stopping worker
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:37637'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:41625'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:33423'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:46983'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:37113'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:40427'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:43465'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:45047'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:45035'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:37297'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:46647'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:33529'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:38873'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:40541'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:45399'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.147:39241'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.147:46655
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 32748 was killed by signal 15
distributed.nanny - INFO - Worker process 32768 was killed by signal 15
distributed.nanny - INFO - Worker process 32822 was killed by signal 15
distributed.nanny - INFO - Worker process 32746 was killed by signal 15
distributed.nanny - INFO - Worker process 32780 was killed by signal 15
distributed.nanny - INFO - Worker process 32761 was killed by signal 15
distributed.nanny - INFO - Worker process 32825 was killed by signal 15
distributed.nanny - INFO - Worker process 32883 was killed by signal 15
distributed.nanny - INFO - Worker process 32789 was killed by signal 15
distributed.nanny - INFO - Worker process 32834 was killed by signal 15
distributed.nanny - INFO - Worker process 32838 was killed by signal 15
distributed.nanny - INFO - Worker process 32772 was killed by signal 15
distributed.nanny - INFO - Worker process 32852 was killed by signal 15
distributed.nanny - INFO - Worker process 32845 was killed by signal 15
distributed.nanny - INFO - Worker process 32782 was killed by signal 15
distributed.nanny - INFO - Worker process 32872 was killed by signal 15
distributed.nanny - INFO - Worker process 32800 was killed by signal 15
distributed.nanny - INFO - Worker process 32848 was killed by signal 15
distributed.nanny - INFO - Worker process 32868 was killed by signal 15
distributed.nanny - INFO - Worker process 32747 was killed by signal 15
distributed.nanny - INFO - Worker process 32873 was killed by signal 15
distributed.nanny - INFO - Worker process 32863 was killed by signal 15
distributed.nanny - INFO - Worker process 32856 was killed by signal 15
distributed.nanny - INFO - Worker process 32794 was killed by signal 15
distributed.nanny - INFO - Worker process 32819 was killed by signal 15
distributed.nanny - INFO - Worker process 32840 was killed by signal 15
distributed.nanny - INFO - Worker process 32844 was killed by signal 15
distributed.nanny - INFO - Worker process 32786 was killed by signal 15
distributed.nanny - INFO - Worker process 32792 was killed by signal 15
distributed.nanny - INFO - Worker process 32865 was killed by signal 15
distributed.nanny - INFO - Worker process 32889 was killed by signal 15
distributed.nanny - INFO - Worker process 32804 was killed by signal 15
distributed.nanny - INFO - Worker process 32893 was killed by signal 15
distributed.nanny - INFO - Worker process 32756 was killed by signal 15
distributed.nanny - INFO - Worker process 32764 was killed by signal 15
distributed.nanny - INFO - Worker process 32798 was killed by signal 15
distributed.nanny - INFO - Worker process 32885 was killed by signal 15
distributed.nanny - INFO - Worker process 32774 was killed by signal 15
distributed.nanny - INFO - Worker process 32829 was killed by signal 15
distributed.nanny - INFO - Worker process 32831 was killed by signal 15
distributed.nanny - INFO - Worker process 32777 was killed by signal 15
distributed.nanny - INFO - Worker process 32758 was killed by signal 15
distributed.nanny - INFO - Worker process 32898 was killed by signal 15
distributed.nanny - INFO - Worker process 32860 was killed by signal 15
distributed.nanny - INFO - Worker process 32879 was killed by signal 15
distributed.nanny - INFO - Worker process 32901 was killed by signal 15
distributed.nanny - INFO - Worker process 32896 was killed by signal 15
distributed.nanny - INFO - Worker process 32904 was killed by signal 15
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 32974 was killed by signal 15
distributed.nanny - INFO - Worker process 32916 was killed by signal 15
distributed.nanny - INFO - Worker process 32954 was killed by signal 15
distributed.nanny - INFO - Worker process 32924 was killed by signal 15
distributed.nanny - INFO - Worker process 32966 was killed by signal 15
distributed.nanny - INFO - Worker process 32935 was killed by signal 15
distributed.nanny - INFO - Worker process 32950 was killed by signal 15
distributed.nanny - INFO - Worker process 32962 was killed by signal 15
distributed.nanny - INFO - Worker process 32943 was killed by signal 15
distributed.nanny - INFO - Worker process 33016 was killed by signal 15
distributed.nanny - INFO - Worker process 33005 was killed by signal 15
distributed.nanny - INFO - Worker process 32977 was killed by signal 15
distributed.nanny - INFO - Worker process 33049 was killed by signal 15
distributed.nanny - INFO - Worker process 33012 was killed by signal 15
distributed.nanny - INFO - Worker process 32947 was killed by signal 15
distributed.nanny - INFO - Worker process 32968 was killed by signal 15
distributed.nanny - INFO - Worker process 33029 was killed by signal 15
distributed.nanny - INFO - Worker process 33061 was killed by signal 15
distributed.nanny - INFO - Worker process 33037 was killed by signal 15
distributed.nanny - INFO - Worker process 32981 was killed by signal 15
distributed.nanny - INFO - Worker process 32952 was killed by signal 15
distributed.nanny - INFO - Worker process 32988 was killed by signal 15
distributed.nanny - INFO - Worker process 33056 was killed by signal 15
distributed.nanny - INFO - Worker process 33048 was killed by signal 15
distributed.nanny - INFO - Worker process 33021 was killed by signal 15
distributed.nanny - INFO - Worker process 32912 was killed by signal 15
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
