distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:38291'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:45277'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:45569'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:37621'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:43169'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:42245'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:32923'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:39595'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:37005'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:32779'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:45619'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:39451'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:34011'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:34005'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:37655'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:33485'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:39963'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:36543'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:34889'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:41045'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:35177'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:42145'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:44589'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:36845'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:37667'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:35067'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:33635'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:39873'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:34221'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:39947'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:47095'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:37063'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:47081'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:41943'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:40873'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:33273'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:38133'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:35705'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:45887'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:37003'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:33355'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:36011'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:44327'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:42699'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:42659'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:38615'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:33955'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:44209'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:42513'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:34927'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:45027'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:46605'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:39089'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:44071'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:45125'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:44127'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:43725'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:36811'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:43321'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:38581'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:42669'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:41057'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:46927'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:44467'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:32867'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:43927'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:39907'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:37845'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:44339'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:41089'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:36061'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:44507'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:46139'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:42031'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:35417'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:43563'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:35285'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:41227'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:46177'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:42855'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:33057'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:39287'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:37189'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:35173'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:46621'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:43669'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:45359'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:39541'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:39805'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:34573'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:44331'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:33843'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:42657'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:38417'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:35531'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:33835'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:39885'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:43155'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:33495'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.38:40197'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:46275
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:46275
distributed.worker - INFO -          dashboard at:       198.202.103.38:38039
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-h7pqbs2w
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:38245
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:38245
distributed.worker - INFO -          dashboard at:       198.202.103.38:41549
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-fui7nr4h
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:42327
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:42327
distributed.worker - INFO -          dashboard at:       198.202.103.38:33159
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ze7zmgjm
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:42663
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:42663
distributed.worker - INFO -          dashboard at:       198.202.103.38:40979
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-cmqiodkh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:34077
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:34077
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:33175
distributed.worker - INFO -          dashboard at:       198.202.103.38:46421
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:33175
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:       198.202.103.38:37501
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gq_jk3jq
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6nww66el
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:33227
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:33227
distributed.worker - INFO -          dashboard at:       198.202.103.38:32889
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ec_k70ba
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:43373
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:43373
distributed.worker - INFO -          dashboard at:       198.202.103.38:35103
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-guaympuy
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:46035
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:46035
distributed.worker - INFO -          dashboard at:       198.202.103.38:33931
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gi21pxrg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:32937
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:32937
distributed.worker - INFO -          dashboard at:       198.202.103.38:42561
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_ibsxmi7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:35719
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:46671
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:34163
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:35719
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:34163
distributed.worker - INFO -          dashboard at:       198.202.103.38:44177
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:46671
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -          dashboard at:       198.202.103.38:39031
distributed.worker - INFO -          dashboard at:       198.202.103.38:33067
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-v_old27x
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4zuxzf91
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-x97ix4gf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:41011
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:41011
distributed.worker - INFO -          dashboard at:       198.202.103.38:36073
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qo06l77_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:37557
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:37557
distributed.worker - INFO -          dashboard at:       198.202.103.38:43739
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-547wftsh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:43099
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:43099
distributed.worker - INFO -          dashboard at:       198.202.103.38:42279
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0u7n__v8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:36511
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:36511
distributed.worker - INFO -          dashboard at:       198.202.103.38:42167
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-czeoqt3y
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:39015
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:39015
distributed.worker - INFO -          dashboard at:       198.202.103.38:34001
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-2ig68jt2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:37847
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:37847
distributed.worker - INFO -          dashboard at:       198.202.103.38:42901
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-epqd15fv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:33639
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:33639
distributed.worker - INFO -          dashboard at:       198.202.103.38:42213
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tr_mrwky
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:34263
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:34263
distributed.worker - INFO -          dashboard at:       198.202.103.38:37799
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xf29rm5x
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:43945
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:43945
distributed.worker - INFO -          dashboard at:       198.202.103.38:35323
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-mqw8xusl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:46969
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:46969
distributed.worker - INFO -          dashboard at:       198.202.103.38:36703
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-waoc24iv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:39421
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:39421
distributed.worker - INFO -          dashboard at:       198.202.103.38:39013
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-nbg_8qny
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:37113
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:37113
distributed.worker - INFO -          dashboard at:       198.202.103.38:33119
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9qryedpb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:42101
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:42101
distributed.worker - INFO -          dashboard at:       198.202.103.38:42493
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4cm41t2f
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:36359
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:36359
distributed.worker - INFO -          dashboard at:       198.202.103.38:36993
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_ugocdu3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:34575
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:34575
distributed.worker - INFO -          dashboard at:       198.202.103.38:35491
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-kzmh0qy9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:45273
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:45273
distributed.worker - INFO -          dashboard at:       198.202.103.38:35081
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-r4dw3ql7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:34031
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:34031
distributed.worker - INFO -          dashboard at:       198.202.103.38:45957
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-59ecns_5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:34717
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:34717
distributed.worker - INFO -          dashboard at:       198.202.103.38:33919
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-j6b5p478
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:45451
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:45451
distributed.worker - INFO -          dashboard at:       198.202.103.38:32869
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-22uipqlt
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:46677
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:46677
distributed.worker - INFO -          dashboard at:       198.202.103.38:41779
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-i6jodhx7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:33509
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:33509
distributed.worker - INFO -          dashboard at:       198.202.103.38:46365
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0itvq65f
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:41351
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:41351
distributed.worker - INFO -          dashboard at:       198.202.103.38:38013
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ybf54ykg
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:38291'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:45277'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:34077
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:45569'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:37621'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:42663
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:43169'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:33175
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:42245'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:42327
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:32923'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:38245
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:39595'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:33227
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:37005'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:46275
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:32779'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:43373
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:45619'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:32937
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:39451'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:46035
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:34011'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:35719
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:34005'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:34163
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:37655'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:37557
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:46671
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:33485'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:39963'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:41011
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:36543'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:34889'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:36511
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:34263
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:41045'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:43099
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:35177'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:37847
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:42145'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:45273
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:44589'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:33639
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:36845'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:37113
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:43945
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:37667'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:35067'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:39421
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:46969
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:33635'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:39873'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:36359
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:34221'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:34575
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:34717
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:39947'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:47095'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:42101
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:37063'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:45451
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:47081'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:46677
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:41943'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:33509
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:40873'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:34031
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:33273'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:38133'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:35705'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:45887'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:37003'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:33355'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:41351
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:36011'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:44327'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:42699'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:42659'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:38615'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:33955'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:44209'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:42513'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:34927'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:45027'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:46605'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:39089'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:44071'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:45125'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:44127'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:43725'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:36811'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:43321'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:38581'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:42669'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:41057'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:46927'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:44467'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:32867'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:43927'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:39907'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:37845'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:44339'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:41089'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:36061'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:44507'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:46139'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:42031'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:35417'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:43563'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:35285'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:41227'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:46177'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:42855'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:33057'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:39287'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:37189'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:35173'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:46621'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:39015
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:43669'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:45359'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:39541'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:39805'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:34573'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:44331'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:33843'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:42657'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:38417'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:35531'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:33835'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:39885'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:43155'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:33495'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.38:40197'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.38:40561
distributed.worker - INFO -          Listening to: tcp://198.202.103.38:40561
distributed.worker - INFO -          dashboard at:       198.202.103.38:42939
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7nk24st3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.38:40561
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 45952 was killed by signal 15
distributed.nanny - INFO - Worker process 45982 was killed by signal 15
distributed.nanny - INFO - Worker process 45978 was killed by signal 15
distributed.nanny - INFO - Worker process 45853 was killed by signal 15
distributed.nanny - INFO - Worker process 45987 was killed by signal 15
distributed.nanny - INFO - Worker process 45884 was killed by signal 15
distributed.nanny - INFO - Worker process 45859 was killed by signal 15
distributed.nanny - INFO - Worker process 45895 was killed by signal 15
distributed.nanny - INFO - Worker process 45931 was killed by signal 15
distributed.nanny - INFO - Worker process 45889 was killed by signal 15
distributed.nanny - INFO - Worker process 45862 was killed by signal 15
distributed.nanny - INFO - Worker process 45985 was killed by signal 15
distributed.nanny - INFO - Worker process 45974 was killed by signal 15
distributed.nanny - INFO - Worker process 45856 was killed by signal 15
distributed.nanny - INFO - Worker process 45899 was killed by signal 15
distributed.nanny - INFO - Worker process 45868 was killed by signal 15
distributed.nanny - INFO - Worker process 45865 was killed by signal 15
distributed.nanny - INFO - Worker process 45927 was killed by signal 15
distributed.nanny - INFO - Worker process 45909 was killed by signal 15
distributed.nanny - INFO - Worker process 45881 was killed by signal 15
distributed.nanny - INFO - Worker process 45872 was killed by signal 15
distributed.nanny - INFO - Worker process 45913 was killed by signal 15
distributed.nanny - INFO - Worker process 45916 was killed by signal 15
distributed.nanny - INFO - Worker process 45949 was killed by signal 15
distributed.nanny - INFO - Worker process 45934 was killed by signal 15
distributed.nanny - INFO - Worker process 45904 was killed by signal 15
distributed.nanny - INFO - Worker process 45943 was killed by signal 15
distributed.nanny - INFO - Worker process 45946 was killed by signal 15
distributed.nanny - INFO - Worker process 45919 was killed by signal 15
distributed.nanny - INFO - Worker process 45921 was killed by signal 15
distributed.nanny - INFO - Worker process 45997 was killed by signal 15
distributed.nanny - INFO - Worker process 45968 was killed by signal 15
distributed.nanny - INFO - Worker process 45957 was killed by signal 15
distributed.nanny - INFO - Worker process 45990 was killed by signal 15
distributed.nanny - INFO - Worker process 45995 was killed by signal 15
distributed.nanny - INFO - Worker process 45937 was killed by signal 15
distributed.nanny - INFO - Worker process 45893 was killed by signal 15
distributed.nanny - INFO - Worker process 45963 was killed by signal 15
distributed.nanny - INFO - Worker process 46006 was killed by signal 15
distributed.nanny - INFO - Worker process 46004 was killed by signal 15
distributed.nanny - INFO - Worker process 46008 was killed by signal 15
distributed.nanny - INFO - Worker process 46013 was killed by signal 15
distributed.nanny - INFO - Worker process 46016 was killed by signal 15
distributed.nanny - INFO - Worker process 46011 was killed by signal 15
distributed.nanny - INFO - Worker process 46019 was killed by signal 15
distributed.nanny - INFO - Worker process 46025 was killed by signal 15
distributed.nanny - INFO - Worker process 46053 was killed by signal 15
distributed.nanny - INFO - Worker process 46046 was killed by signal 15
distributed.nanny - INFO - Worker process 46059 was killed by signal 15
distributed.nanny - INFO - Worker process 46030 was killed by signal 15
distributed.nanny - INFO - Worker process 46027 was killed by signal 15
distributed.nanny - INFO - Worker process 46043 was killed by signal 15
distributed.nanny - INFO - Worker process 46077 was killed by signal 15
distributed.nanny - INFO - Worker process 46061 was killed by signal 15
distributed.nanny - INFO - Worker process 46069 was killed by signal 15
distributed.nanny - INFO - Worker process 46064 was killed by signal 15
distributed.nanny - INFO - Worker process 46056 was killed by signal 15
distributed.nanny - INFO - Worker process 46050 was killed by signal 15
distributed.nanny - INFO - Worker process 46072 was killed by signal 15
distributed.nanny - INFO - Worker process 46082 was killed by signal 15
distributed.nanny - INFO - Worker process 46084 was killed by signal 15
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 46088 was killed by signal 15
distributed.nanny - INFO - Worker process 46094 was killed by signal 15
distributed.nanny - INFO - Worker process 46101 was killed by signal 15
distributed.nanny - INFO - Worker process 46097 was killed by signal 15
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 46435 was killed by signal 15
distributed.nanny - INFO - Worker process 46441 was killed by signal 15
distributed.nanny - INFO - Worker process 46437 was killed by signal 15
distributed.nanny - INFO - Worker process 46397 was killed by signal 15
distributed.nanny - INFO - Worker process 45837 was killed by signal 15
distributed.nanny - INFO - Worker process 45965 was killed by signal 15
distributed.nanny - INFO - Worker process 45886 was killed by signal 15
distributed.nanny - INFO - Worker process 46398 was killed by signal 15
distributed.nanny - INFO - Worker process 45878 was killed by signal 15
distributed.nanny - INFO - Worker process 45840 was killed by signal 15
distributed.nanny - INFO - Worker process 45842 was killed by signal 15
distributed.nanny - INFO - Worker process 45847 was killed by signal 15
distributed.nanny - INFO - Worker process 45873 was killed by signal 15
distributed.nanny - INFO - Worker process 45838 was killed by signal 15
distributed.nanny - INFO - Worker process 45850 was killed by signal 15
distributed.nanny - INFO - Worker process 46393 was killed by signal 15
distributed.nanny - INFO - Worker process 46394 was killed by signal 15
distributed.nanny - INFO - Worker process 46104 was killed by signal 15
distributed.nanny - INFO - Worker process 46433 was killed by signal 15
distributed.nanny - INFO - Worker process 46449 was killed by signal 15
distributed.nanny - INFO - Worker process 46431 was killed by signal 15
distributed.nanny - INFO - Worker process 46444 was killed by signal 15
distributed.nanny - INFO - Worker process 46452 was killed by signal 15
distributed.nanny - INFO - Worker process 46454 was killed by signal 15
distributed.nanny - INFO - Worker process 46463 was killed by signal 15
distributed.nanny - INFO - Worker process 46459 was killed by signal 15
distributed.nanny - INFO - Worker process 46467 was killed by signal 15
distributed.nanny - INFO - Worker process 46473 was killed by signal 15
distributed.nanny - INFO - Worker process 46540 was killed by signal 15
distributed.nanny - INFO - Worker process 46542 was killed by signal 15
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
