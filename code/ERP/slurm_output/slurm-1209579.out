distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:36985'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:43207'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:42621'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:39261'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37765'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:36629'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:36309'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:35231'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38721'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:45891'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:35629'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:36655'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:41123'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:33705'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38865'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:43653'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:44143'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:41253'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:45877'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:35897'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34701'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37485'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:33527'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:42769'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:44997'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37647'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:41217'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:41915'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34317'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:41077'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:45221'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38009'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:39389'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:36599'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:39557'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38651'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:35121'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:33443'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38471'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37709'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:39375'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:46557'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:39651'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:46653'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37035'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:33007'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:35011'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:46677'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:42945'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38495'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:43557'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37615'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:45453'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38945'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:36809'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:44017'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:35425'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:42295'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:36079'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38167'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38579'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34893'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34821'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:45927'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:46133'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:39553'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:36243'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:41003'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:43053'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:33135'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:45217'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:36323'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37961'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:35869'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:46241'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:43061'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:44177'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:42297'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:39085'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:39491'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:46407'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34595'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:33253'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:40591'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38603'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:40109'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:45519'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:45593'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:40781'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:35829'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:36385'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34401'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:39457'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34141'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37099'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:43443'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34627'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:35193'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:42341'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:44131'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:39665
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:39665
distributed.worker - INFO -          dashboard at:      198.202.102.215:40551
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:43949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:43949
distributed.worker - INFO -          dashboard at:      198.202.102.215:40291
distributed.worker - INFO -               Threads:                          1
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:35867
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:37433
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:40313
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:35867
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:37433
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:35667
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-fjv3162z
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:40329
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:40313
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:44599
distributed.worker - INFO -          dashboard at:      198.202.102.215:42853
distributed.worker - INFO -          dashboard at:      198.202.102.215:37953
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:32847
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:35667
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:40329
distributed.worker - INFO -          dashboard at:      198.202.102.215:45945
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:44599
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:32847
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -          dashboard at:      198.202.102.215:33639
distributed.worker - INFO -          dashboard at:      198.202.102.215:39405
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -          dashboard at:      198.202.102.215:44739
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-07qk983y
distributed.worker - INFO -          dashboard at:      198.202.102.215:40783
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9ih11pev
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-f1zp0sp4
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-wryrw2sw
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hddzvgbw
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-589op2xo
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1093wt63
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-j9e81p8y
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:34119
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:34119
distributed.worker - INFO -          dashboard at:      198.202.102.215:33137
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-igbt7fbh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:42299
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:42299
distributed.worker - INFO -          dashboard at:      198.202.102.215:42313
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zihd58vb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:34635
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:34635
distributed.worker - INFO -          dashboard at:      198.202.102.215:38419
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-asdcs4he
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:44209
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:44209
distributed.worker - INFO -          dashboard at:      198.202.102.215:38213
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-f8z293ha
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:35101
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:35101
distributed.worker - INFO -          dashboard at:      198.202.102.215:42017
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_1gd_47y
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:44987
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:44987
distributed.worker - INFO -          dashboard at:      198.202.102.215:33859
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9wkvohkx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:37805
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:37805
distributed.worker - INFO -          dashboard at:      198.202.102.215:36117
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-jn5xjl7a
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:44999
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:44999
distributed.worker - INFO -          dashboard at:      198.202.102.215:38847
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gzunq8_y
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:36359
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:36359
distributed.worker - INFO -          dashboard at:      198.202.102.215:42619
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-t_4duea_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:41251
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:41251
distributed.worker - INFO -          dashboard at:      198.202.102.215:42411
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-z9pt0pa7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:41109
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:41109
distributed.worker - INFO -          dashboard at:      198.202.102.215:41463
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1zvopp05
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:46925
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:46925
distributed.worker - INFO -          dashboard at:      198.202.102.215:38387
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4wvs57p0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:36937
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:36937
distributed.worker - INFO -          dashboard at:      198.202.102.215:42597
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6rdfamke
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:43579
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:43579
distributed.worker - INFO -          dashboard at:      198.202.102.215:43195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-maiq_xf7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:39601
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:39601
distributed.worker - INFO -          dashboard at:      198.202.102.215:37153
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-fvh4hupb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:42095
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:42095
distributed.worker - INFO -          dashboard at:      198.202.102.215:46807
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-39bu3hkj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:45235
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:45235
distributed.worker - INFO -          dashboard at:      198.202.102.215:37271
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3ib8p4ql
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:34689
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:34689
distributed.worker - INFO -          dashboard at:      198.202.102.215:38927
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-wafr66n5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:45063
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:45063
distributed.worker - INFO -          dashboard at:      198.202.102.215:39743
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pidatk2u
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:42739
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:42739
distributed.worker - INFO -          dashboard at:      198.202.102.215:38543
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_7b22ds6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:42827
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:42827
distributed.worker - INFO -          dashboard at:      198.202.102.215:34479
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-js896_86
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:37359
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:37359
distributed.worker - INFO -          dashboard at:      198.202.102.215:41771
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-dj9asjs7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:45117
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:45117
distributed.worker - INFO -          dashboard at:      198.202.102.215:33401
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1n1da8x0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:42969
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:42969
distributed.worker - INFO -          dashboard at:      198.202.102.215:39081
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7j3ee1iv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:43545
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:43545
distributed.worker - INFO -          dashboard at:      198.202.102.215:35975
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7xk4zm_1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:39489
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:39489
distributed.worker - INFO -          dashboard at:      198.202.102.215:41437
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ujti4_ir
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:44003
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:44003
distributed.worker - INFO -          dashboard at:      198.202.102.215:34145
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-edeu_yf1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:41401
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:41401
distributed.worker - INFO -          dashboard at:      198.202.102.215:34157
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-11tz7vmw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:37643
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:37643
distributed.worker - INFO -          dashboard at:      198.202.102.215:41835
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-u_rmj0r2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:39715
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:39715
distributed.worker - INFO -          dashboard at:      198.202.102.215:37059
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4yz9umyb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:38947
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:38947
distributed.worker - INFO -          dashboard at:      198.202.102.215:36253
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4fkktco1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:39087
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:39087
distributed.worker - INFO -          dashboard at:      198.202.102.215:44765
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xjx29q5r
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:35559
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:35559
distributed.worker - INFO -          dashboard at:      198.202.102.215:36331
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gda1f9xu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:44865
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:44865
distributed.worker - INFO -          dashboard at:      198.202.102.215:46409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ox1kre4p
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:35007
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:35007
distributed.worker - INFO -          dashboard at:      198.202.102.215:35741
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-y334pkgn
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:34189
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:34189
distributed.worker - INFO -          dashboard at:      198.202.102.215:41445
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-f1crol6n
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:35913
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:35913
distributed.worker - INFO -          dashboard at:      198.202.102.215:39765
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-k7kc4bvp
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:41363
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:41363
distributed.worker - INFO -          dashboard at:      198.202.102.215:43127
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-u50qfswn
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:46219
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:46219
distributed.worker - INFO -          dashboard at:      198.202.102.215:45705
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-iafdujmm
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:34155
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:34155
distributed.worker - INFO -          dashboard at:      198.202.102.215:41393
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xctocqrs
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:41737
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:41737
distributed.worker - INFO -          dashboard at:      198.202.102.215:46643
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hytopupo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:42895
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:42895
distributed.worker - INFO -          dashboard at:      198.202.102.215:37547
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-cjml5abw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:39937
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:39937
distributed.worker - INFO -          dashboard at:      198.202.102.215:35227
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ozbbae30
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:35591
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:35591
distributed.worker - INFO -          dashboard at:      198.202.102.215:42959
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-owo63ok3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:34959
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:34959
distributed.worker - INFO -          dashboard at:      198.202.102.215:43747
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3o_htilw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:34149
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:34149
distributed.worker - INFO -          dashboard at:      198.202.102.215:37933
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9bnou83a
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:39653
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:39653
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.102.215:33879
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-o8v3ykt4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:43583
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:43583
distributed.worker - INFO -          dashboard at:      198.202.102.215:44921
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-l92l1771
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:40171
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:40171
distributed.worker - INFO -          dashboard at:      198.202.102.215:43071
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-790hu4iw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:46285
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:46285
distributed.worker - INFO -          dashboard at:      198.202.102.215:42707
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-lfiqflrf
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:46067
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:46067
distributed.worker - INFO -          dashboard at:      198.202.102.215:34499
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vrzj8iuj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:33033
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:33033
distributed.worker - INFO -          dashboard at:      198.202.102.215:38849
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-z_7k5z39
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:38627
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:38627
distributed.worker - INFO -          dashboard at:      198.202.102.215:37467
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-r9wub8rv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:43163
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:43163
distributed.worker - INFO -          dashboard at:      198.202.102.215:41323
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-k070a5_6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:34409
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:34409
distributed.worker - INFO -          dashboard at:      198.202.102.215:32913
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-kyw958tv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:33187
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:33187
distributed.worker - INFO -          dashboard at:      198.202.102.215:36557
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-b5ywe6rk
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:44591
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:44591
distributed.worker - INFO -          dashboard at:      198.202.102.215:43923
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-yc_erkjo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:33079
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:33079
distributed.worker - INFO -          dashboard at:      198.202.102.215:42877
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xcqv50p1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:33509
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:33509
distributed.worker - INFO -          dashboard at:      198.202.102.215:34007
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_euha9mi
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:43165
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:43165
distributed.worker - INFO -          dashboard at:      198.202.102.215:33737
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0j66w51l
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:39917
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:39917
distributed.worker - INFO -          dashboard at:      198.202.102.215:39607
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0fj2atxe
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:34283
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:34283
distributed.worker - INFO -          dashboard at:      198.202.102.215:38333
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-nmnemao6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:39127
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:39127
distributed.worker - INFO -          dashboard at:      198.202.102.215:38647
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-cy83bof3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:35871
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:35871
distributed.worker - INFO -          dashboard at:      198.202.102.215:40537
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-t0pic79l
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:46327
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:46327
distributed.worker - INFO -          dashboard at:      198.202.102.215:34981
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pfl8oh_o
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:41383
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:41383
distributed.worker - INFO -          dashboard at:      198.202.102.215:36949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-q2di1ubu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:43655
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:43655
distributed.worker - INFO -          dashboard at:      198.202.102.215:43935
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-e54lv2q6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:41541
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:41541
distributed.worker - INFO -          dashboard at:      198.202.102.215:41625
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-wqn9ds09
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:36329
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:36329
distributed.worker - INFO -          dashboard at:      198.202.102.215:38767
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gts75b77
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:35217
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:35217
distributed.worker - INFO -          dashboard at:      198.202.102.215:45153
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-muxqyaa8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:37393
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:37393
distributed.worker - INFO -          dashboard at:      198.202.102.215:43989
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-e6lls0t0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:33341
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:33341
distributed.worker - INFO -          dashboard at:      198.202.102.215:36951
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-kbyna2qo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:44165
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:44165
distributed.worker - INFO -          dashboard at:      198.202.102.215:34455
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4f8gbqe0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:46239
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:46239
distributed.worker - INFO -          dashboard at:      198.202.102.215:39529
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6xpu9j0g
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:42377
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:42377
distributed.worker - INFO -          dashboard at:      198.202.102.215:39541
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-rf56zeat
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:33353
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:33353
distributed.worker - INFO -          dashboard at:      198.202.102.215:33647
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5o4fpa4n
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:41315
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:41315
distributed.worker - INFO -          dashboard at:      198.202.102.215:45349
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-eenj0bw_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:43191
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:43191
distributed.worker - INFO -          dashboard at:      198.202.102.215:44151
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4_6zzyob
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:38939
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:38939
distributed.worker - INFO -          dashboard at:      198.202.102.215:34241
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-jyzl7984
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:46261
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:46261
distributed.worker - INFO -          dashboard at:      198.202.102.215:46589
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-uzez5v_9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:44929
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:44929
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:34131
distributed.worker - INFO -          dashboard at:      198.202.102.215:44919
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:34131
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -          dashboard at:      198.202.102.215:42151
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-n_zrhsi1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vj1ivha4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:41403
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:41403
distributed.worker - INFO -          dashboard at:      198.202.102.215:46881
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-noxol8hs
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:37427
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:37427
distributed.worker - INFO -          dashboard at:      198.202.102.215:34183
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-rm8dyyiz
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:46247
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:46247
distributed.worker - INFO -          dashboard at:      198.202.102.215:46361
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3id1oka5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:46011
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:46011
distributed.worker - INFO -          dashboard at:      198.202.102.215:45043
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xp1mx6ic
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:41155
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:41155
distributed.worker - INFO -          dashboard at:      198.202.102.215:35415
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ze1uqfx2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:34809
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:34809
distributed.worker - INFO -          dashboard at:      198.202.102.215:33925
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5zl0ywcg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:39833
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:39833
distributed.worker - INFO -          dashboard at:      198.202.102.215:43857
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9qabq14x
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:46451
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:46451
distributed.worker - INFO -          dashboard at:      198.202.102.215:44733
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-sl2srv9n
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:37929
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:37929
distributed.worker - INFO -          dashboard at:      198.202.102.215:46329
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-l5vbfaj7
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:36985'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:43207'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:42621'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:35101
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:39261'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:39937
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37765'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:36629'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:37433
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:45063
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:39665
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:46219
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:36309'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:35231'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:44987
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38721'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:45891'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:35629'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:43583
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:36655'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:37643
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:42299
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:41123'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:39489
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:33705'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:35667
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38865'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:35007
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:43653'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:39653
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:44143'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:41253'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:46285
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:40171
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:35867
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:34155
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:45877'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:35897'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34701'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37485'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:44003
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:43579
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:33527'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:43163
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:42769'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:37805
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:44997'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37647'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:33079
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:41217'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:39715
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:36359
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:41915'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:41109
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34317'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:44599
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:41077'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:34409
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:45221'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:41737
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38009'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:39389'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:37359
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:35591
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:36599'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:32847
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:39557'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:38947
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38651'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:33187
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:35121'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:41363
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:33443'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:33033
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38471'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37709'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:40329
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:39375'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:43949
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:41251
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:46557'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:38627
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:39651'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:46653'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:35559
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:34119
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:44209
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:41401
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37035'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:33007'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:35011'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:42969
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:46677'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:42945'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:42827
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:44865
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38495'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:43557'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:34149
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37615'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:46925
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:45453'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:36937
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:40313
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38945'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:42739
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:36809'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:34959
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:44017'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:34189
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:35425'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:34635
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:42295'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:34689
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:36079'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:39087
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38167'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:45235
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38579'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:45117
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34893'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34821'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:35913
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:45927'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:46067
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:42095
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:43545
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:46133'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:39601
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:39553'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:36243'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:34283
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:41003'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:43053'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:42895
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:44591
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:33135'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:44999
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:45217'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:39127
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:36323'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:33509
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37961'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:41383
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:35869'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:43165
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:46241'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:39917
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:43061'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:35871
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:44177'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:46327
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:42297'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:35217
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:39085'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:36329
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:41541
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:43655
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:39491'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:46407'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34595'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:33253'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:33341
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:44165
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:40591'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:38939
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38603'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:40109'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:37393
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:42377
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:45519'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:45593'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:46239
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:33353
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:40781'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:41315
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:35829'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:44929
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:36385'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34401'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:43191
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:41403
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:46261
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:39457'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34141'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:46247
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37099'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:39833
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:43443'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:34131
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34627'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:41155
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:35193'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:46011
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:42341'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:37427
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:44131'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:34809
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:46451
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:37929
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47004 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46997 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46993 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46989 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46981 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46984 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46972 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46974 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46961 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46968 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46957 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46937 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46952 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46941 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46926 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46930 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46928 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46920 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46933 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46915 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46917 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46909 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46903 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46902 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46898 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46893 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46906 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46896 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46888 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46886 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46882 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46877 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46866 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46868 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46863 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46871 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46861 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46858 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46852 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46856 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46849 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46843 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46834 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46832 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46827 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46826 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46820 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46829 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46824 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46814 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46810 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46816 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46802 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46804 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46800 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46793 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46794 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46796 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46787 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46784 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46779 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46781 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46776 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46770 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46768 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46765 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46760 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46758 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46762 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46752 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46750 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46747 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46744 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46740 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46738 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46735 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46730 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46729 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46727 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46721 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46719 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46716 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46714 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46710 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46707 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46703 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46701 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46696 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46698 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46691 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46688 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46685 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46683 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46679 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46677 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46674 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46669 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46666 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46670 parent=46585 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46664 parent=46585 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
    assert exitcode is not None
AssertionError
