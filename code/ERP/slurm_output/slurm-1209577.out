distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:46013'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:35051'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:43521'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:34573'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:46373'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:34197'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:37621'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:44641'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:39149'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:41803'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:33535'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:34723'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:46025'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:42031'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:33433'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:32889'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:38055'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:34087'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:36869'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:34441'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:33235'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:41777'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:45785'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:44469'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:39795'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:37639'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:34251'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:45475'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:37267'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:37595'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:35839'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:43741'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:42435'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:33369'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:36727'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:34711'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:34043'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:36163'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:34403'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:35027'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:36501'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:35035'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:33201'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:37357'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:38291'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:34155'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:39673'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:40419'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:45721'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:44833'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:45873'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:34499'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:41685'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:41361'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:46359'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:44081'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:37871'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:38633'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:35591'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:43299'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:46407'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:41315'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:43987'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:35799'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:34405'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:38777'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:44949'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:42851'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:39125'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:43711'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:44487'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:36191'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:42503'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:35593'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:36391'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:33491'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:38683'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:33857'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:35811'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:38001'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:37137'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:37945'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:46753'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:36827'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:33467'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:36765'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:44911'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:36487'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:46357'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:45841'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:37341'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:35779'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:42779'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:37833'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:47007'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:43031'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:36761'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:45615'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:39659'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.149:38425'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:33827
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:43985
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:33827
distributed.worker - INFO -          dashboard at:      198.202.103.149:41185
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:43985
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:      198.202.103.149:41821
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8eql3ino
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-dcnv3qg6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:33513
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:33513
distributed.worker - INFO -          dashboard at:      198.202.103.149:40255
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-oe8dn7kh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:43489
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:43489
distributed.worker - INFO -          dashboard at:      198.202.103.149:42649
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-dg__6hec
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:46709
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:46709
distributed.worker - INFO -          dashboard at:      198.202.103.149:44999
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-wnw1ag16
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:41229
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:41229
distributed.worker - INFO -          dashboard at:      198.202.103.149:44467
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-df6wuspq
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:45709
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:45709
distributed.worker - INFO -          dashboard at:      198.202.103.149:35161
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-k4j3iy5x
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:37645
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:37645
distributed.worker - INFO -          dashboard at:      198.202.103.149:41367
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8aourh4t
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:46835
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:46835
distributed.worker - INFO -          dashboard at:      198.202.103.149:38423
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hv2vf5c_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:46007
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:46007
distributed.worker - INFO -          dashboard at:      198.202.103.149:44061
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tprlyp6l
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:46351
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:46351
distributed.worker - INFO -          dashboard at:      198.202.103.149:45937
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-lw59ohve
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:39117
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:39117
distributed.worker - INFO -          dashboard at:      198.202.103.149:37459
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-d9l53wvg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:42525
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:42525
distributed.worker - INFO -          dashboard at:      198.202.103.149:41763
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-eqpv6twi
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:45277
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:45277
distributed.worker - INFO -          dashboard at:      198.202.103.149:33353
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4a9sbu4b
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:42177
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:42177
distributed.worker - INFO -          dashboard at:      198.202.103.149:36545
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-cqh0hvaf
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:38655
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:38655
distributed.worker - INFO -          dashboard at:      198.202.103.149:42863
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-sva6iwsz
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:45749
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:45749
distributed.worker - INFO -          dashboard at:      198.202.103.149:45061
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4_p31qki
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:40095
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:40095
distributed.worker - INFO -          dashboard at:      198.202.103.149:35419
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-khko6iao
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:46013'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:35051'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:43521'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:41229
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:46709
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:34573'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:43489
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:46373'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:34197'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:33827
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:37621'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:33513
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:43985
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:37645
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:44641'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:39149'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:41803'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:33535'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:46835
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:45709
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:34723'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:46025'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:46007
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:42525
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:42031'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:39117
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:33433'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:32889'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:45277
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:38055'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:46351
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:38655
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:42177
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:34087'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:40095
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:36869'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:45749
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:34441'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:33235'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:41777'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:45785'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:44469'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:39795'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:37639'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:34251'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:45475'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:37267'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:37595'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:35839'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:43741'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:42435'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:33369'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:36727'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:34711'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:34043'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:36163'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:34403'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:35027'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:36501'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:35035'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:33201'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:37357'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:38291'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:34155'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:39673'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:40419'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:45721'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:44833'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:45873'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:34499'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:41685'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:41361'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:46359'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:44081'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:37871'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:38633'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:35591'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:43299'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:46407'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:41315'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:43987'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:35799'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:34405'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:38777'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:44949'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:42851'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:39125'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:43711'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:44487'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:36191'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:42503'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:35593'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:36391'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:33491'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:38683'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:33857'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:35811'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:38001'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:37137'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:37945'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:46753'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:36827'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:33467'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:36765'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:44911'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:36487'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:46357'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:45841'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:37341'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:35779'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:42779'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:37833'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:47007'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:43031'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:36761'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:45615'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:39659'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.149:38425'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:45161
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:45161
distributed.worker - INFO -          dashboard at:      198.202.103.149:32997
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ecp_h98k
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:45161
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:34009
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:34009
distributed.worker - INFO -          dashboard at:      198.202.103.149:42151
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-j5ojaiok
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:34009
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:41813
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:41813
distributed.worker - INFO -          dashboard at:      198.202.103.149:43803
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-2ga8wcqa
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:41813
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:41095
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:41095
distributed.worker - INFO -          dashboard at:      198.202.103.149:37641
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9enrwts5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:41095
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:43997
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:43997
distributed.worker - INFO -          dashboard at:      198.202.103.149:41901
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-l_5_9__x
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:43997
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:33865
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:33865
distributed.worker - INFO -          dashboard at:      198.202.103.149:43565
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-uiumc01j
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:33865
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:41205
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:41205
distributed.worker - INFO -          dashboard at:      198.202.103.149:46245
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-324ich7m
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:41205
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:46187
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:46187
distributed.worker - INFO -          dashboard at:      198.202.103.149:38089
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-nfz93qqm
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:46187
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:35127
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:35127
distributed.worker - INFO -          dashboard at:      198.202.103.149:44253
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ytc25id9
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:35127
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:46437
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:46437
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:36425
distributed.worker - INFO -          dashboard at:      198.202.103.149:34777
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:36425
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.103.149:37321
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-h_2dofgm
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-k1jm6vef
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:36425
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:46437
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:45441
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:45441
distributed.worker - INFO -          dashboard at:      198.202.103.149:33981
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-dlw2wtoe
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:45441
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69424 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69422 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69420 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69352 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69349 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69282 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69279 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69277 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69275 parent=68633 started daemon>
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:37141
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:43101
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69264 parent=68633 started daemon>
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:37141
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:33547
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:40723
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:45163
distributed.worker - INFO -          dashboard at:      198.202.103.149:46261
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:33547
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:40723
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:43101
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -          dashboard at:      198.202.103.149:44167
distributed.worker - INFO -          dashboard at:      198.202.103.149:36069
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:45163
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -          dashboard at:      198.202.103.149:38067
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.103.149:37803
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-w38ia1b3
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8n202hqw
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-82ashzyz
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-isbadvf8
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4ywjodwl
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:37141
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:33547
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:45163
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:43101
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:40723
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69272 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69221 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69267 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69262 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69270 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69122 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=69000 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68997 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68994 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68990 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68985 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68982 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68976 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68973 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68970 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68966 parent=68633 started daemon>
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:33079
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:44509
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:37557
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:45889
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:34443
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:44509
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:46173
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:33079
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:37557
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:35559
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:45889
distributed.worker - INFO -          dashboard at:      198.202.103.149:35037
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:33501
distributed.worker - INFO -          dashboard at:      198.202.103.149:37437
distributed.worker - INFO -          dashboard at:      198.202.103.149:40887
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:34443
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68962 parent=68633 started daemon>
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:46173
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:35559
distributed.worker - INFO -          dashboard at:      198.202.103.149:42003
distributed.worker - INFO -          dashboard at:      198.202.103.149:36265
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:33501
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.103.149:44491
distributed.worker - INFO -          dashboard at:      198.202.103.149:35341
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -          dashboard at:      198.202.103.149:41621
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ool5nmkc
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-d90pon4t
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68959 parent=68633 started daemon>
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tb2tewur
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zvyge03w
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-89b_xv70
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-h4j6qh87
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-2hogvxkr
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68956 parent=68633 started daemon>
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:44509
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-llpq8du5
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:34443
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:33079
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:45889
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:46173
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:33501
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68953 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68949 parent=68633 started daemon>
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:35559
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:37557
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68943 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68947 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68938 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68934 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68930 parent=68633 started daemon>
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:40305
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:44481
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:44909
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:46579
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:44481
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:44295
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68926 parent=68633 started daemon>
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:44909
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:40305
distributed.worker - INFO -          dashboard at:      198.202.103.149:41847
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -          dashboard at:      198.202.103.149:44045
distributed.worker - INFO -          dashboard at:      198.202.103.149:44401
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:44295
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO -          dashboard at:      198.202.103.149:34633
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:46579
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-mu2sslui
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -          dashboard at:      198.202.103.149:45523
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9wj1cy_1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-oglfm830
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7ak59cis
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pyyzmdi0
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68922 parent=68633 started daemon>
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:44481
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68917 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68910 parent=68633 started daemon>
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:44909
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:44295
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:40305
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:46579
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68913 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68907 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68891 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68889 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68886 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68893 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68884 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68895 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68899 parent=68633 started daemon>
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.149:33531
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68871 parent=68633 started daemon>
distributed.worker - INFO -          Listening to: tcp://198.202.103.149:33531
distributed.worker - INFO -          dashboard at:      198.202.103.149:40211
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68870 parent=68633 started daemon>
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-g3_2_ph5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.149:33531
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68868 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68866 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68861 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68864 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68856 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68845 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68849 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68840 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68838 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68832 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68834 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68826 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68823 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68819 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68816 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68810 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68802 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68807 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68799 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68796 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68791 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68789 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68782 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68780 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68777 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68774 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68771 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68768 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68764 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68762 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68760 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68757 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68752 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68750 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68746 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68742 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68743 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68737 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68735 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68732 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68728 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68727 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68722 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68720 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68718 parent=68633 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=68713 parent=68633 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
