distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:35733'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:37661'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:44859'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:36715'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:33625'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:38243'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:37029'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:34183'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:41517'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:38307'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:37773'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:44659'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:46425'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:35067'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:44945'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:41111'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:33377'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:43141'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:36101'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:36977'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:34133'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:40435'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:46013'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:46871'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:36471'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:35177'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:35727'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:41271'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:35839'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:39293'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:42399'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:34159'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:46157'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:35363'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:41453'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:45567'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:32845'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:39381'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:42949'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:34603'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:38649'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:36757'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:37601'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:44409'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:45861'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:43651'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:46519'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:41519'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:34375'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:39705'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:44639'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:46309'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:40721'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:37605'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:42251'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:40671'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:41025'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:42729'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:39025'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:42017'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:35157'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:34421'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:46397'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:33001'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:45129'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:39363'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:43961'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:33873'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:34911'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:39999'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:46543'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:34901'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:39571'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:44827'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:40309'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:38225'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:42047'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:44861'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:43097'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:34339'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:42971'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:46439'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:39289'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:38157'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:43055'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:40819'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:38105'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:37101'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:41181'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:34029'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:45025'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:35109'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:35089'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:33431'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:43873'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:36653'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:40573'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:37307'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:43057'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.148:43265'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:43117
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:43117
distributed.worker - INFO -          dashboard at:      198.202.101.148:36613
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4negk2fr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:40059
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:40059
distributed.worker - INFO -          dashboard at:      198.202.101.148:39843
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-t4_7piym
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:37321
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:37321
distributed.worker - INFO -          dashboard at:      198.202.101.148:41441
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-v07s8ogw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:42009
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:42009
distributed.worker - INFO -          dashboard at:      198.202.101.148:43725
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-rciiodul
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:33249
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:33249
distributed.worker - INFO -          dashboard at:      198.202.101.148:46665
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5t8dxcsc
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:41727
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:41727
distributed.worker - INFO -          dashboard at:      198.202.101.148:36331
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-c2fy12ym
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:47053
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:47053
distributed.worker - INFO -          dashboard at:      198.202.101.148:39491
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-r6s9y2xn
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:43959
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:43959
distributed.worker - INFO -          dashboard at:      198.202.101.148:43069
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_cnged8w
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:40189
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:40189
distributed.worker - INFO -          dashboard at:      198.202.101.148:37991
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-02ki8cui
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:38511
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:38511
distributed.worker - INFO -          dashboard at:      198.202.101.148:40271
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pko14n9y
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:42339
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:42339
distributed.worker - INFO -          dashboard at:      198.202.101.148:46649
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-f32nw1w9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:43709
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:43709
distributed.worker - INFO -          dashboard at:      198.202.101.148:43077
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7kyvky_f
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:39165
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:39165
distributed.worker - INFO -          dashboard at:      198.202.101.148:37079
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-earuk9hf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:35701
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:35701
distributed.worker - INFO -          dashboard at:      198.202.101.148:38107
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_7j8tlhf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:41345
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:41345
distributed.worker - INFO -          dashboard at:      198.202.101.148:34549
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-02774_1q
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:46435
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:46435
distributed.worker - INFO -          dashboard at:      198.202.101.148:37123
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9dryo7q2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:45497
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:45497
distributed.worker - INFO -          dashboard at:      198.202.101.148:38001
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3gmhrzop
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:38309
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:38309
distributed.worker - INFO -          dashboard at:      198.202.101.148:33871
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-h5a56c8y
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:37561
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:37561
distributed.worker - INFO -          dashboard at:      198.202.101.148:38003
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-c1y0cdio
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:46745
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:46745
distributed.worker - INFO -          dashboard at:      198.202.101.148:40139
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7k52lkna
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:46265
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:46265
distributed.worker - INFO -          dashboard at:      198.202.101.148:43061
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-nr9jq3e6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:32887
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:32887
distributed.worker - INFO -          dashboard at:      198.202.101.148:41785
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-nmwfbe_a
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:45621
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:45621
distributed.worker - INFO -          dashboard at:      198.202.101.148:39863
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-kv1dgcvw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:35787
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:35787
distributed.worker - INFO -          dashboard at:      198.202.101.148:46237
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:42257
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:42257
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_dh0jsx2
distributed.worker - INFO -          dashboard at:      198.202.101.148:41999
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-y5grf_bs
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:35783
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:35783
distributed.worker - INFO -          dashboard at:      198.202.101.148:36995
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tdg8re0_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:36651
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:36651
distributed.worker - INFO -          dashboard at:      198.202.101.148:36713
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vp7ubl6z
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:41147
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:41147
distributed.worker - INFO -          dashboard at:      198.202.101.148:37883
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-kn_ipn14
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:39011
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:39011
distributed.worker - INFO -          dashboard at:      198.202.101.148:44001
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_1e4p0dw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:34747
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:34747
distributed.worker - INFO -          dashboard at:      198.202.101.148:35583
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-d4fol8m_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:42347
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:42347
distributed.worker - INFO -          dashboard at:      198.202.101.148:40669
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-wgm0lp2l
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:32939
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:32939
distributed.worker - INFO -          dashboard at:      198.202.101.148:34191
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-m2cxoyx9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:41745
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:41745
distributed.worker - INFO -          dashboard at:      198.202.101.148:44501
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-c2qbzpjo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:37961
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:37961
distributed.worker - INFO -          dashboard at:      198.202.101.148:35617
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-s6gmr5p4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:41751
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:41751
distributed.worker - INFO -          dashboard at:      198.202.101.148:44421
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-rmf6573y
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:45859
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:45859
distributed.worker - INFO -          dashboard at:      198.202.101.148:42973
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-773_i1lj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:40103
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:40103
distributed.worker - INFO -          dashboard at:      198.202.101.148:39555
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-65d1kb8y
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:34641
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:34641
distributed.worker - INFO -          dashboard at:      198.202.101.148:39825
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-sik9jgcj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:46747
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:46747
distributed.worker - INFO -          dashboard at:      198.202.101.148:35275
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hyv9559o
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:33765
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:33765
distributed.worker - INFO -          dashboard at:      198.202.101.148:39139
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-n5ke62sd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:42649
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:42649
distributed.worker - INFO -          dashboard at:      198.202.101.148:46503
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7r__68t2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:39385
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:39385
distributed.worker - INFO -          dashboard at:      198.202.101.148:38723
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hvan2o50
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:33655
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:33655
distributed.worker - INFO -          dashboard at:      198.202.101.148:45457
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ua7gzzm_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:41965
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:41965
distributed.worker - INFO -          dashboard at:      198.202.101.148:39101
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-oywiewcr
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:41281
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:41281
distributed.worker - INFO -          dashboard at:      198.202.101.148:38849
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-81zcak9o
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:42583
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:42583
distributed.worker - INFO -          dashboard at:      198.202.101.148:39629
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-04o5hzcd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:36595
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:36595
distributed.worker - INFO -          dashboard at:      198.202.101.148:44959
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-eef0epww
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:39673
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:39673
distributed.worker - INFO -          dashboard at:      198.202.101.148:43853
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-yd62bhin
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:33457
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:33457
distributed.worker - INFO -          dashboard at:      198.202.101.148:40445
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-y52r6l02
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:38565
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:38565
distributed.worker - INFO -          dashboard at:      198.202.101.148:38539
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-50_sad8w
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:36323
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:36323
distributed.worker - INFO -          dashboard at:      198.202.101.148:42579
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6pywy56f
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:43049
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:43049
distributed.worker - INFO -          dashboard at:      198.202.101.148:35977
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hhpcg9gd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:35099
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:35099
distributed.worker - INFO -          dashboard at:      198.202.101.148:41417
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-kt8e4nep
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:37943
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:37943
distributed.worker - INFO -          dashboard at:      198.202.101.148:45219
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tt25iq0w
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:33403
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:33403
distributed.worker - INFO -          dashboard at:      198.202.101.148:39593
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-v5p6fisf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:40953
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:40953
distributed.worker - INFO -          dashboard at:      198.202.101.148:46133
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8tt1vz4t
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:35735
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:35735
distributed.worker - INFO -          dashboard at:      198.202.101.148:45633
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-298l7uta
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:33979
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:33979
distributed.worker - INFO -          dashboard at:      198.202.101.148:36765
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-uyfxm97y
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:36269
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:36269
distributed.worker - INFO -          dashboard at:      198.202.101.148:45843
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-dab8un93
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:41721
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:41721
distributed.worker - INFO -          dashboard at:      198.202.101.148:39703
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9bc0j_aa
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:38315
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:38315
distributed.worker - INFO -          dashboard at:      198.202.101.148:44053
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-g9xvpyu4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:37191
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:37191
distributed.worker - INFO -          dashboard at:      198.202.101.148:41351
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8jg2ks7l
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:42311
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:42311
distributed.worker - INFO -          dashboard at:      198.202.101.148:33529
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-28xg2ebn
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:36179
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:36179
distributed.worker - INFO -          dashboard at:      198.202.101.148:36625
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-213x46gm
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:42797
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:42797
distributed.worker - INFO -          dashboard at:      198.202.101.148:35975
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gx2b086v
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:33715
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:33715
distributed.worker - INFO -          dashboard at:      198.202.101.148:44531
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xiqz4292
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:33295
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:33295
distributed.worker - INFO -          dashboard at:      198.202.101.148:37667
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-bo57feke
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:37167
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:37167
distributed.worker - INFO -          dashboard at:      198.202.101.148:37857
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tq0c4a2f
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:37365
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:37365
distributed.worker - INFO -          dashboard at:      198.202.101.148:33599
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pau4yjzr
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:33067
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:33067
distributed.worker - INFO -          dashboard at:      198.202.101.148:37651
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hggoe3_5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:33639
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:33639
distributed.worker - INFO -          dashboard at:      198.202.101.148:37053
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-2xlhvm9f
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:38509
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:38509
distributed.worker - INFO -          dashboard at:      198.202.101.148:33807
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-n136oaod
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:33013
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:33013
distributed.worker - INFO -          dashboard at:      198.202.101.148:34463
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-w_djziht
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:43155
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:43155
distributed.worker - INFO -          dashboard at:      198.202.101.148:40311
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-wbggeswa
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:35733'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:37661'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:44859'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:43959
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:36715'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:43117
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:33625'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:47053
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:38243'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:41345
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:37029'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:34183'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:42339
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:43709
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:41517'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:46745
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:38307'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:46435
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:37773'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:35701
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:44659'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:46425'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:39165
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:40189
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:35067'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:42009
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:44945'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:37321
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:41111'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:33249
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:33377'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:40059
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:43141'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:41727
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:36101'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:45497
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:36977'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:38309
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:34133'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:32887
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:40435'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:41751
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:46013'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:39011
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:46871'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:37561
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:36471'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:32939
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:35177'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:37961
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:35727'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:36651
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:41271'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:46265
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:35839'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:45621
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:39293'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:35783
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:42399'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:35787
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:34159'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:42257
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:46157'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:42347
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:35363'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:41745
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:41453'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:40103
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:45567'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:46747
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:32845'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:43049
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:39381'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:40953
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:42949'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:37191
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:34603'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:34747
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:38649'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:36323
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:36757'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:41721
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:37601'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:44409'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:33457
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:35099
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:45861'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:38565
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:43651'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:36595
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:46519'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:39673
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:41519'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:42649
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:34375'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:41281
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:39705'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:33765
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:44639'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:39385
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:46309'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:41965
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:40721'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:45859
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:35735
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:37605'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:42251'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:42583
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:40671'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:33715
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:41025'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:33403
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:42729'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:37943
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:39025'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:34641
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:42017'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:42797
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:35157'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:33295
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:34421'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:36179
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:46397'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:33001'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:38315
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:33655
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:45129'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:37167
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:39363'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:33979
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:43961'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:41147
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:33873'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:36269
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:34911'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:39999'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:37365
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:38509
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:46543'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:34901'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:43155
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:39571'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:42311
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:44827'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:33013
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:40309'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:33067
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:38225'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:42047'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:33639
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:44861'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:38511
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:43097'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:34339'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:42971'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:46439'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:39289'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:38157'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:43055'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:40819'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:38105'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:37101'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:41181'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:34029'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:45025'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:35109'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:35089'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:33431'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:43873'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:36653'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:40573'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:37307'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:43057'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.148:43265'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.148:41009
distributed.worker - INFO -          Listening to: tcp://198.202.101.148:41009
distributed.worker - INFO -          dashboard at:      198.202.101.148:44721
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-bqn2qf5d
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.101.148:41009
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 43799 was killed by signal 15
distributed.nanny - INFO - Worker process 43798 was killed by signal 15
distributed.nanny - INFO - Worker process 43807 was killed by signal 15
distributed.nanny - INFO - Worker process 43809 was killed by signal 15
distributed.nanny - INFO - Worker process 43747 was killed by signal 15
distributed.nanny - INFO - Worker process 43803 was killed by signal 15
distributed.nanny - INFO - Worker process 43990 was killed by signal 15
distributed.nanny - INFO - Worker process 43818 was killed by signal 15
distributed.nanny - INFO - Worker process 43828 was killed by signal 15
distributed.nanny - INFO - Worker process 43822 was killed by signal 15
distributed.nanny - INFO - Worker process 43794 was killed by signal 15
distributed.nanny - INFO - Worker process 43878 was killed by signal 15
distributed.nanny - INFO - Worker process 43825 was killed by signal 15
distributed.nanny - INFO - Worker process 43813 was killed by signal 15
distributed.nanny - INFO - Worker process 43816 was killed by signal 15
distributed.nanny - INFO - Worker process 43840 was killed by signal 15
distributed.nanny - INFO - Worker process 43880 was killed by signal 15
distributed.nanny - INFO - Worker process 43870 was killed by signal 15
distributed.nanny - INFO - Worker process 43911 was killed by signal 15
distributed.nanny - INFO - Worker process 43934 was killed by signal 15
distributed.nanny - INFO - Worker process 43740 was killed by signal 15
distributed.nanny - INFO - Worker process 43890 was killed by signal 15
distributed.nanny - INFO - Worker process 43896 was killed by signal 15
distributed.nanny - INFO - Worker process 43942 was killed by signal 15
distributed.nanny - INFO - Worker process 43737 was killed by signal 15
distributed.nanny - INFO - Worker process 43976 was killed by signal 15
distributed.nanny - INFO - Worker process 43993 was killed by signal 15
distributed.nanny - INFO - Worker process 43753 was killed by signal 15
distributed.nanny - INFO - Worker process 43785 was killed by signal 15
distributed.nanny - INFO - Worker process 43998 was killed by signal 15
distributed.nanny - INFO - Worker process 43986 was killed by signal 15
distributed.nanny - INFO - Worker process 43970 was killed by signal 15
distributed.nanny - INFO - Worker process 43916 was killed by signal 15
distributed.nanny - INFO - Worker process 43968 was killed by signal 15
distributed.nanny - INFO - Worker process 43936 was killed by signal 15
distributed.nanny - INFO - Worker process 43924 was killed by signal 15
distributed.nanny - INFO - Worker process 43938 was killed by signal 15
distributed.nanny - INFO - Worker process 43957 was killed by signal 15
distributed.nanny - INFO - Worker process 43743 was killed by signal 15
distributed.nanny - INFO - Worker process 43781 was killed by signal 15
distributed.nanny - INFO - Worker process 43855 was killed by signal 15
distributed.nanny - INFO - Worker process 43838 was killed by signal 15
distributed.nanny - INFO - Worker process 43852 was killed by signal 15
distributed.nanny - INFO - Worker process 43955 was killed by signal 15
distributed.nanny - INFO - Worker process 43764 was killed by signal 15
distributed.nanny - INFO - Worker process 44014 was killed by signal 15
distributed.nanny - INFO - Worker process 44009 was killed by signal 15
distributed.nanny - INFO - Worker process 44001 was killed by signal 15
distributed.nanny - INFO - Worker process 44011 was killed by signal 15
distributed.nanny - INFO - Worker process 43774 was killed by signal 15
distributed.nanny - INFO - Worker process 43762 was killed by signal 15
distributed.nanny - INFO - Worker process 43849 was killed by signal 15
distributed.nanny - INFO - Worker process 43899 was killed by signal 15
distributed.nanny - INFO - Worker process 43860 was killed by signal 15
distributed.nanny - INFO - Worker process 43940 was killed by signal 15
distributed.nanny - INFO - Worker process 43963 was killed by signal 15
distributed.nanny - INFO - Worker process 43949 was killed by signal 15
distributed.nanny - INFO - Worker process 43834 was killed by signal 15
distributed.nanny - INFO - Worker process 43771 was killed by signal 15
distributed.nanny - INFO - Worker process 43789 was killed by signal 15
distributed.nanny - INFO - Worker process 43874 was killed by signal 15
distributed.nanny - INFO - Worker process 43792 was killed by signal 15
distributed.nanny - INFO - Worker process 43767 was killed by signal 15
distributed.nanny - INFO - Worker process 44035 was killed by signal 15
distributed.nanny - INFO - Worker process 43738 was killed by signal 15
distributed.nanny - INFO - Worker process 43775 was killed by signal 15
distributed.nanny - INFO - Worker process 44021 was killed by signal 15
distributed.nanny - INFO - Worker process 44043 was killed by signal 15
distributed.nanny - INFO - Worker process 44040 was killed by signal 15
distributed.nanny - INFO - Worker process 44054 was killed by signal 15
distributed.nanny - INFO - Worker process 44004 was killed by signal 15
distributed.nanny - INFO - Worker process 43918 was killed by signal 15
distributed.nanny - INFO - Worker process 43982 was killed by signal 15
distributed.nanny - INFO - Worker process 43845 was killed by signal 15
distributed.nanny - INFO - Worker process 43951 was killed by signal 15
distributed.nanny - INFO - Worker process 43862 was killed by signal 15
distributed.nanny - INFO - Worker process 43913 was killed by signal 15
distributed.nanny - INFO - Worker process 43922 was killed by signal 15
distributed.nanny - INFO - Worker process 43887 was killed by signal 15
distributed.nanny - INFO - Worker process 43960 was killed by signal 15
distributed.nanny - INFO - Worker process 43783 was killed by signal 15
distributed.nanny - INFO - Worker process 43759 was killed by signal 15
distributed.nanny - INFO - Worker process 44059 was killed by signal 15
distributed.nanny - INFO - Worker process 43866 was killed by signal 15
distributed.nanny - INFO - Worker process 44046 was killed by signal 15
distributed.nanny - INFO - Worker process 43920 was killed by signal 15
distributed.nanny - INFO - Worker process 43748 was killed by signal 15
distributed.nanny - INFO - Worker process 44030 was killed by signal 15
distributed.nanny - INFO - Worker process 44052 was killed by signal 15
distributed.nanny - INFO - Worker process 43979 was killed by signal 15
distributed.nanny - INFO - Worker process 44050 was killed by signal 15
distributed.nanny - INFO - Worker process 43947 was killed by signal 15
distributed.nanny - INFO - Worker process 43755 was killed by signal 15
distributed.nanny - INFO - Worker process 43884 was killed by signal 15
distributed.nanny - INFO - Worker process 44017 was killed by signal 15
distributed.nanny - INFO - Worker process 44060 was killed by signal 15
distributed.nanny - INFO - Worker process 44027 was killed by signal 15
distributed.nanny - INFO - Worker process 44048 was killed by signal 15
distributed.nanny - INFO - Worker process 44057 was killed by signal 15
distributed.nanny - INFO - Worker process 44032 was killed by signal 15
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
