distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:40409'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:44003'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:39991'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:40427'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:38697'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:34697'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:35997'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:36087'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:38827'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:45015'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:45931'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:36141'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:45601'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:47029'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:46609'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:39819'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:43455'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:46297'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:42657'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:38269'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:42395'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:38599'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:37707'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:45287'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:45973'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:38191'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:35393'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:41921'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:40813'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:34929'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:42477'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:37177'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:46959'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:46603'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:43509'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:41881'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:43729'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:46323'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:37889'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:43619'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:35899'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:41543'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:38475'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:38751'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:34765'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:37179'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:45303'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:43171'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:41433'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:36449'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:44623'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:43123'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:37339'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:39695'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:33621'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:35921'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:41025'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:42013'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:37997'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:42397'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:46693'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:43891'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:32809'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:35939'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:43047'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:46767'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:41899'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:41589'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:46657'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:41795'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:43971'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:41681'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:44943'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:41557'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:42423'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:35361'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:44369'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:33249'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:38033'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:35475'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:45887'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:44123'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:37691'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:45119'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:37503'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:34839'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:40243'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:44333'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:42551'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:37695'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:44043'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:35381'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:39011'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:41013'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:33929'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:46485'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:34875'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:37751'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:37413'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.156:34917'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:41865
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:41865
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:38801
distributed.worker - INFO -          dashboard at:      198.202.103.156:37399
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:38801
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO -          dashboard at:      198.202.103.156:44551
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:44519
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:44519
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:      198.202.103.156:45181
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:39343
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pgndubez
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:41021
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:39343
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xnz7d_n6
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:41021
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.103.156:44155
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:      198.202.103.156:40003
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-mz3f6o_m
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-x92_3xzx
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xgnv64db
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:44925
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:44925
distributed.worker - INFO -          dashboard at:      198.202.103.156:35089
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-20z9p2_5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:33739
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:33739
distributed.worker - INFO -          dashboard at:      198.202.103.156:35405
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ddpukkbz
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:43261
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:43261
distributed.worker - INFO -          dashboard at:      198.202.103.156:35419
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-t59i8say
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:36119
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:36119
distributed.worker - INFO -          dashboard at:      198.202.103.156:42509
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6xkps0kp
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:44887
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:44887
distributed.worker - INFO -          dashboard at:      198.202.103.156:46679
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7_9or5dm
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:45077
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:45077
distributed.worker - INFO -          dashboard at:      198.202.103.156:37855
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gmwuir2g
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:44011
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:44011
distributed.worker - INFO -          dashboard at:      198.202.103.156:42235
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hpchor4u
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:34443
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:34443
distributed.worker - INFO -          dashboard at:      198.202.103.156:44047
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-lhmkhxuq
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:35819
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:35819
distributed.worker - INFO -          dashboard at:      198.202.103.156:33025
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gvqz5ado
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:46523
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:46523
distributed.worker - INFO -          dashboard at:      198.202.103.156:35421
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vfbdsqvh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:45513
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:45513
distributed.worker - INFO -          dashboard at:      198.202.103.156:40101
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vo9weikj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:39707
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:39707
distributed.worker - INFO -          dashboard at:      198.202.103.156:46843
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-02ssv9c4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:34187
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:34187
distributed.worker - INFO -          dashboard at:      198.202.103.156:33347
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3p7ohlo1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:35319
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:35319
distributed.worker - INFO -          dashboard at:      198.202.103.156:35971
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-bmn1uslf
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:45943
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:45943
distributed.worker - INFO -          dashboard at:      198.202.103.156:45619
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ck0kqa8w
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:45969
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:45969
distributed.worker - INFO -          dashboard at:      198.202.103.156:42777
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vtb1it7q
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:32967
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:32967
distributed.worker - INFO -          dashboard at:      198.202.103.156:43937
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3lea2syj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:36547
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:36547
distributed.worker - INFO -          dashboard at:      198.202.103.156:38837
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-r_v6x13f
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:46367
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:46367
distributed.worker - INFO -          dashboard at:      198.202.103.156:40837
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-28m3l3ix
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:33139
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:33139
distributed.worker - INFO -          dashboard at:      198.202.103.156:40479
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1gdtq881
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:43743
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:43743
distributed.worker - INFO -          dashboard at:      198.202.103.156:36849
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hjv4q_wu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:44851
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:44851
distributed.worker - INFO -          dashboard at:      198.202.103.156:40021
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-k95hmrb2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:37679
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:37679
distributed.worker - INFO -          dashboard at:      198.202.103.156:40863
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-30ug3fjr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:45095
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:45095
distributed.worker - INFO -          dashboard at:      198.202.103.156:36447
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9weh9o8j
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:39193
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:46653
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:39193
distributed.worker - INFO -          dashboard at:      198.202.103.156:47099
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ng0tclbs
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:46653
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.103.156:43979
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ghazx7on
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:40169
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:40169
distributed.worker - INFO -          dashboard at:      198.202.103.156:35199
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-s9tjetj4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:46501
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:46501
distributed.worker - INFO -          dashboard at:      198.202.103.156:35619
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-no8nvg4p
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:36089
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:36089
distributed.worker - INFO -          dashboard at:      198.202.103.156:41747
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-oemwnfmd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:41781
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:41781
distributed.worker - INFO -          dashboard at:      198.202.103.156:32833
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-yahtj_2p
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:42253
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:42253
distributed.worker - INFO -          dashboard at:      198.202.103.156:44707
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-n538xqkw
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:33189
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:33189
distributed.worker - INFO -          dashboard at:      198.202.103.156:33963
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1fu5nyow
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:44979
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:44979
distributed.worker - INFO -          dashboard at:      198.202.103.156:46173
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-08b8lx_p
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:38653
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:38653
distributed.worker - INFO -          dashboard at:      198.202.103.156:40927
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-jaef9l0_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:42797
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:42797
distributed.worker - INFO -          dashboard at:      198.202.103.156:34941
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-opzjp77c
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:34197
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:34197
distributed.worker - INFO -          dashboard at:      198.202.103.156:38691
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hfuu0k9t
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:35665
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:35665
distributed.worker - INFO -          dashboard at:      198.202.103.156:43505
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gu9fapcp
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:45065
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:45065
distributed.worker - INFO -          dashboard at:      198.202.103.156:39197
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8g_ca481
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:44879
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:44879
distributed.worker - INFO -          dashboard at:      198.202.103.156:37423
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-cfs04bb2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:44027
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:44027
distributed.worker - INFO -          dashboard at:      198.202.103.156:45369
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-2wrq_emm
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:39367
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:39367
distributed.worker - INFO -          dashboard at:      198.202.103.156:45025
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-nomqtl_t
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:32811
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:32811
distributed.worker - INFO -          dashboard at:      198.202.103.156:38955
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-j3hzbqel
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:38401
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:38401
distributed.worker - INFO -          dashboard at:      198.202.103.156:44347
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_wiw1kt4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:39097
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:39097
distributed.worker - INFO -          dashboard at:      198.202.103.156:42483
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vnhxfn9q
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:39899
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:39899
distributed.worker - INFO -          dashboard at:      198.202.103.156:34145
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gitl_v1_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:45727
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:45727
distributed.worker - INFO -          dashboard at:      198.202.103.156:40179
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-q72ypas4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:37561
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:37561
distributed.worker - INFO -          dashboard at:      198.202.103.156:42695
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pc1n6uvy
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:40731
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:40731
distributed.worker - INFO -          dashboard at:      198.202.103.156:34945
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-s4ywyj3a
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:34707
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:34707
distributed.worker - INFO -          dashboard at:      198.202.103.156:36633
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pa6dpggv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:39415
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:39415
distributed.worker - INFO -          dashboard at:      198.202.103.156:42385
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-48y8veou
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:35275
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:35275
distributed.worker - INFO -          dashboard at:      198.202.103.156:36717
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-au15mmeo
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:42025
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:42025
distributed.worker - INFO -          dashboard at:      198.202.103.156:34977
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-2ti4j_73
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:35321
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:35321
distributed.worker - INFO -          dashboard at:      198.202.103.156:37419
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6j8uzb54
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:37999
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:37999
distributed.worker - INFO -          dashboard at:      198.202.103.156:45659
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-kl09p9ym
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:33237
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:33237
distributed.worker - INFO -          dashboard at:      198.202.103.156:43035
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-muk2bg6z
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:36973
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:36973
distributed.worker - INFO -          dashboard at:      198.202.103.156:35603
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-cq2zr5dj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:36177
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:36177
distributed.worker - INFO -          dashboard at:      198.202.103.156:46599
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-s6j80a4y
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:37597
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:37597
distributed.worker - INFO -          dashboard at:      198.202.103.156:38507
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3ive0zfu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:35955
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:35955
distributed.worker - INFO -          dashboard at:      198.202.103.156:37319
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-uwoow6gi
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:45033
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:45033
distributed.worker - INFO -          dashboard at:      198.202.103.156:33063
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-buuf76v5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:44865
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:44865
distributed.worker - INFO -          dashboard at:      198.202.103.156:35407
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_fwpricz
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:40409'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:44003'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:46501
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:39991'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:40427'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:46367
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:38697'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:45943
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:37679
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:34697'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:35997'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:35819
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:36087'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:44851
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:38827'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:45969
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:45015'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:46653
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:45931'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:43743
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:36141'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:35319
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:45601'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:43261
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:47029'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:41865
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:46609'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:39193
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:39819'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:43455'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:44887
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:42253
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:46297'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:41021
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:42657'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:44519
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:46523
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:38269'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:42395'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:45513
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:38599'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:34443
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:37707'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:39343
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:45287'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:33139
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:45973'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:44011
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:38191'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:34187
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:44925
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:35393'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:41921'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:33739
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:40813'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:39707
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:34929'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:32967
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:42477'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:45095
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:38801
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:37177'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:46959'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:36547
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:46603'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:36089
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:43509'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:33189
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:41781
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:41881'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:43729'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:38653
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:46323'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:44979
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:37889'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:40169
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:43619'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:42797
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:35899'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:41543'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:34197
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:45065
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:38475'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:44879
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:38751'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:35665
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:34765'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:39097
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:37179'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:32811
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:45303'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:39367
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:43171'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:44027
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:41433'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:39899
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:36449'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:45727
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:44623'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:40731
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:43123'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:34707
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:37339'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:38401
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:39695'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:37597
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:33621'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:35275
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:35921'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:41025'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:37999
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:42013'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:35321
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:37997'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:42025
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:36973
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:42397'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:46693'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:39415
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:43891'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:33237
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:32809'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:41897
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:45033
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:35939'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:41897
distributed.worker - INFO -          dashboard at:      198.202.103.156:45911
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:43047'
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:37561
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:44865
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:46767'
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-v6nthifg
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:36119
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:41899'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:36177
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:41897
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:41589'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:46657'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:35955
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:41795'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:43971'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:41681'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:44943'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:41557'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:42423'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:35361'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:45077
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:44369'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:33249'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:38033'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:35475'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:45887'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:44123'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:37691'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:45119'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:37503'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:34839'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:40243'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:44333'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:42551'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:37695'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:44043'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:35381'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:39011'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:41013'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:33929'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:46485'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:34875'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:37751'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:37413'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.156:34917'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.156:45729
distributed.worker - INFO -          Listening to: tcp://198.202.103.156:45729
distributed.worker - INFO -          dashboard at:      198.202.103.156:36267
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-l_6z0i46
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.156:45729
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32659 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32657 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32655 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32653 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32649 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32651 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32645 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32643 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32639 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32637 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32630 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32626 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32623 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32633 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32620 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32616 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32611 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32607 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32602 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32599 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32595 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32590 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32588 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32585 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32578 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32580 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32573 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32569 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32567 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32563 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32559 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32556 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32552 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32549 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32546 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32543 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32537 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32532 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32530 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32526 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32523 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32518 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32515 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32511 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32503 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32501 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32482 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32494 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32507 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32460 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32455 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32464 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32451 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32449 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32444 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32447 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32441 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32438 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32436 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32433 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32429 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32425 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32421 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32418 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32415 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32412 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32409 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32406 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32403 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32399 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32397 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32393 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32391 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32388 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32384 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32382 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32379 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32366 parent=32238 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=32361 parent=32238 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
