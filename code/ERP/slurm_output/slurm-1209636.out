distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:45115'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:40807'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:32977'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:46667'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:37683'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:42467'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:39083'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:46685'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:42543'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:46467'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:36201'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:38169'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:38825'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:41753'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:32999'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:45889'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:45189'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:37895'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:36967'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:41065'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:46261'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:40799'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:41823'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:32785'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:38253'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:46789'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:42469'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:36419'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:44977'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:46279'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:39023'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:46973'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:39105'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:40691'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:36463'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:45263'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:34893'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:39513'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:46139'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:45423'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:39369'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:41073'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:40719'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:43281'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:40471'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:40345'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:38617'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:41487'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:46359'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:33385'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:37705'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:44175'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:36713'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:45023'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:35851'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:35845'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:40369'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:42293'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:44341'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:42157'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:35451'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:46361'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:42235'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:46295'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:45401'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:45095'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:38203'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:41257'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:44913'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:34047'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:36335'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:36553'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:38363'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:41265'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:44065'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:41367'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:43243'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:40099'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:39495'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:41735'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:39277'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:33405'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:39553'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:34821'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:36243'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:45609'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:37083'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:36495'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:43431'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:46371'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:37219'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:45323'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:46307'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:40027'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:42661'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:46305'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:46913'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:32893'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:44573'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.144:45475'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:44751
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:44751
distributed.worker - INFO -          dashboard at:      198.202.101.144:38985
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:39271
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:40291
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ux6_dhbv
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:39271
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:40291
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.101.144:46097
distributed.worker - INFO -          dashboard at:      198.202.101.144:36435
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-sf10ab6x
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zjrix52p
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:33623
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:33623
distributed.worker - INFO -          dashboard at:      198.202.101.144:43161
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gru1yqc_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:36283
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:36283
distributed.worker - INFO -          dashboard at:      198.202.101.144:44779
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-lt1athf9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:46407
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:46407
distributed.worker - INFO -          dashboard at:      198.202.101.144:42649
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-dhyin7b6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:44115
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:44115
distributed.worker - INFO -          dashboard at:      198.202.101.144:36415
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ld3teutw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:39361
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:39361
distributed.worker - INFO -          dashboard at:      198.202.101.144:38681
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-m7mtdjde
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:33149
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:33149
distributed.worker - INFO -          dashboard at:      198.202.101.144:39983
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zfrpkhpy
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:42851
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:42851
distributed.worker - INFO -          dashboard at:      198.202.101.144:34181
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-c7j9cx0v
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:39387
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:39387
distributed.worker - INFO -          dashboard at:      198.202.101.144:40225
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xcghdqn9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:37519
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:37519
distributed.worker - INFO -          dashboard at:      198.202.101.144:43745
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ce3rx6nd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:44487
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:44487
distributed.worker - INFO -          dashboard at:      198.202.101.144:36555
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-a9ll9i_a
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:35281
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:35281
distributed.worker - INFO -          dashboard at:      198.202.101.144:34277
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-wjptx537
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:41715
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:41715
distributed.worker - INFO -          dashboard at:      198.202.101.144:47063
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-oxz7c1l7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:33047
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:33047
distributed.worker - INFO -          dashboard at:      198.202.101.144:44153
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pii8rogt
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:46309
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:46309
distributed.worker - INFO -          dashboard at:      198.202.101.144:43465
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-x4qv4m1g
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:36061
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:36061
distributed.worker - INFO -          dashboard at:      198.202.101.144:37993
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7yb_xxi4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:36181
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:36181
distributed.worker - INFO -          dashboard at:      198.202.101.144:38117
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-up21ffh3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:37073
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:37073
distributed.worker - INFO -          dashboard at:      198.202.101.144:34779
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qb7omd_s
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:45283
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:45283
distributed.worker - INFO -          dashboard at:      198.202.101.144:34475
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qwagvno6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:35413
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:35413
distributed.worker - INFO -          dashboard at:      198.202.101.144:38123
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_lg1h5ol
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:33581
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:33581
distributed.worker - INFO -          dashboard at:      198.202.101.144:46409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0kx3v_9r
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:45427
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:45427
distributed.worker - INFO -          dashboard at:      198.202.101.144:33865
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zve9nb67
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:41845
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:41845
distributed.worker - INFO -          dashboard at:      198.202.101.144:34023
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qfykt33j
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:43621
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:43621
distributed.worker - INFO -          dashboard at:      198.202.101.144:45549
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-445y60so
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:34665
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:34665
distributed.worker - INFO -          dashboard at:      198.202.101.144:36753
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4yv4va4o
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:44955
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:44955
distributed.worker - INFO -          dashboard at:      198.202.101.144:37715
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3_lfymtu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:32955
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:32955
distributed.worker - INFO -          dashboard at:      198.202.101.144:35221
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-rye7mgz1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:39133
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:39133
distributed.worker - INFO -          dashboard at:      198.202.101.144:44089
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zqq3_x_4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:45115'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:40807'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:32977'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:46407
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:46667'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:33149
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:40291
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:37683'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:33623
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:42467'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:44751
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:39083'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:44115
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:46685'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:42543'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:36283
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:46467'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:39361
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:36201'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:39271
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:42851
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:38169'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:38825'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:37519
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:41753'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:39387
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:32999'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:46309
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:45889'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:35281
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:45189'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:44487
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:37895'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:41715
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:36967'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:36181
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:41065'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:36061
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:33047
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:46261'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:40799'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:37073
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:41823'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:35413
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:32785'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:45283
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:38253'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:33581
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:43621
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:46789'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:44955
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:42469'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:36419'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:41845
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:44977'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:34665
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:46279'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:45427
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:39023'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:46973'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:39133
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:32955
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:39105'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:40691'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:36463'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:45263'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:34893'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:39513'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:46139'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:45423'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:39369'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:41073'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:40719'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:43281'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:40471'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:40345'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:38617'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:41487'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:46359'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:33385'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:37705'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:44175'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:36713'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:45023'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:35851'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:35845'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:40369'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:42293'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:44341'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:42157'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:35451'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:46361'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:42235'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:46295'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:45401'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:45095'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:38203'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:41257'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:44913'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:34047'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:36335'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:36553'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:38363'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:41265'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:44065'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:41367'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:43243'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:40099'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:39495'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:41735'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:39277'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:33405'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:39553'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:34821'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:36243'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:45609'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:37083'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:36495'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:43431'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:46371'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:37219'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:45323'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:46307'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:40027'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:42661'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:46305'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:46913'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:32893'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:44573'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.144:45475'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.144:46547
distributed.worker - INFO -          Listening to: tcp://198.202.101.144:46547
distributed.worker - INFO -          dashboard at:      198.202.101.144:44003
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-37i7ic21
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.101.144:46547
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO - Stopping worker
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 3959 was killed by signal 15
distributed.nanny - INFO - Worker process 4050 was killed by signal 15
distributed.nanny - INFO - Worker process 3986 was killed by signal 15
distributed.nanny - INFO - Worker process 4112 was killed by signal 15
distributed.nanny - INFO - Worker process 3976 was killed by signal 15
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 4153 was killed by signal 15
distributed.nanny - INFO - Worker process 4033 was killed by signal 15
distributed.nanny - INFO - Worker process 4089 was killed by signal 15
distributed.nanny - INFO - Worker process 4167 was killed by signal 15
distributed.nanny - INFO - Worker process 4052 was killed by signal 15
distributed.nanny - INFO - Worker process 4003 was killed by signal 15
distributed.nanny - INFO - Worker process 4059 was killed by signal 15
distributed.nanny - INFO - Worker process 4091 was killed by signal 15
distributed.nanny - INFO - Worker process 3965 was killed by signal 15
distributed.nanny - INFO - Worker process 4038 was killed by signal 15
distributed.nanny - INFO - Worker process 4016 was killed by signal 15
distributed.nanny - INFO - Worker process 4046 was killed by signal 15
distributed.nanny - INFO - Worker process 4094 was killed by signal 15
distributed.nanny - INFO - Worker process 3968 was killed by signal 15
distributed.nanny - INFO - Worker process 3983 was killed by signal 15
distributed.nanny - INFO - Worker process 3949 was killed by signal 15
distributed.nanny - INFO - Worker process 4097 was killed by signal 15
distributed.nanny - INFO - Worker process 4031 was killed by signal 15
distributed.nanny - INFO - Worker process 4122 was killed by signal 15
distributed.nanny - INFO - Worker process 4079 was killed by signal 15
distributed.nanny - INFO - Worker process 4075 was killed by signal 15
distributed.nanny - INFO - Worker process 4082 was killed by signal 15
distributed.nanny - INFO - Worker process 4105 was killed by signal 15
distributed.nanny - INFO - Worker process 4126 was killed by signal 15
distributed.nanny - INFO - Worker process 3969 was killed by signal 15
distributed.nanny - INFO - Worker process 3980 was killed by signal 15
distributed.nanny - INFO - Worker process 4072 was killed by signal 15
distributed.nanny - INFO - Worker process 4147 was killed by signal 15
distributed.nanny - INFO - Worker process 3974 was killed by signal 15
distributed.nanny - INFO - Worker process 4065 was killed by signal 15
distributed.nanny - INFO - Worker process 4131 was killed by signal 15
distributed.nanny - INFO - Worker process 4023 was killed by signal 15
distributed.nanny - INFO - Worker process 3962 was killed by signal 15
distributed.nanny - INFO - Worker process 4014 was killed by signal 15
distributed.nanny - INFO - Worker process 3942 was killed by signal 15
distributed.nanny - INFO - Worker process 3990 was killed by signal 15
distributed.nanny - INFO - Worker process 3995 was killed by signal 15
distributed.nanny - INFO - Worker process 4019 was killed by signal 15
distributed.nanny - INFO - Worker process 4026 was killed by signal 15
distributed.nanny - INFO - Worker process 4190 was killed by signal 15
distributed.nanny - INFO - Worker process 4008 was killed by signal 15
distributed.nanny - INFO - Worker process 4133 was killed by signal 15
distributed.nanny - INFO - Worker process 4067 was killed by signal 15
distributed.nanny - INFO - Worker process 3956 was killed by signal 15
distributed.nanny - INFO - Worker process 3940 was killed by signal 15
distributed.nanny - INFO - Worker process 3952 was killed by signal 15
distributed.nanny - INFO - Worker process 4137 was killed by signal 15
distributed.nanny - INFO - Worker process 4145 was killed by signal 15
distributed.nanny - INFO - Worker process 4029 was killed by signal 15
distributed.nanny - INFO - Worker process 4140 was killed by signal 15
distributed.nanny - INFO - Worker process 4178 was killed by signal 15
distributed.nanny - INFO - Worker process 4062 was killed by signal 15
distributed.nanny - INFO - Worker process 3992 was killed by signal 15
distributed.nanny - INFO - Worker process 4101 was killed by signal 15
distributed.nanny - INFO - Worker process 3946 was killed by signal 15
distributed.nanny - INFO - Worker process 3944 was killed by signal 15
distributed.nanny - INFO - Worker process 4158 was killed by signal 15
distributed.nanny - INFO - Worker process 4001 was killed by signal 15
distributed.nanny - INFO - Worker process 4163 was killed by signal 15
distributed.nanny - INFO - Worker process 4007 was killed by signal 15
distributed.nanny - INFO - Worker process 4185 was killed by signal 15
distributed.nanny - INFO - Worker process 4199 was killed by signal 15
distributed.nanny - INFO - Worker process 4118 was killed by signal 15
distributed.nanny - INFO - Worker process 4180 was killed by signal 15
distributed.nanny - INFO - Worker process 4193 was killed by signal 15
distributed.nanny - INFO - Worker process 3998 was killed by signal 15
distributed.nanny - INFO - Worker process 4238 was killed by signal 15
distributed.nanny - INFO - Worker process 4108 was killed by signal 15
distributed.nanny - INFO - Worker process 4202 was killed by signal 15
distributed.nanny - INFO - Worker process 4175 was killed by signal 15
distributed.nanny - INFO - Worker process 4169 was killed by signal 15
distributed.nanny - INFO - Worker process 4221 was killed by signal 15
distributed.nanny - INFO - Worker process 4205 was killed by signal 15
distributed.nanny - INFO - Worker process 4226 was killed by signal 15
distributed.nanny - INFO - Worker process 4219 was killed by signal 15
distributed.nanny - INFO - Worker process 4240 was killed by signal 15
distributed.nanny - INFO - Worker process 4210 was killed by signal 15
distributed.nanny - INFO - Worker process 4232 was killed by signal 15
distributed.nanny - INFO - Worker process 4250 was killed by signal 15
distributed.nanny - INFO - Worker process 4245 was killed by signal 15
distributed.nanny - INFO - Worker process 4197 was killed by signal 15
distributed.nanny - INFO - Worker process 4253 was killed by signal 15
distributed.nanny - INFO - Worker process 4216 was killed by signal 15
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
