distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:42659'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:40065'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:42785'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:42169'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:35441'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:46299'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:35365'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:44829'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:39713'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:36849'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:40373'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:42293'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:40577'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:46977'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:38713'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:33483'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:38523'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:47025'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:35083'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:46221'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:39885'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:42391'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:41697'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:42571'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:38147'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:39769'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:45673'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:33287'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:42009'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:44271'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:35737'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:43537'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:36291'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:35145'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:38885'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:45361'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:35881'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:39911'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:46269'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:42209'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:46861'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:34685'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:37359'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:38295'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:37041'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:32961'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:34951'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:41917'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:34905'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:33077'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:34207'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:34801'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:45557'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:33259'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:38625'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:33659'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:41929'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:46709'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:34677'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:35251'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:33389'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:41711'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:37069'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:39495'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:45123'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:46901'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:36155'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:43159'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:44269'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:37941'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:44443'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:44851'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:36773'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:43881'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:43639'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:44613'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:34065'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:44237'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:45271'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:38721'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:38129'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:33125'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:37371'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:36435'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:41467'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:41687'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:37301'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:43851'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:46061'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:45181'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:38277'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:45611'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:40627'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:35069'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:40455'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:46795'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:35407'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:34673'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:34875'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.89:46585'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:40685
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:40685
distributed.worker - INFO -          dashboard at:       198.202.102.89:38237
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8__tq41u
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:34079
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:34079
distributed.worker - INFO -          dashboard at:       198.202.102.89:38731
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-lpw_ztev
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:37459
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:37459
distributed.worker - INFO -          dashboard at:       198.202.102.89:34763
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-svp8kkqz
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:32883
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:32883
distributed.worker - INFO -          dashboard at:       198.202.102.89:41079
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ppgeufy6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:37321
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:37321
distributed.worker - INFO -          dashboard at:       198.202.102.89:37053
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-w_34loe5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:43663
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:43663
distributed.worker - INFO -          dashboard at:       198.202.102.89:42045
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-df1t_xj_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:41475
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:41475
distributed.worker - INFO -          dashboard at:       198.202.102.89:46913
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-w251ay8l
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:36903
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:36903
distributed.worker - INFO -          dashboard at:       198.202.102.89:44757
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-sp_c1qvh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:42275
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:42275
distributed.worker - INFO -          dashboard at:       198.202.102.89:46711
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-35hkwk2u
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:42139
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:42139
distributed.worker - INFO -          dashboard at:       198.202.102.89:35601
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-aj9djdr8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:35821
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:35821
distributed.worker - INFO -          dashboard at:       198.202.102.89:37127
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7qxwcq5f
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:40367
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:40367
distributed.worker - INFO -          dashboard at:       198.202.102.89:33195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-r_n9h6_n
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:35275
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:35275
distributed.worker - INFO -          dashboard at:       198.202.102.89:43247
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-sc0shnh0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:39095
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:39095
distributed.worker - INFO -          dashboard at:       198.202.102.89:43173
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pxw5upx9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:45079
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:45079
distributed.worker - INFO -          dashboard at:       198.202.102.89:41169
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-x5upl038
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:40877
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:40877
distributed.worker - INFO -          dashboard at:       198.202.102.89:39127
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-m4saypc2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:33155
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:33155
distributed.worker - INFO -          dashboard at:       198.202.102.89:35883
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tyo4uegq
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:36293
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:36293
distributed.worker - INFO -          dashboard at:       198.202.102.89:38301
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-byirq8ka
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:40157
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:40157
distributed.worker - INFO -          dashboard at:       198.202.102.89:39281
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-supzwkgv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:36099
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:36099
distributed.worker - INFO -          dashboard at:       198.202.102.89:43351
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3uzx4v31
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:34471
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:34471
distributed.worker - INFO -          dashboard at:       198.202.102.89:40119
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5iuk5r00
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:33599
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:33599
distributed.worker - INFO -          dashboard at:       198.202.102.89:40957
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-80gfk7br
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:43479
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:43479
distributed.worker - INFO -          dashboard at:       198.202.102.89:42427
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8dzp0pdb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:38841
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:38841
distributed.worker - INFO -          dashboard at:       198.202.102.89:36319
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-w7x0z4g3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:45899
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:45899
distributed.worker - INFO -          dashboard at:       198.202.102.89:38545
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-jp1a8sj_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:34405
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:34405
distributed.worker - INFO -          dashboard at:       198.202.102.89:45071
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3_q_eh4z
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:46431
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:46431
distributed.worker - INFO -          dashboard at:       198.202.102.89:35723
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7dyyygp2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:42015
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:42015
distributed.worker - INFO -          dashboard at:       198.202.102.89:38355
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-74mz1cm9
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:35133
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:35133
distributed.worker - INFO -          dashboard at:       198.202.102.89:43043
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-90mjeju9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:34703
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:34703
distributed.worker - INFO -          dashboard at:       198.202.102.89:46877
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-mz1k9xcl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:46179
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:46179
distributed.worker - INFO -          dashboard at:       198.202.102.89:42407
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ghdzha77
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:40639
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:40639
distributed.worker - INFO -          dashboard at:       198.202.102.89:40403
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-op1vjltv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:34209
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:34209
distributed.worker - INFO -          dashboard at:       198.202.102.89:38701
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pymzji48
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:39477
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:39477
distributed.worker - INFO -          dashboard at:       198.202.102.89:34279
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vdvo35tz
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:46469
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:46469
distributed.worker - INFO -          dashboard at:       198.202.102.89:41125
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8qefusy7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:34547
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:34547
distributed.worker - INFO -          dashboard at:       198.202.102.89:43763
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0z49a0x7
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:44473
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:44473
distributed.worker - INFO -          dashboard at:       198.202.102.89:35893
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-a6m3xmhi
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:33941
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:33941
distributed.worker - INFO -          dashboard at:       198.202.102.89:36543
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1p8d5aqj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:44729
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:44729
distributed.worker - INFO -          dashboard at:       198.202.102.89:34211
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_0imgdmm
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:38849
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:38849
distributed.worker - INFO -          dashboard at:       198.202.102.89:46327
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6uyy2kbv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.89:39107
distributed.worker - INFO -          Listening to: tcp://198.202.102.89:39107
distributed.worker - INFO -          dashboard at:       198.202.102.89:47071
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-fxei27ln
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:42659'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:40065'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:42785'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:36903
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:37459
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:42169'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:35441'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:40685
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:46299'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:34079
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:35365'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:41475
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:44829'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:32883
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:39713'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:36849'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:37321
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:43663
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:40373'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:42275
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:42293'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:40367
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:40577'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:42139
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:46977'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:35821
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:38713'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:40877
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:33483'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:45079
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:38523'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:36293
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:47025'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:33155
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:35083'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:33599
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:46221'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:39885'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:36099
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:40157
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:42391'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:41697'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:45899
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:38841
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:42571'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:34471
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:38147'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:43479
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:39769'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:46431
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:45673'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:34405
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:33287'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:42015
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:42009'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:44271'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:35133
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:35737'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:34703
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:43537'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:40639
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:46179
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:36291'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:39477
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:35145'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:38885'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:34209
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:46469
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:45361'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:35881'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:35275
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:34547
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:39911'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:46269'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:33941
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:42209'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:46861'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:34685'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:37359'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:38295'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:37041'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:38849
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:32961'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:34951'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:41917'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:44473
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:34905'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:33077'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:44729
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:34207'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:34801'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:45557'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:33259'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:38625'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:33659'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:41929'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:46709'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:39107
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:34677'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:35251'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:33389'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:41711'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:37069'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:39495'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:45123'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:46901'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:36155'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:43159'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:44269'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:37941'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:44443'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.89:39095
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:44851'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:36773'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:43881'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:43639'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:44613'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:34065'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:44237'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:45271'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:38721'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:38129'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:33125'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:37371'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:36435'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:41467'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:41687'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:37301'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:43851'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:46061'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:45181'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:38277'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:45611'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:40627'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:35069'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:40455'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:46795'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:35407'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:34673'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:34875'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.89:46585'
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47357 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47429 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47427 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47358 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47425 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47353 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47350 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47348 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47356 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47259 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47027 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47023 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47020 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47005 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47009 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47012 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47000 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46996 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47015 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46992 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47002 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46987 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46983 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46981 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46977 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46973 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46965 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46962 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46959 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46955 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46946 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46953 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46940 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46944 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46937 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46934 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46923 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46928 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46920 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46916 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46918 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46911 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46899 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46892 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46895 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46900 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46893 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46880 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46886 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46884 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46872 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46869 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46874 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46877 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46865 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46860 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46854 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46852 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46845 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46837 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46840 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46832 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46828 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46824 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46817 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46811 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46804 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46800 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46796 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46789 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46785 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46783 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46780 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46777 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46774 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46769 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46772 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46764 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46762 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46759 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46756 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46753 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46749 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46747 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46744 parent=46636 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=46739 parent=46636 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    assert exitcode is not None
AssertionError
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
