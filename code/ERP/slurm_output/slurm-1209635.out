distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36963'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:39235'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:42185'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:45351'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:41639'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:42649'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:33775'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38425'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:34689'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:47033'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:45633'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38717'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:34675'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:35709'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36881'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:45267'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:34769'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:46815'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:45643'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:44247'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:39957'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:43485'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38907'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:40783'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36375'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38261'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38389'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:43867'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36597'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:35997'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:41497'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:33571'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38657'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:40899'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:43033'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:46827'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:43535'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:45513'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:34755'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:44313'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:39237'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:47017'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:40873'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:39037'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:46237'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:33613'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:33467'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36023'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:45075'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:35915'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:35123'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:40731'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:35979'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:35129'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:37467'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:33251'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:46055'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:45883'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:43185'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:33085'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:39785'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:40673'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:39083'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:47083'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38807'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:43041'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:37099'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:43951'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:41249'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:44447'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:33381'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:45171'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:35433'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:35789'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:34549'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:33627'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:43179'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:33997'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:45445'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38545'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:39111'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:42793'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:41933'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:40041'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:34991'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38515'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:43189'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:41701'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:37871'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38091'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38463'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:41965'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36497'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:35205'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:38649'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36697'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:36255'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:42207'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:46435'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.148:44303'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:43223
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39675
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:43223
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:43957
distributed.worker - INFO -          dashboard at:      198.202.103.148:40561
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:34293
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:38703
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39675
distributed.worker - INFO -          dashboard at:      198.202.103.148:33193
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:46851
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:43957
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:33761
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:34293
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:40255
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:38703
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -          dashboard at:      198.202.103.148:46571
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:36205
distributed.worker - INFO -          dashboard at:      198.202.103.148:46375
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_2pmpnny
distributed.worker - INFO -          dashboard at:      198.202.103.148:37401
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:40255
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:36859
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:45849
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -          dashboard at:      198.202.103.148:34601
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:46851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:33761
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -          dashboard at:      198.202.103.148:36675
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ez8p_u37
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:36205
distributed.worker - INFO -          dashboard at:      198.202.103.148:40113
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:      198.202.103.148:45733
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:36859
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:45849
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-jeeht6z_
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-juouc2yj
distributed.worker - INFO -          dashboard at:      198.202.103.148:43645
distributed.worker - INFO -          dashboard at:      198.202.103.148:41625
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-b3wx7g6h
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hwlpm104
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qvl9xy9u
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-z13v893q
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-8axn33zu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-sll2lxw0
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-95r8r4d0
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:33335
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:33335
distributed.worker - INFO -          dashboard at:      198.202.103.148:42191
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1mlo2g4o
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:42399
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:42399
distributed.worker - INFO -          dashboard at:      198.202.103.148:40767
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tdmu2g4s
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:36585
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:36585
distributed.worker - INFO -          dashboard at:      198.202.103.148:33185
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5_p6nz7n
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:43417
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:43417
distributed.worker - INFO -          dashboard at:      198.202.103.148:41611
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-aq6z5p_3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:36309
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:36309
distributed.worker - INFO -          dashboard at:      198.202.103.148:42247
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-obh9_jdv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:35617
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:35617
distributed.worker - INFO -          dashboard at:      198.202.103.148:44649
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-am80ie1v
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39067
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39067
distributed.worker - INFO -          dashboard at:      198.202.103.148:33763
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-g6nj_zsh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:33447
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:33447
distributed.worker - INFO -          dashboard at:      198.202.103.148:45139
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9wlrhu91
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:45713
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:45713
distributed.worker - INFO -          dashboard at:      198.202.103.148:34417
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-lddfvcjs
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:38327
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:38327
distributed.worker - INFO -          dashboard at:      198.202.103.148:40371
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-i1vt6cqh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:46625
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:46625
distributed.worker - INFO -          dashboard at:      198.202.103.148:38351
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-v80nt7wh
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39395
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39395
distributed.worker - INFO -          dashboard at:      198.202.103.148:45321
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:40487
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5wpn9hpl
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:40487
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.103.148:39403
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-uqvt2647
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:35517
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:35517
distributed.worker - INFO -          dashboard at:      198.202.103.148:36705
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pbccp6_j
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:35921
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:35921
distributed.worker - INFO -          dashboard at:      198.202.103.148:46641
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-x122wtms
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:33845
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:33845
distributed.worker - INFO -          dashboard at:      198.202.103.148:36939
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hdd3nwec
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:43753
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:43753
distributed.worker - INFO -          dashboard at:      198.202.103.148:38519
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-jdk9mjbn
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:34989
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:34989
distributed.worker - INFO -          dashboard at:      198.202.103.148:32839
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-i5feposl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:40929
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:40929
distributed.worker - INFO -          dashboard at:      198.202.103.148:33463
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ieraxwjk
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:32887
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:32887
distributed.worker - INFO -          dashboard at:      198.202.103.148:36433
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-e87z6htt
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:38835
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:38835
distributed.worker - INFO -          dashboard at:      198.202.103.148:46227
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tllj7gk1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:40591
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:40591
distributed.worker - INFO -          dashboard at:      198.202.103.148:40579
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ln8wakbs
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:43399
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:43399
distributed.worker - INFO -          dashboard at:      198.202.103.148:43711
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zh6nfqgv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:40551
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:40551
distributed.worker - INFO -          dashboard at:      198.202.103.148:46747
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tenpb55j
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:39263
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:39263
distributed.worker - INFO -          dashboard at:      198.202.103.148:33425
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-fdwca4ux
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36963'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:39235'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:42185'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39675
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:45351'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:34293
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:41639'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:43223
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:42649'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:40255
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:33775'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:45849
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38425'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:43957
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:34689'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:36205
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:47033'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:45633'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:46851
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:38703
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38717'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:34675'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:36585
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:33761
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:35709'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:36859
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:42399
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36881'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:33335
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:45267'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:35617
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:34769'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:46815'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:43417
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:45643'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:36309
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:44247'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:33447
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:39957'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:45713
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:43485'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39067
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38907'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:46625
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39395
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:40783'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36375'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:38327
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38261'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:35517
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38389'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:43867'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:40487
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:35921
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:33845
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36597'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:35997'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:34989
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:41497'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:43753
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:33571'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:38835
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38657'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:40899'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:40551
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:43033'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:46827'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:43535'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:45513'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:40929
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:32887
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:34755'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:44313'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:40591
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:39237'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:47017'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:39263
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:40873'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:39037'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:46237'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:33613'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:33467'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36023'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:45075'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:35915'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:35123'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:40731'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:35979'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:35129'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:37467'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:33251'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:46055'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:45883'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:43185'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:33085'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:39785'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:40673'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:43399
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:39083'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:47083'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38807'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:43041'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:37099'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:43951'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:41249'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:44447'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:33381'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:45171'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:35433'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:35789'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:34549'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:33627'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:43179'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:33997'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:45445'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38545'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:39111'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:42793'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:41933'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:40041'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:34991'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38515'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:43189'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:41701'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:37871'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38091'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38463'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:41965'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36497'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:35205'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:38649'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36697'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:36255'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:42207'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:46435'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.148:44303'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.148:40887
distributed.worker - INFO -          Listening to: tcp://198.202.103.148:40887
distributed.worker - INFO -          dashboard at:      198.202.103.148:33427
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-svmyec5c
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.148:40887
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO - Stopping worker
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 87696 was killed by signal 15
distributed.nanny - INFO - Worker process 87766 was killed by signal 15
distributed.nanny - INFO - Worker process 87779 was killed by signal 15
distributed.nanny - INFO - Worker process 87690 was killed by signal 15
distributed.nanny - INFO - Worker process 87783 was killed by signal 15
distributed.nanny - INFO - Worker process 87703 was killed by signal 15
distributed.nanny - INFO - Worker process 87672 was killed by signal 15
distributed.nanny - INFO - Worker process 87674 was killed by signal 15
distributed.nanny - INFO - Worker process 87706 was killed by signal 15
distributed.nanny - INFO - Worker process 87680 was killed by signal 15
distributed.nanny - INFO - Worker process 87777 was killed by signal 15
distributed.nanny - INFO - Worker process 87767 was killed by signal 15
distributed.nanny - INFO - Worker process 87757 was killed by signal 15
distributed.nanny - INFO - Worker process 87679 was killed by signal 15
distributed.nanny - INFO - Worker process 87683 was killed by signal 15
distributed.nanny - INFO - Worker process 87687 was killed by signal 15
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 87828 was killed by signal 15
distributed.nanny - INFO - Worker process 87850 was killed by signal 15
distributed.nanny - INFO - Worker process 87803 was killed by signal 15
distributed.nanny - INFO - Worker process 87823 was killed by signal 15
distributed.nanny - INFO - Worker process 87791 was killed by signal 15
distributed.nanny - INFO - Worker process 87834 was killed by signal 15
distributed.nanny - INFO - Worker process 87831 was killed by signal 15
distributed.nanny - INFO - Worker process 87845 was killed by signal 15
distributed.nanny - INFO - Worker process 87726 was killed by signal 15
distributed.nanny - INFO - Worker process 87742 was killed by signal 15
distributed.nanny - INFO - Worker process 87864 was killed by signal 15
distributed.nanny - INFO - Worker process 87844 was killed by signal 15
distributed.nanny - INFO - Worker process 87668 was killed by signal 15
distributed.nanny - INFO - Worker process 87664 was killed by signal 15
distributed.nanny - INFO - Worker process 87851 was killed by signal 15
distributed.nanny - INFO - Worker process 87660 was killed by signal 15
distributed.nanny - INFO - Worker process 87722 was killed by signal 15
distributed.nanny - INFO - Worker process 87753 was killed by signal 15
distributed.nanny - INFO - Worker process 87773 was killed by signal 15
distributed.nanny - INFO - Worker process 87821 was killed by signal 15
distributed.nanny - INFO - Worker process 87788 was killed by signal 15
distributed.nanny - INFO - Worker process 87795 was killed by signal 15
distributed.nanny - INFO - Worker process 87732 was killed by signal 15
distributed.nanny - INFO - Worker process 87871 was killed by signal 15
distributed.nanny - INFO - Worker process 87693 was killed by signal 15
distributed.nanny - INFO - Worker process 87798 was killed by signal 15
distributed.nanny - INFO - Worker process 87815 was killed by signal 15
distributed.nanny - INFO - Worker process 87808 was killed by signal 15
distributed.nanny - INFO - Worker process 87825 was killed by signal 15
distributed.nanny - INFO - Worker process 87807 was killed by signal 15
distributed.nanny - INFO - Worker process 87661 was killed by signal 15
distributed.nanny - INFO - Worker process 87666 was killed by signal 15
distributed.nanny - INFO - Worker process 87709 was killed by signal 15
distributed.nanny - INFO - Worker process 87702 was killed by signal 15
distributed.nanny - INFO - Worker process 87813 was killed by signal 15
distributed.nanny - INFO - Worker process 87860 was killed by signal 15
distributed.nanny - INFO - Worker process 87714 was killed by signal 15
distributed.nanny - INFO - Worker process 87842 was killed by signal 15
distributed.nanny - INFO - Worker process 87761 was killed by signal 15
distributed.nanny - INFO - Worker process 87716 was killed by signal 15
distributed.nanny - INFO - Worker process 87711 was killed by signal 15
distributed.nanny - INFO - Worker process 87728 was killed by signal 15
distributed.nanny - INFO - Worker process 87738 was killed by signal 15
distributed.nanny - INFO - Worker process 87867 was killed by signal 15
distributed.nanny - INFO - Worker process 87719 was killed by signal 15
distributed.nanny - INFO - Worker process 87734 was killed by signal 15
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
