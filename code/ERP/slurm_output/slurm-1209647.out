distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:45145'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43761'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:35515'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:40525'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:35149'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34365'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43151'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:35923'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34613'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:38797'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:33211'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41847'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42801'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:39143'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41795'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41227'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:35089'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:44043'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42589'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:33813'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:45733'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:46389'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34027'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:45825'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:45233'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:33081'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:36107'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42469'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:33607'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:44939'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:46317'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:40771'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:38605'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:40803'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42957'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:38141'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:44773'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43461'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:46981'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43017'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:40139'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:36469'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43507'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:36475'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:44425'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:38985'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41779'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:32901'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34101'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42487'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:38271'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:35789'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42909'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:33397'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:33267'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:46309'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:37975'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:44455'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:36193'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43753'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:33367'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41331'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:33257'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41477'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:45883'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34229'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41027'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42571'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:35725'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:39747'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:38711'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:44021'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:35207'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:45301'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:46589'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43341'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:37367'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34559'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:40555'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:45155'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:40917'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:46781'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42173'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:33575'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43169'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:39771'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:33345'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43813'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:35203'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:36163'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:44197'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43263'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43917'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:38453'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:35257'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41039'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:40675'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43215'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:36269'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:37921'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:46713
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:45109
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:46713
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:34703
distributed.worker - INFO -          dashboard at:       198.202.103.41:34359
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:34703
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO -          dashboard at:       198.202.103.41:39223
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:40783
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:45109
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:45177
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:40783
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:       198.202.103.41:45567
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:45177
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:       198.202.103.41:37569
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO -          dashboard at:       198.202.103.41:41077
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-n8vuwx7w
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:41289
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:45311
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:41289
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -          dashboard at:       198.202.103.41:45871
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:45311
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-nnimqe07
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO -          dashboard at:       198.202.103.41:44441
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_9qpyxwf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-kcsyymqu
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-onlj_6ab
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_dd5umuh
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zhw3sloj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:41635
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:41635
distributed.worker - INFO -          dashboard at:       198.202.103.41:32845
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-x20i717b
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:46933
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:46933
distributed.worker - INFO -          dashboard at:       198.202.103.41:37859
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-2ms3tp2v
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:45351
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:45351
distributed.worker - INFO -          dashboard at:       198.202.103.41:43557
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-be2uql0s
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:40757
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:40757
distributed.worker - INFO -          dashboard at:       198.202.103.41:44659
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5hccrdzr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:47059
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:47059
distributed.worker - INFO -          dashboard at:       198.202.103.41:45439
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-b8jt43zp
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:36861
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:36861
distributed.worker - INFO -          dashboard at:       198.202.103.41:36963
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ssoye9b1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:42691
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:42691
distributed.worker - INFO -          dashboard at:       198.202.103.41:34991
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5ygz4om8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:40001
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:40001
distributed.worker - INFO -          dashboard at:       198.202.103.41:44859
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tthvk496
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:32999
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:32999
distributed.worker - INFO -          dashboard at:       198.202.103.41:35735
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vaa3811w
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:46959
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:46959
distributed.worker - INFO -          dashboard at:       198.202.103.41:38653
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pxfzcguk
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:45863
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:45863
distributed.worker - INFO -          dashboard at:       198.202.103.41:41581
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ldc1l0dx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:43905
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:43905
distributed.worker - INFO -          dashboard at:       198.202.103.41:45479
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-djcv87rh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:45461
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:45461
distributed.worker - INFO -          dashboard at:       198.202.103.41:38603
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3ib9yvhe
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:46133
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:46133
distributed.worker - INFO -          dashboard at:       198.202.103.41:36157
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-kb_jkev0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:37495
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:37495
distributed.worker - INFO -          dashboard at:       198.202.103.41:41149
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-sdti4bx2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:39823
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:39823
distributed.worker - INFO -          dashboard at:       198.202.103.41:38347
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-eq9_8863
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:43369
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:43369
distributed.worker - INFO -          dashboard at:       198.202.103.41:42275
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5pga7k4n
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:37761
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:37761
distributed.worker - INFO -          dashboard at:       198.202.103.41:39859
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9gl0d3zo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:46463
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:46463
distributed.worker - INFO -          dashboard at:       198.202.103.41:46751
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-walhv_h4
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:45145'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43761'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:35515'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:40525'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:46933
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:35149'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:37761
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:46463
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34365'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43151'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:35923'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34613'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:41289
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:38797'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:33211'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41847'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42801'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:40757
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:39143'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:41635
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41795'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41227'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:35089'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:45351
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:44043'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42589'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:39823
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:33813'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:45733'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:46389'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34027'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:45825'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:45233'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:33081'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:32999
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:36107'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:45311
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42469'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:33607'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:43905
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:44939'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:40783
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:46317'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:40771'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:38605'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:40001
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:40803'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42957'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:45109
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:46959
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:38141'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:44773'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43461'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:46981'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43017'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:40139'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:45461
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:36469'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:45863
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43507'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:36475'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:46713
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:44425'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:38985'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41779'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:32901'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34101'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42487'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:38271'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:45177
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:42691
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:35789'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42909'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:33397'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:46133
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:33267'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:46309'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:34703
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:37975'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:37495
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:44455'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:36193'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43753'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:33367'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41331'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:33257'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:43369
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41477'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:45883'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34229'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41027'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42571'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:36861
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:35725'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:39747'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:38711'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:44021'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:35207'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:45301'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:46589'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:47059
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43341'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:37367'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34559'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:40555'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:45155'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:40917'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:46781'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42173'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:33575'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43169'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:39771'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:33345'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43813'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:35203'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:36163'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:44197'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:40281
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:40281
distributed.worker - INFO -          dashboard at:       198.202.103.41:44353
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9jkt23lz
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43263'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:40281
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43917'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:38453'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:35257'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41039'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:40675'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43215'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:36269'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:37921'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:37173
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:37173
distributed.worker - INFO -          dashboard at:       198.202.103.41:36185
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7kb08484
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:37173
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:36413
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:36413
distributed.worker - INFO -          dashboard at:       198.202.103.41:44401
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-2kbnma3t
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:36413
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:45801
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:45801
distributed.worker - INFO -          dashboard at:       198.202.103.41:40129
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-v8uacio3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:45801
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO - Stopping worker
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:44451
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:44451
distributed.worker - INFO -          dashboard at:       198.202.103.41:38721
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-kmiyn9hx
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:44451
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:38909
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:38909
distributed.worker - INFO -          dashboard at:       198.202.103.41:36465
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-oc4et3h8
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:38909
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:44023
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:44023
distributed.worker - INFO -          dashboard at:       198.202.103.41:34289
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6qlmdpk0
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:44023
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:40927
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:40927
distributed.worker - INFO -          dashboard at:       198.202.103.41:37663
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:37949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pjza_wrr
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:40927
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.dask_worker - INFO - End worker
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO - Stopping worker
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44252 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44250 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44248 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44246 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44244 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44240 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44238 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44242 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44232 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44234 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44236 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44230 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44228 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44221 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44225 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44218 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44216 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44214 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44211 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44200 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44202 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44193 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44190 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44183 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44188 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44180 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44177 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44196 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44185 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44168 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44172 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44162 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44156 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44155 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44146 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44153 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44148 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44151 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44144 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44128 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44141 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44138 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44122 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44135 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44130 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44116 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44114 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44125 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44111 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44107 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44100 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44106 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44094 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44091 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44089 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44085 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44081 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44077 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44083 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44067 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44062 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44065 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44058 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44055 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44040 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44028 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44019 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44016 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44013 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44010 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44007 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=44004 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=43996 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=43974 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=43978 parent=43880 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=43984 parent=43880 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    assert exitcode is not None
AssertionError
