distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:37531'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:33205'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:43553'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:35195'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:39387'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:34059'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:40265'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:34395'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:40083'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:44177'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:32955'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:39855'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:38577'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:39993'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:41797'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:37227'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:37373'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:41553'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:41649'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:33207'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:43607'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:36865'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:40841'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:34693'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:38261'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:40695'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:42445'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:46831'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:39355'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:40047'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:44327'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:38789'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:42941'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:38557'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:43353'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:43297'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:40861'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:45619'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:35745'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:42659'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:33495'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:41153'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:36411'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:43991'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:38403'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:36115'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:34637'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:41865'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:44973'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:43457'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:34479'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:37563'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:37441'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:45911'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:33387'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:37661'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:46917'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:44603'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:39853'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:34115'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:38227'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:40207'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:42375'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:41197'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:36861'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:43837'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:32957'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:42153'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:38849'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:40407'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:38683'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:36979'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:45439'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:47081'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:42995'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:35581'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:43161'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:42207'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:41869'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:37025'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:41993'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:47033'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:44085'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:37695'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:45657'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:45147'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:40215'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:38899'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:33337'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:38707'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:45179'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:46937'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:35041'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:38607'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:39621'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:40409'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:38545'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:37315'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:32987'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.101.145:39527'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:33785
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:34597
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:33785
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:41389
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:34597
distributed.worker - INFO -          dashboard at:      198.202.101.145:32815
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:34049
distributed.worker - INFO -          dashboard at:      198.202.101.145:39623
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:41389
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:38279
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:34671
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:40303
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:34049
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:44215
distributed.worker - INFO -          dashboard at:      198.202.101.145:36083
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:38279
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:34671
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:37017
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:33227
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:40303
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:35249
distributed.worker - INFO -          dashboard at:      198.202.101.145:44319
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:44215
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:      198.202.101.145:42721
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:36487
distributed.worker - INFO -          dashboard at:      198.202.101.145:42459
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:37017
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:42021
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:33227
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:35249
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:33601
distributed.worker - INFO -          dashboard at:      198.202.101.145:35637
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:46647
distributed.worker - INFO -          dashboard at:      198.202.101.145:33911
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:40021
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:34547
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:36487
distributed.worker - INFO -          dashboard at:      198.202.101.145:42989
distributed.worker - INFO -          dashboard at:      198.202.101.145:38865
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:45395
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:33601
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:42021
distributed.worker - INFO -          dashboard at:      198.202.101.145:44037
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:36663
distributed.worker - INFO -          dashboard at:      198.202.101.145:43317
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-od5esl0a
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.101.145:38117
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -          dashboard at:      198.202.101.145:35271
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:46647
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-k0dsld1_
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:34547
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:40021
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -          dashboard at:      198.202.101.145:45833
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.101.145:38847
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:45395
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.101.145:41171
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-cc9hfn0a
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:36663
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_le20rlx
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -                Memory:                 1000.00 MB
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:43643
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:      198.202.101.145:41111
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:      198.202.101.145:41043
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-b5w9s1vt
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ugx7f7w5
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gah04gdl
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xyp1npuk
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ezezuauc
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:43643
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3gd1smkz
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-bnnmqrh5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ck6i_ma9
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-m950caw6
distributed.worker - INFO -          dashboard at:      198.202.101.145:44463
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:42341
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0pf4ve8q
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tl98gqn6
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ohmp4cq0
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-44p_97ll
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hi5ra70o
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:42341
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-mm3wgs5g
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:      198.202.101.145:40683
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6qdp4_pj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-s7edy2_f
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:42267
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:42267
distributed.worker - INFO -          dashboard at:      198.202.101.145:41303
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gmqxf_6l
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:45563
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:45563
distributed.worker - INFO -          dashboard at:      198.202.101.145:43369
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:32983
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1edyuxjr
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:32983
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:      198.202.101.145:43395
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0aorlxyl
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:34647
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:34647
distributed.worker - INFO -          dashboard at:      198.202.101.145:39367
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1nv5w8qs
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:40759
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:40759
distributed.worker - INFO -          dashboard at:      198.202.101.145:34795
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ly8ly4jk
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:40965
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:40965
distributed.worker - INFO -          dashboard at:      198.202.101.145:42983
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-65pn2ops
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:37429
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:37429
distributed.worker - INFO -          dashboard at:      198.202.101.145:39951
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3nvo2sfz
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:44075
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:44075
distributed.worker - INFO -          dashboard at:      198.202.101.145:37245
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3pxkibcy
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:37713
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:37713
distributed.worker - INFO -          dashboard at:      198.202.101.145:40343
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-brhhhqor
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:40639
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:40639
distributed.worker - INFO -          dashboard at:      198.202.101.145:33087
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-oxhg63tv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:45207
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:45207
distributed.worker - INFO -          dashboard at:      198.202.101.145:33857
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xl4yie7z
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:36093
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:36093
distributed.worker - INFO -          dashboard at:      198.202.101.145:45297
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-nl1kks0t
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:45529
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:45529
distributed.worker - INFO -          dashboard at:      198.202.101.145:46863
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6x1ncpn4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:38289
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:38289
distributed.worker - INFO -          dashboard at:      198.202.101.145:42591
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-02bx_gsd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:43633
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:43633
distributed.worker - INFO -          dashboard at:      198.202.101.145:38901
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hb7w3npy
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.101.145:44907
distributed.worker - INFO -          Listening to: tcp://198.202.101.145:44907
distributed.worker - INFO -          dashboard at:      198.202.101.145:37777
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ajvnxrix
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:37531'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:33205'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:33785
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:43553'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:35195'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:45395
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:39387'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:37017
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:34059'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:34547
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:40265'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:38279
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:36663
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:34395'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:40083'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:42021
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:44177'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:34671
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:43643
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:32955'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:39855'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:34597
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:38577'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:34049
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:39993'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:40021
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:41797'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:33601
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:37227'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:46647
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:37373'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:40303
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:41553'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:41389
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:35249
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:41649'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:33207'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:33227
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:43607'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:44215
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:36865'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:36487
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:40841'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:34647
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:34693'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:32983
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:38261'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:40759
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:40695'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:37713
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:42445'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:45563
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:46831'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:42341
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:37429
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:39355'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:40047'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:40639
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:44327'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:40965
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:38789'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:44075
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:42941'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:45207
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:38557'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:36093
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:43353'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:43633
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:43297'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:38289
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:40861'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:44907
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:45619'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:35745'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:42659'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:33495'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:41153'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:42267
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:36411'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:43991'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:38403'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:36115'
distributed.worker - INFO - Stopping worker at tcp://198.202.101.145:45529
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:34637'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:41865'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:44973'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:43457'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:34479'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:37563'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:37441'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:45911'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:33387'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:37661'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:46917'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:44603'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:39853'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:34115'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:38227'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:40207'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:42375'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:41197'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:36861'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:43837'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:32957'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:42153'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:38849'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:40407'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:38683'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:36979'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:45439'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:47081'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:42995'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:35581'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:43161'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:42207'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:41869'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:37025'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:41993'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:47033'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:44085'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:37695'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:45657'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:45147'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:40215'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:38899'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:33337'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:38707'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:45179'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:46937'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:35041'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:38607'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:39621'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:40409'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:38545'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:37315'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:32987'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.101.145:39527'
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48334 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48331 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48289 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48336 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48264 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48333 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48262 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48260 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48068 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48064 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48059 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48055 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48053 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48044 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48033 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48038 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48028 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48022 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48031 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48025 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48015 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48011 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48007 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=48003 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47999 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47997 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47992 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47990 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47985 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47982 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47978 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47975 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47972 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47968 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47963 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47966 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47957 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47951 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47948 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47943 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47937 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47934 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47930 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47927 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47945 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47918 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47915 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47919 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47911 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47904 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47907 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47898 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47901 parent=47668 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=47896 parent=47668 started daemon>
