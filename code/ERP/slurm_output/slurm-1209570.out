distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:41315'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:40183'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:32869'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:42271'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:37407'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:38093'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:47031'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:43333'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:33869'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:35609'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:45895'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:33001'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:38661'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:42347'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:38623'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:45587'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:38967'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:34327'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:42481'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:39763'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:42513'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:39647'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:35297'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:33879'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:45721'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:46817'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:41969'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:45069'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:41513'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:36853'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:33521'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:43473'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:45605'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:36073'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:46873'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:47025'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:34487'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:37165'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:36091'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:33089'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:41391'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:38069'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:45533'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:35083'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:38507'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:37785'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:33029'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:36377'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:37451'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:41429'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:43453'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:43317'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:38765'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:40669'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:41847'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:42679'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:38201'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:41381'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:38463'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:35617'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:44891'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:44009'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:41149'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:34189'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:39357'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:45177'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:44939'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:32983'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:43967'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:42611'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:36583'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:42331'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:44347'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:45421'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:36659'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:44803'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:46713'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:42023'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:34669'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:46371'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:43175'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:34793'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:38521'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:38039'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:44087'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:39661'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:42037'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:36601'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:43755'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:44221'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:37851'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:41283'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:39835'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:38041'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:40187'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:34175'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:38609'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:44915'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:38357'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.90:44461'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:34613
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:34613
distributed.worker - INFO -          dashboard at:       198.202.102.90:43073
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-bhrzjotm
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:36629
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:36629
distributed.worker - INFO -          dashboard at:       198.202.102.90:46085
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-07dq73ns
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:34397
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:34397
distributed.worker - INFO -          dashboard at:       198.202.102.90:35457
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-x2up0usd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:36167
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:36167
distributed.worker - INFO -          dashboard at:       198.202.102.90:39405
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-mpx52a_6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:34707
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:34707
distributed.worker - INFO -          dashboard at:       198.202.102.90:34733
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_tnhqdn4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:36357
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:36357
distributed.worker - INFO -          dashboard at:       198.202.102.90:37633
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7oacb9bn
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:41077
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:41077
distributed.worker - INFO -          dashboard at:       198.202.102.90:34655
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5e4zm1zi
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:36621
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:36621
distributed.worker - INFO -          dashboard at:       198.202.102.90:44457
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-h1ignir5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:43845
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:43845
distributed.worker - INFO -          dashboard at:       198.202.102.90:37597
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-d3ta89fh
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:36279
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:36279
distributed.worker - INFO -          dashboard at:       198.202.102.90:38237
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-mvxx2to2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:46637
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:46637
distributed.worker - INFO -          dashboard at:       198.202.102.90:33159
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-83b67ep_
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:38429
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:38429
distributed.worker - INFO -          dashboard at:       198.202.102.90:46449
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-43n7ua53
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:40489
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:40489
distributed.worker - INFO -          dashboard at:       198.202.102.90:34409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-2qksu0eo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:36603
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:36603
distributed.worker - INFO -          dashboard at:       198.202.102.90:41387
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-o6mg533u
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:39967
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:39967
distributed.worker - INFO -          dashboard at:       198.202.102.90:37515
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-z0wkjovw
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:40823
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:40823
distributed.worker - INFO -          dashboard at:       198.202.102.90:37783
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-wpziy50f
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:35797
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:35797
distributed.worker - INFO -          dashboard at:       198.202.102.90:42437
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7huhxwo4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:36385
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:36385
distributed.worker - INFO -          dashboard at:       198.202.102.90:33691
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-fz3_mtsj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:41795
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:41795
distributed.worker - INFO -          dashboard at:       198.202.102.90:37661
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-aibbyfi1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:33371
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:33371
distributed.worker - INFO -          dashboard at:       198.202.102.90:36125
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-2_8___2j
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:42447
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:42447
distributed.worker - INFO -          dashboard at:       198.202.102.90:35495
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ijhnkckt
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:45937
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:45937
distributed.worker - INFO -          dashboard at:       198.202.102.90:34007
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5kbfk230
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:34277
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:34277
distributed.worker - INFO -          dashboard at:       198.202.102.90:34091
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1hdoubuu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:33801
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:33801
distributed.worker - INFO -          dashboard at:       198.202.102.90:33043
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-mmtlo64v
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:34329
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:34329
distributed.worker - INFO -          dashboard at:       198.202.102.90:35043
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3yoeqvoj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:41315'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:40183'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:32869'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:42271'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:41077
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:37407'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:38093'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:40823
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:47031'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:43333'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:35797
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:33869'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:45937
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:35609'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:45895'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:33001'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:36603
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:38661'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:42347'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:38623'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:36357
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:45587'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:38967'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:34327'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:42481'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:39763'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:42513'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:39647'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:35297'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:33879'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:45721'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:46817'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:41969'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:45069'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:41513'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:36853'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:46637
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:33521'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:43473'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:45605'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:36073'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:46873'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:47025'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:34487'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:37165'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:34277
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:34707
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:36091'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:33089'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:41391'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:38069'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:45533'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:35083'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:36385
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:38507'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:40489
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:37785'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:33029'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:36377'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:37451'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:43845
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:34397
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:41429'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:43453'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:43317'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:38765'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:40669'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:41847'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:42679'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:38201'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:41381'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:38463'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:35617'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:34613
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:44891'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:44009'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:34329
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:41149'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:34189'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:39357'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:33371
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:45177'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:44939'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:32983'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:43967'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:42611'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:36621
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:36583'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:42331'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:44347'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:45421'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:41795
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:36279
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:36659'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:44803'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:46713'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:42023'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:34669'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:36167
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:46371'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:43175'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:34793'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:38521'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:38039'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:44087'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:39661'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:42037'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:36601'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:43755'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:36629
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:44221'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:37851'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:41283'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:42447
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:39835'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:38041'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:40187'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:34175'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:38609'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:44915'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:38357'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:33801
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:38429
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.90:44461'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:39967
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:45307
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:45307
distributed.worker - INFO -          dashboard at:       198.202.102.90:42253
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gi480tx_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:45307
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO - Stopping worker
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO - Stopping worker
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:41407
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:41407
distributed.worker - INFO -          dashboard at:       198.202.102.90:46815
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9xq8cxhf
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:43531
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:43531
distributed.worker - INFO -          dashboard at:       198.202.102.90:42559
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ku7_3zqg
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:41407
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:43531
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO - Stopping worker
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:38095
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:38095
distributed.worker - INFO -          dashboard at:       198.202.102.90:39235
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-x3cgydau
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:38095
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:46431
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:46431
distributed.worker - INFO -          dashboard at:       198.202.102.90:36531
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xvhy05pl
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:46431
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:35285
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:35285
distributed.worker - INFO -          dashboard at:       198.202.102.90:40661
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3m6627yp
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:35285
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:36881
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:36881
distributed.worker - INFO -          dashboard at:       198.202.102.90:37981
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-cdk_9hdh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:36863
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:36863
distributed.worker - INFO -          dashboard at:       198.202.102.90:40457
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:36881
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-56iyydf7
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:36863
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 83089 was killed by signal 15
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:34075
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.90:42017
distributed.nanny - INFO - Worker process 83069 was killed by signal 15
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:34075
distributed.worker - INFO -          Listening to: tcp://198.202.102.90:42017
distributed.worker - INFO -          dashboard at:       198.202.102.90:38425
distributed.worker - INFO -          dashboard at:       198.202.102.90:40099
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:33409
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-shijpzqa
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-74uummz9
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Worker process 83081 was killed by signal 15
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:42017
distributed.worker - INFO - Stopping worker at tcp://198.202.102.90:34075
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Worker process 83076 was killed by signal 15
distributed.nanny - INFO - Worker process 83085 was killed by signal 15
distributed.nanny - INFO - Worker process 83095 was killed by signal 15
distributed.nanny - INFO - Worker process 83101 was killed by signal 15
distributed.nanny - INFO - Worker process 83093 was killed by signal 15
distributed.nanny - INFO - Worker process 83099 was killed by signal 15
distributed.nanny - INFO - Worker process 83103 was killed by signal 15
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83319 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83313 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83320 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83314 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83311 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83316 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83309 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83299 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83294 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83280 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83248 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83235 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83203 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83201 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83172 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83129 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83071 parent=82943 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=83072 parent=82943 started daemon>
