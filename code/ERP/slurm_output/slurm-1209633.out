distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:45587'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:36539'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:41587'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:35527'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:43175'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:37505'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:42339'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:38669'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:34841'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:33393'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:37363'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:42991'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:46281'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:33667'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:39499'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:45173'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:34127'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:46097'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:39107'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:35331'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:37615'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:43685'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:42123'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:41385'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:40727'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:37895'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:41697'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:44589'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:34955'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:33043'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:39643'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:45129'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:42009'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:37271'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:45291'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:46233'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:40117'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:40967'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:40097'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:43997'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:46857'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:33773'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:45191'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:39867'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:46049'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:43605'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:40803'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:46961'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:45667'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:38795'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:34693'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:46569'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:46277'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:38157'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:38065'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:35185'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:37361'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:44791'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:35443'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:34635'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:40029'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:41673'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:34739'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:43547'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:34265'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:46157'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:33833'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:43799'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:34703'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:36089'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:45115'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:38971'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:37825'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:41993'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:42415'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:38505'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:35431'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:36039'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:37175'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:43335'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:40613'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:37667'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:47085'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:33429'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:38247'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:39429'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:41815'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:45501'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:33817'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:45219'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:43657'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:35835'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:44203'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:40597'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:42815'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:41123'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:45385'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:44067'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:32991'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.40:38859'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:33937
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:33937
distributed.worker - INFO -          dashboard at:       198.202.103.40:33125
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ysryvnub
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:38593
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:38593
distributed.worker - INFO -          dashboard at:       198.202.103.40:37453
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9dpo19cc
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:45457
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:45457
distributed.worker - INFO -          dashboard at:       198.202.103.40:33985
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qb4i2ttw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:44907
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:44907
distributed.worker - INFO -          dashboard at:       198.202.103.40:38735
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-tiz2xs3y
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:40121
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:40121
distributed.worker - INFO -          dashboard at:       198.202.103.40:43341
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-prt55o0d
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:39777
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:39777
distributed.worker - INFO -          dashboard at:       198.202.103.40:33127
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6nz7ct1h
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:41077
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:41077
distributed.worker - INFO -          dashboard at:       198.202.103.40:46279
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-wqgdq8mh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:34919
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:34919
distributed.worker - INFO -          dashboard at:       198.202.103.40:43481
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-jge3b96d
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:46099
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:46099
distributed.worker - INFO -          dashboard at:       198.202.103.40:41333
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-wlpumocp
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:42277
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:42277
distributed.worker - INFO -          dashboard at:       198.202.103.40:32783
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7gp84ang
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:40311
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:40311
distributed.worker - INFO -          dashboard at:       198.202.103.40:39249
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pw484_4t
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:45271
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:45271
distributed.worker - INFO -          dashboard at:       198.202.103.40:43023
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0e_n3301
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:39377
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:39377
distributed.worker - INFO -          dashboard at:       198.202.103.40:41285
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pnwyz7mw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:33625
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:33625
distributed.worker - INFO -          dashboard at:       198.202.103.40:34109
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6gfs9et1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:39615
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:39615
distributed.worker - INFO -          dashboard at:       198.202.103.40:47027
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-du9y336f
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:34267
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:34267
distributed.worker - INFO -          dashboard at:       198.202.103.40:33051
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3rsnwv4b
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:42139
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:42139
distributed.worker - INFO -          dashboard at:       198.202.103.40:34745
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-b078ejof
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:43659
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:43659
distributed.worker - INFO -          dashboard at:       198.202.103.40:38015
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-j8x7ei6e
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:38249
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:38249
distributed.worker - INFO -          dashboard at:       198.202.103.40:46531
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ffby5kbo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:33563
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:33563
distributed.worker - INFO -          dashboard at:       198.202.103.40:45067
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-wvh5uj0q
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:43279
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:43279
distributed.worker - INFO -          dashboard at:       198.202.103.40:33459
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_tk7m94s
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:34327
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:34327
distributed.worker - INFO -          dashboard at:       198.202.103.40:39535
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5idjks2f
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:45479
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:45479
distributed.worker - INFO -          dashboard at:       198.202.103.40:42607
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-optafrv5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:45103
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:45103
distributed.worker - INFO -          dashboard at:       198.202.103.40:44415
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xlvro_ar
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:40317
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:40317
distributed.worker - INFO -          dashboard at:       198.202.103.40:36371
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-t40xnbso
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:41373
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:41373
distributed.worker - INFO -          dashboard at:       198.202.103.40:40659
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7d4j_vy_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:39987
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:39987
distributed.worker - INFO -          dashboard at:       198.202.103.40:45171
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-b7nip59e
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:44195
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:44195
distributed.worker - INFO -          dashboard at:       198.202.103.40:45917
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ue26ga95
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:39357
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:39357
distributed.worker - INFO -          dashboard at:       198.202.103.40:40901
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-bt8e5q3u
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:32995
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:32995
distributed.worker - INFO -          dashboard at:       198.202.103.40:41969
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-rsa935vh
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:37957
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:37957
distributed.worker - INFO -          dashboard at:       198.202.103.40:45047
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-yb_01ras
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:46415
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:46415
distributed.worker - INFO -          dashboard at:       198.202.103.40:34201
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-dwheztbp
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:37851
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:37851
distributed.worker - INFO -          dashboard at:       198.202.103.40:43903
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-o2nhws74
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:41647
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:41647
distributed.worker - INFO -          dashboard at:       198.202.103.40:44743
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-nsu27506
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:36717
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:36717
distributed.worker - INFO -          dashboard at:       198.202.103.40:39933
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xxdbq8jg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.40:35677
distributed.worker - INFO -          Listening to: tcp://198.202.103.40:35677
distributed.worker - INFO -          dashboard at:       198.202.103.40:36017
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-3w3p37yy
distributed.worker - INFO - -------------------------------------------------
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:45587'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:36539'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:33937
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:41587'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:35527'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:38593
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:44907
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:43175'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:37505'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:41077
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:42339'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:45457
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:38669'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:39777
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:40121
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:34841'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:33393'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:42277
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:37363'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:34919
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:42991'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:46099
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:46281'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:40311
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:33667'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:33625
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:39499'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:45271
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:45173'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:43659
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:34127'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:39615
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:46097'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:34267
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:39107'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:42139
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:35331'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:33563
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:37615'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:43279
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:43685'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:39987
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:42123'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:34327
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:41385'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:38249
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:40727'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:41373
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:37895'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:40317
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:41697'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:45479
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:44589'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:44195
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:34955'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:32995
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:33043'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:39357
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:37957
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:39643'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:45129'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:46415
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:42009'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:37851
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:37271'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:41647
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:45291'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:46233'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:40117'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:40967'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:35677
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:40097'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:36717
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:43997'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:46857'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:33773'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:45191'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:39867'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:39377
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:46049'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:43605'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:40803'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:46961'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:45667'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:38795'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:34693'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:46569'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:46277'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:38157'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:38065'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:35185'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:37361'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:44791'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:35443'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:34635'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:40029'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:41673'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:34739'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:43547'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:34265'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:46157'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:33833'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:43799'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:34703'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:36089'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:45115'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:38971'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:37825'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:41993'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:42415'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:38505'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:35431'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:36039'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:37175'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:43335'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:40613'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:37667'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:47085'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:33429'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:38247'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:39429'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:41815'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:45501'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:33817'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:45219'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:43657'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:35835'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:44203'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:40597'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:42815'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:41123'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:45385'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:44067'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.40:45103
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:32991'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.40:38859'
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 117612 was killed by signal 15
distributed.nanny - INFO - Worker process 117601 was killed by signal 15
distributed.nanny - INFO - Worker process 117614 was killed by signal 15
distributed.nanny - INFO - Worker process 117617 was killed by signal 15
distributed.nanny - INFO - Worker process 117598 was killed by signal 15
distributed.nanny - INFO - Worker process 117539 was killed by signal 15
distributed.nanny - INFO - Worker process 117567 was killed by signal 15
distributed.nanny - INFO - Worker process 117488 was killed by signal 15
distributed.nanny - INFO - Worker process 117554 was killed by signal 15
distributed.nanny - INFO - Worker process 117584 was killed by signal 15
distributed.nanny - INFO - Worker process 117500 was killed by signal 15
distributed.nanny - INFO - Worker process 117608 was killed by signal 15
distributed.nanny - INFO - Worker process 117494 was killed by signal 15
distributed.nanny - INFO - Worker process 117484 was killed by signal 15
distributed.nanny - INFO - Worker process 117545 was killed by signal 15
distributed.nanny - INFO - Worker process 117588 was killed by signal 15
distributed.nanny - INFO - Worker process 117570 was killed by signal 15
distributed.nanny - INFO - Worker process 117514 was killed by signal 15
distributed.nanny - INFO - Worker process 117573 was killed by signal 15
distributed.nanny - INFO - Worker process 117490 was killed by signal 15
distributed.nanny - INFO - Worker process 117562 was killed by signal 15
distributed.nanny - INFO - Worker process 117592 was killed by signal 15
distributed.nanny - INFO - Worker process 117505 was killed by signal 15
distributed.nanny - INFO - Worker process 117526 was killed by signal 15
distributed.nanny - INFO - Worker process 117517 was killed by signal 15
distributed.nanny - INFO - Worker process 117577 was killed by signal 15
distributed.nanny - INFO - Worker process 117619 was killed by signal 15
distributed.nanny - INFO - Worker process 117603 was killed by signal 15
distributed.nanny - INFO - Worker process 117581 was killed by signal 15
distributed.nanny - INFO - Worker process 117523 was killed by signal 15
distributed.nanny - INFO - Worker process 117508 was killed by signal 15
distributed.nanny - INFO - Worker process 117497 was killed by signal 15
distributed.nanny - INFO - Worker process 117521 was killed by signal 15
distributed.nanny - INFO - Worker process 117558 was killed by signal 15
distributed.nanny - INFO - Worker process 117512 was killed by signal 15
distributed.nanny - INFO - Worker process 117541 was killed by signal 15
distributed.nanny - INFO - Worker process 117502 was killed by signal 15
distributed.nanny - INFO - Worker process 117550 was killed by signal 15
distributed.nanny - INFO - Worker process 117532 was killed by signal 15
distributed.nanny - INFO - Worker process 117486 was killed by signal 15
distributed.nanny - INFO - Worker process 117633 was killed by signal 15
distributed.nanny - INFO - Worker process 117635 was killed by signal 15
distributed.nanny - INFO - Worker process 117625 was killed by signal 15
distributed.nanny - INFO - Worker process 117627 was killed by signal 15
distributed.nanny - INFO - Worker process 117639 was killed by signal 15
distributed.nanny - INFO - Worker process 117651 was killed by signal 15
distributed.nanny - INFO - Worker process 117645 was killed by signal 15
distributed.nanny - INFO - Worker process 117654 was killed by signal 15
distributed.nanny - INFO - Worker process 117657 was killed by signal 15
distributed.nanny - INFO - Worker process 117699 was killed by signal 15
distributed.nanny - INFO - Worker process 117706 was killed by signal 15
distributed.nanny - INFO - Worker process 117670 was killed by signal 15
distributed.nanny - INFO - Worker process 117677 was killed by signal 15
distributed.nanny - INFO - Worker process 117720 was killed by signal 15
distributed.nanny - INFO - Worker process 117695 was killed by signal 15
distributed.nanny - INFO - Worker process 117717 was killed by signal 15
distributed.nanny - INFO - Worker process 117660 was killed by signal 15
distributed.nanny - INFO - Worker process 117725 was killed by signal 15
distributed.nanny - INFO - Worker process 117833 was killed by signal 15
distributed.nanny - INFO - Worker process 117863 was killed by signal 15
distributed.nanny - INFO - Worker process 117730 was killed by signal 15
distributed.nanny - INFO - Worker process 117674 was killed by signal 15
distributed.nanny - INFO - Worker process 117681 was killed by signal 15
distributed.nanny - INFO - Worker process 117684 was killed by signal 15
distributed.nanny - INFO - Worker process 117702 was killed by signal 15
distributed.nanny - INFO - Worker process 117714 was killed by signal 15
distributed.nanny - INFO - Worker process 117710 was killed by signal 15
distributed.nanny - INFO - Worker process 117692 was killed by signal 15
distributed.nanny - INFO - Worker process 118248 was killed by signal 15
distributed.nanny - INFO - Worker process 117667 was killed by signal 15
distributed.nanny - INFO - Worker process 117629 was killed by signal 15
distributed.nanny - INFO - Worker process 117642 was killed by signal 15
distributed.nanny - INFO - Worker process 117663 was killed by signal 15
distributed.nanny - INFO - Worker process 117866 was killed by signal 15
distributed.nanny - INFO - Worker process 118063 was killed by signal 15
distributed.nanny - INFO - Worker process 118205 was killed by signal 15
distributed.nanny - INFO - Worker process 118151 was killed by signal 15
distributed.nanny - INFO - Worker process 118251 was killed by signal 15
distributed.nanny - INFO - Worker process 118253 was killed by signal 15
distributed.nanny - INFO - Worker process 118262 was killed by signal 15
distributed.nanny - INFO - Worker process 118258 was killed by signal 15
distributed.nanny - INFO - Worker process 118246 was killed by signal 15
distributed.nanny - INFO - Worker process 118256 was killed by signal 15
distributed.nanny - INFO - Worker process 118265 was killed by signal 15
distributed.nanny - INFO - Worker process 118268 was killed by signal 15
distributed.nanny - INFO - Worker process 118271 was killed by signal 15
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - INFO - Worker process 118275 was killed by signal 15
distributed.nanny - INFO - Worker process 118277 was killed by signal 15
distributed.nanny - INFO - Worker process 118289 was killed by signal 15
distributed.nanny - INFO - Worker process 118282 was killed by signal 15
distributed.nanny - INFO - Worker process 118285 was killed by signal 15
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=118377 parent=117411 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=118311 parent=117411 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=118308 parent=117411 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=118305 parent=117411 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=118303 parent=117411 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=118298 parent=117411 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=118293 parent=117411 started daemon>
