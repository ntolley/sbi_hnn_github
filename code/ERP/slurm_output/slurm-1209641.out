distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37593'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:42643'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38729'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:43843'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:43497'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38189'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37581'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37713'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37843'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:35683'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:36409'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37443'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:39383'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34465'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:42125'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:46647'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:35811'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:42537'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:41837'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:43629'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:46415'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:39117'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34417'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:41203'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38403'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37159'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34379'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:46493'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37697'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:42445'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34353'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:33031'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:43911'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:33969'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:41663'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:35083'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:44783'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:36947'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:41083'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38501'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:45071'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:35091'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:45465'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:43885'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:43339'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37013'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:37483'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:35445'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:33941'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:42047'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:46167'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:36831'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:40561'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:40579'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34845'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:40055'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:33209'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:43027'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:42933'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:44699'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34267'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:33575'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:41979'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:45315'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:43055'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:35011'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:45173'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34489'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:41617'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38575'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:33511'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:41295'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:41823'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:42023'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:44389'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:33135'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:45257'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:36419'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:41415'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:39593'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:39379'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:39143'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:46855'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:45157'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:43589'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:44007'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:42625'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:40203'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:36909'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34087'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:43021'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38869'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:40657'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:34125'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:42837'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:41933'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:33447'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:44105'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:45975'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.102.215:38295'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:42623
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:42623
distributed.worker - INFO -          dashboard at:      198.202.102.215:43033
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-bx8up8on
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:45933
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:45933
distributed.worker - INFO -          dashboard at:      198.202.102.215:40189
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-n2_d1mdr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:38217
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:38217
distributed.worker - INFO -          dashboard at:      198.202.102.215:40877
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-o4sw3b0c
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:44129
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:44129
distributed.worker - INFO -          dashboard at:      198.202.102.215:44015
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-c__l1nh4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:44307
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:44307
distributed.worker - INFO -          dashboard at:      198.202.102.215:35167
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-teujbnhp
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:45047
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:45047
distributed.worker - INFO -          dashboard at:      198.202.102.215:45037
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_eov06a5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:37007
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:37007
distributed.worker - INFO -          dashboard at:      198.202.102.215:35761
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4g3eklip
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:32857
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:32857
distributed.worker - INFO -          dashboard at:      198.202.102.215:36305
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0g5hsh0c
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:40719
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:40719
distributed.worker - INFO -          dashboard at:      198.202.102.215:35293
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xuyj8fmj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:46803
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:46803
distributed.worker - INFO -          dashboard at:      198.202.102.215:40793
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7w5644bo
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:44229
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:44229
distributed.worker - INFO -          dashboard at:      198.202.102.215:39541
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7kbiqka0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:35255
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:35255
distributed.worker - INFO -          dashboard at:      198.202.102.215:39053
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7gjk0rgr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:46541
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:46541
distributed.worker - INFO -          dashboard at:      198.202.102.215:36281
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-hn_1oxsx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:36925
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:36925
distributed.worker - INFO -          dashboard at:      198.202.102.215:33597
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-mz9xnidj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:43505
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:43505
distributed.worker - INFO -          dashboard at:      198.202.102.215:37119
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-f52tyegd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:36801
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:36801
distributed.worker - INFO -          dashboard at:      198.202.102.215:38491
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ppkt4smv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:36823
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:36823
distributed.worker - INFO -          dashboard at:      198.202.102.215:34075
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-m0s8avcx
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:44123
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:44123
distributed.worker - INFO -          dashboard at:      198.202.102.215:35095
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7njxsw8c
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:40233
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:40233
distributed.worker - INFO -          dashboard at:      198.202.102.215:39153
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5ygbz2kr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:33891
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:33891
distributed.worker - INFO -          dashboard at:      198.202.102.215:39007
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_jm92pgq
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:34839
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:34839
distributed.worker - INFO -          dashboard at:      198.202.102.215:40939
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-bp0q_heb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:40763
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:40763
distributed.worker - INFO -          dashboard at:      198.202.102.215:34357
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zv6r1fg4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:36111
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:36111
distributed.worker - INFO -          dashboard at:      198.202.102.215:38077
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-y2lrots1
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:39265
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:39265
distributed.worker - INFO -          dashboard at:      198.202.102.215:46041
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-i5tfucuy
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:46399
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:46399
distributed.worker - INFO -          dashboard at:      198.202.102.215:41677
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-rb8a7peu
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:45353
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:45353
distributed.worker - INFO -          dashboard at:      198.202.102.215:42225
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-bl675s2u
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:35515
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:35515
distributed.worker - INFO -          dashboard at:      198.202.102.215:38443
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-46fl0_6x
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:36641
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:36641
distributed.worker - INFO -          dashboard at:      198.202.102.215:36333
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-twe2gub8
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:42007
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:42007
distributed.worker - INFO -          dashboard at:      198.202.102.215:43157
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-r4_ahg35
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:34205
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:34205
distributed.worker - INFO -          dashboard at:      198.202.102.215:41287
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-cuhxg9ta
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:35999
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:35999
distributed.worker - INFO -          dashboard at:      198.202.102.215:33625
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-g_pixkz5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:38931
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:38931
distributed.worker - INFO -          dashboard at:      198.202.102.215:37891
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-av6es7s0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:34259
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:34259
distributed.worker - INFO -          dashboard at:      198.202.102.215:37415
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4x92rewd
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:45411
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:45411
distributed.worker - INFO -          dashboard at:      198.202.102.215:37149
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-r1fthuz8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:44257
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:44257
distributed.worker - INFO -          dashboard at:      198.202.102.215:45463
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-f7k66ujy
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:45509
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:45509
distributed.worker - INFO -          dashboard at:      198.202.102.215:42281
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5sfhyen4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:36515
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:36515
distributed.worker - INFO -          dashboard at:      198.202.102.215:36225
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-z3vyimfl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:37237
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:37237
distributed.worker - INFO -          dashboard at:      198.202.102.215:41729
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-df78xrpv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:40547
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:40547
distributed.worker - INFO -          dashboard at:      198.202.102.215:34589
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9qwn4hcf
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:46475
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:46475
distributed.worker - INFO -          dashboard at:      198.202.102.215:33697
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-javszq2i
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:45721
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:45721
distributed.worker - INFO -          dashboard at:      198.202.102.215:40403
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-yx56lb63
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:44777
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:44777
distributed.worker - INFO -          dashboard at:      198.202.102.215:35073
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5bmym68p
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:37793
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:37793
distributed.worker - INFO -          dashboard at:      198.202.102.215:44829
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4lxvvzjy
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:40887
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:40887
distributed.worker - INFO -          dashboard at:      198.202.102.215:40635
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-mc7z59yh
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:42487
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:42487
distributed.worker - INFO -          dashboard at:      198.202.102.215:39279
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-5sbt31v6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:46455
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:46455
distributed.worker - INFO -          dashboard at:      198.202.102.215:37955
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-079opr25
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:43693
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:43693
distributed.worker - INFO -          dashboard at:      198.202.102.215:33023
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-d2x346ob
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:35871
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:35871
distributed.worker - INFO -          dashboard at:      198.202.102.215:34955
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-duwa52kf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37593'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:42643'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38729'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:36801
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:43843'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:45047
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:43497'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:36925
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38189'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:42623
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37581'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:37007
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37713'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:32857
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37843'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:44307
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:35683'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:45933
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:46803
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:36823
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:36409'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37443'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:39383'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:35255
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34465'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:40233
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:42125'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:33891
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:46647'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:35811'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:46541
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:44123
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:42537'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:44229
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:41837'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:43505
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:43629'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:44129
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:46415'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:40763
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:39117'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34417'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:39265
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:46399
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:41203'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:45721
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38403'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:34839
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37159'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:45353
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34379'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:38931
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:46493'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:36111
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:35515
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:34205
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37697'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:42445'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34353'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:42007
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:33031'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:43911'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:36641
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:44257
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:33969'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:34259
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:41663'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:35999
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:35083'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:45509
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:44783'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:37793
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:36947'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:45411
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:41083'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:36515
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38501'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:37237
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:45071'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:46475
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:35091'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:45465'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:35871
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:43885'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:43339'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37013'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:37483'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:35445'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:40547
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:33941'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:42047'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:46167'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:36831'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:40561'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:40579'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34845'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:40055'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:33209'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:44777
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:43027'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:42933'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:44699'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:43693
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34267'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:40887
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:33575'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:41979'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:45315'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:43055'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:35011'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:45173'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34489'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:38217
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:41617'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38575'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:33511'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:42487
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:41295'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:46455
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:41823'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:42023'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:44389'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:33135'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:45257'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:36419'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:41415'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:39593'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:39379'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:39143'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:46855'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:45157'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:43589'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:44007'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:42625'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:40203'
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:40719
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:36909'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34087'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:43021'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38869'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:40657'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:34125'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:42837'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:41933'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:33447'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:44105'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:45975'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.102.215:38295'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:35579
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:35579
distributed.worker - INFO -          dashboard at:      198.202.102.215:41835
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-d6cohomg
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:35579
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.102.215:33893
distributed.worker - INFO -          Listening to: tcp://198.202.102.215:33893
distributed.worker - INFO -          dashboard at:      198.202.102.215:42347
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-j83kewvx
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.102.215:33893
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61943 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61940 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61937 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61936 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61934 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61932 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61930 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61922 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61924 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61919 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61917 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61914 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61912 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61907 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61901 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61894 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61887 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61889 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61880 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61883 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61876 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61873 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61866 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61869 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61863 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61857 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61859 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61861 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61853 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61845 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61843 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61848 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61834 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61839 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61837 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61827 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61829 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61824 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61822 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61819 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61813 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61816 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61799 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61802 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61804 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61797 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61791 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61784 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61782 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61789 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61778 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61776 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61770 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61763 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61765 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61760 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61757 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61750 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61748 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61744 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61739 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61738 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61733 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61729 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61730 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61723 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61716 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61713 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61709 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61707 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61705 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61700 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61698 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61696 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61693 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61688 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61687 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61683 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61681 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61674 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61677 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61672 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61669 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61663 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61662 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61659 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61655 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61654 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61650 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61647 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61644 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61641 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61637 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61635 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61632 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61628 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61622 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61625 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61621 parent=61546 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=61619 parent=61546 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    assert exitcode is not None
AssertionError
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
    assert exitcode is not None
AssertionError
