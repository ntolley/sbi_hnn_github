distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:39457'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:38939'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:44567'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34213'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41353'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:40517'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34485'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:46671'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42755'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:46873'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42955'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:33831'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34589'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:37861'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:37335'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:45119'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42207'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34443'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41253'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34817'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:40965'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43615'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34389'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:39147'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:37923'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34657'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:44191'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:36519'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:39751'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:45689'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43361'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:40589'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41029'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41359'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:39283'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:45671'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34115'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:44211'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43391'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:33541'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:32775'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:37011'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43855'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:44933'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:37775'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34607'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:37251'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:40407'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:33585'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:35119'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:39555'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43401'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:44005'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43607'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:44279'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:37239'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:38873'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:45481'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:45949'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34279'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:45125'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:45249'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41173'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42451'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:33889'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:40283'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:46439'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:44593'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:38309'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41659'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:39509'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42151'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42063'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:37057'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:35615'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42471'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:36013'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:36795'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34863'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:39581'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:35629'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43703'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:39353'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:37873'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:36991'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41655'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34315'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:45745'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:38995'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:45395'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:34407'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:35345'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41287'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42611'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:32951'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42059'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:41663'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:42501'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:43811'
distributed.nanny - INFO -         Start Nanny at: 'tcp://198.202.103.41:44031'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:46461
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:46461
distributed.worker - INFO -          dashboard at:       198.202.103.41:37757
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-uq5k8sm5
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:43173
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:43173
distributed.worker - INFO -          dashboard at:       198.202.103.41:33887
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gtwrldcg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:35475
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:35475
distributed.worker - INFO -          dashboard at:       198.202.103.41:34225
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-zlawpvxb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:37485
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:37485
distributed.worker - INFO -          dashboard at:       198.202.103.41:34909
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-yd1q5nis
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:42489
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:42489
distributed.worker - INFO -          dashboard at:       198.202.103.41:45761
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-z7s5fvh6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:34299
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:34299
distributed.worker - INFO -          dashboard at:       198.202.103.41:46043
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qnioh717
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:46797
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:46797
distributed.worker - INFO -          dashboard at:       198.202.103.41:41921
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-90y9c1ki
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:44369
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:44369
distributed.worker - INFO -          dashboard at:       198.202.103.41:35543
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-kbheybt9
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:34243
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:34243
distributed.worker - INFO -          dashboard at:       198.202.103.41:33701
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-jk262diw
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:36003
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:36003
distributed.worker - INFO -          dashboard at:       198.202.103.41:46911
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-dfy7kcpx
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:46287
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:46287
distributed.worker - INFO -          dashboard at:       198.202.103.41:34653
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-cyge5o5b
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:39753
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:39753
distributed.worker - INFO -          dashboard at:       198.202.103.41:36939
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-n48xh1ap
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:44013
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:44013
distributed.worker - INFO -          dashboard at:       198.202.103.41:45225
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-o6q2jrqb
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:46401
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:46401
distributed.worker - INFO -          dashboard at:       198.202.103.41:34911
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-b3tsg1jn
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:45893
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:45893
distributed.worker - INFO -          dashboard at:       198.202.103.41:32973
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1n0ws5c3
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:33055
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:33055
distributed.worker - INFO -          dashboard at:       198.202.103.41:43493
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-p3j_sl8b
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:44981
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:44981
distributed.worker - INFO -          dashboard at:       198.202.103.41:44983
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-f5zz6eud
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:36963
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:36963
distributed.worker - INFO -          dashboard at:       198.202.103.41:34149
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-a0smiz5w
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:46403
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:46403
distributed.worker - INFO -          dashboard at:       198.202.103.41:36587
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-sumufijy
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:33213
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:33213
distributed.worker - INFO -          dashboard at:       198.202.103.41:41333
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-_66w6rvp
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:39327
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:39327
distributed.worker - INFO -          dashboard at:       198.202.103.41:41867
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-olmb7qhy
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:39703
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:39703
distributed.worker - INFO -          dashboard at:       198.202.103.41:44675
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-rxpuitcg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:38687
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:38687
distributed.worker - INFO -          dashboard at:       198.202.103.41:40425
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-vcqk5yxr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:42491
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:42491
distributed.worker - INFO -          dashboard at:       198.202.103.41:37477
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-d9m3hu2e
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:37913
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:37913
distributed.worker - INFO -          dashboard at:       198.202.103.41:32779
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ntmc_hyg
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:34431
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:34431
distributed.worker - INFO -          dashboard at:       198.202.103.41:46091
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-pfjsb17s
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:46423
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:46423
distributed.worker - INFO -          dashboard at:       198.202.103.41:37895
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-iutrypu7
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:40603
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:40603
distributed.worker - INFO -          dashboard at:       198.202.103.41:36347
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6jki27wf
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:45219
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:45219
distributed.worker - INFO -          dashboard at:       198.202.103.41:45777
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-qzvsh4l8
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:46923
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:46923
distributed.worker - INFO -          dashboard at:       198.202.103.41:33587
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-dc4uqtt6
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:34691
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:34691
distributed.worker - INFO -          dashboard at:       198.202.103.41:45165
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-4uxvxkwl
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:40917
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:40917
distributed.worker - INFO -          dashboard at:       198.202.103.41:46225
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-40cnf0cj
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:46601
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:46601
distributed.worker - INFO -          dashboard at:       198.202.103.41:45757
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-a69nghui
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:36799
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:36799
distributed.worker - INFO -          dashboard at:       198.202.103.41:41009
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-1s469104
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:45473
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:45473
distributed.worker - INFO -          dashboard at:       198.202.103.41:35507
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xpd9k11u
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:44453
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:44453
distributed.worker - INFO -          dashboard at:       198.202.103.41:35235
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-0rjedsqe
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:34077
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:34077
distributed.worker - INFO -          dashboard at:       198.202.103.41:43837
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-c1avsae4
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:38425
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:38425
distributed.worker - INFO -          dashboard at:       198.202.103.41:36313
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-7x4vuabv
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:34051
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:34051
distributed.worker - INFO -          dashboard at:       198.202.103.41:45353
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-6_2dj0mc
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:33237
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:33237
distributed.worker - INFO -          dashboard at:       198.202.103.41:33875
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gslajkfp
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:35789
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:35789
distributed.worker - INFO -          dashboard at:       198.202.103.41:37227
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ryicz4yr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:39107
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:39107
distributed.worker - INFO -          dashboard at:       198.202.103.41:41883
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-xaoxyhn0
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:45511
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:45511
distributed.worker - INFO -          dashboard at:       198.202.103.41:43233
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-gajh7zdu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:43897
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:43897
distributed.worker - INFO -          dashboard at:       198.202.103.41:41981
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9aadmgvr
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:32771
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:32771
distributed.worker - INFO -          dashboard at:       198.202.103.41:41847
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-ljjoc8k2
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:44667
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:44667
distributed.worker - INFO -          dashboard at:       198.202.103.41:45977
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-9buziov7
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:40667
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:40667
distributed.worker - INFO -          dashboard at:       198.202.103.41:34487
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-kw75up04
distributed.worker - INFO - -------------------------------------------------
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:45985
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:45985
distributed.worker - INFO -          dashboard at:       198.202.103.41:42265
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-n24xxfbv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:39457'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:38939'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:46461
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:44567'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:46403
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34213'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:37485
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41353'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:40517'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:39327
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34485'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:42489
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:46671'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:36003
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42755'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:46797
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:46873'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:44013
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42955'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:44369
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:33831'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:35475
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34589'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:44981
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:37861'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:45893
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:37335'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:34243
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:46401
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:45119'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:46287
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42207'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34443'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:34299
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41253'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:39753
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34817'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:33055
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:40965'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:36963
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43615'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:42491
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34389'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:39703
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:39147'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:40603
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:37923'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:33213
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34657'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:45219
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:44191'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:34431
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:43173
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:36519'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:39751'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:46423
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:45689'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:38687
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43361'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:37913
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:40589'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:34691
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41029'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:40917
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41359'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:46923
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:39283'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:36799
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:45671'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:46601
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:45473
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34115'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:44211'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:38425
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:34077
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43391'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:33541'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:44453
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:32775'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:33237
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:37011'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:34051
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43855'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:44933'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:35789
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:39107
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:37775'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:43897
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34607'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:45511
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:37251'
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:40407'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:33585'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:35119'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:40667
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:39555'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43401'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:44005'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43607'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:44279'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:44667
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:37239'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:38873'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:45481'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:45949'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34279'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:45125'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:45249'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41173'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:32771
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42451'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:33889'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:40283'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:46439'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:44593'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:38309'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41659'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:39509'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42151'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42063'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:37057'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:35615'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42471'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:36013'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:36795'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34863'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:39581'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:35629'
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:45985
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43703'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:39353'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:37873'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:36991'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41655'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34315'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:45745'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:38995'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:45395'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:34407'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:35345'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41287'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42611'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:32951'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42059'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:41663'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:42501'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:43811'
distributed.nanny - INFO - Closing Nanny at 'tcp://198.202.103.41:44031'
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO - Stopping worker
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
/home/ntolley/anaconda3/envs/sbi/lib/python3.8/contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at: tcp://198.202.103.41:46221
distributed.worker - INFO -          Listening to: tcp://198.202.103.41:46221
distributed.worker - INFO -          dashboard at:       198.202.103.41:41259
distributed.worker - INFO - Waiting to connect to: tcp://198.202.103.227:35195
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                 1000.00 MB
distributed.worker - INFO -       Local Directory: /home/ntolley/Jones_Lab/sbi_hnn_github/code/ERP/dask-worker-space/dask-worker-space/worker-2cor4o76
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Stopping worker at tcp://198.202.103.41:46221
distributed.worker - INFO - Closed worker has not yet started: Status.undefined
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 0 seconds, killing
distributed.dask_worker - INFO - End worker
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 271, in _
    await asyncio.wait_for(self.start(), timeout=timeout)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 498, in wait_for
    raise exceptions.TimeoutError()
asyncio.exceptions.TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 469, in <module>
    go()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 465, in go
    main()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 451, in main
    loop.run_sync(run)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/tornado/ioloop.py", line 530, in run_sync
    return future_cell[0].result()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/cli/dask_worker.py", line 445, in run
    await asyncio.gather(*nannies)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/asyncio/tasks.py", line 692, in _wrap_awaitable
    return (yield from awaitable.__await__())
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/core.py", line 275, in _
    raise TimeoutError(
asyncio.exceptions.TimeoutError: Nanny failed to start in 60 seconds
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36899 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36897 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36895 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36893 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36889 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36891 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36885 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36887 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36880 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36883 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36874 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36876 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36865 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36870 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36862 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36860 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36857 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36855 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36867 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36849 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36841 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36837 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36844 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36833 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36827 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36830 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36851 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36819 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36822 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36810 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36825 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36803 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36815 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36800 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36797 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36794 parent=36516 started daemon>
distributed.process - INFO - reaping stray process <SpawnProcess name='Dask Worker process (from Nanny)' pid=36791 parent=36516 started daemon>
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ntolley/anaconda3/envs/sbi/lib/python3.8/site-packages/distributed/process.py", line 235, in _watch_process
    assert exitcode is not None
AssertionError
