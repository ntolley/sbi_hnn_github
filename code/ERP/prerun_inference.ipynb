{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ntolley/anaconda3/lib/python3.7/site-packages/elephant/pandas_bridge.py:22: DeprecationWarning: pandas_bridge module will be removed in Elephant v0.8.x\n",
      "  DeprecationWarning)\n",
      "/home/ntolley/anaconda3/lib/python3.7/site-packages/holoviews/operation/datashader.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Callable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if 'DISPLAY' in os.environ:\n",
    "    del os.environ['DISPLAY']\n",
    "import torch\n",
    "import dill\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import hnn_core\n",
    "from hnn_core import simulate_dipole, Network, read_params, JoblibBackend\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sbi.utils as utils\n",
    "from sbi.inference.base import infer\n",
    "import multiprocessing\n",
    "import datetime\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "from scipy import interpolate\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import spike_train_functions\n",
    "import hnn_simnets_functions\n",
    "import numba\n",
    "import sbi_functions\n",
    "from sbi_functions import run_simulator\n",
    "from joblib import Parallel, delayed\n",
    "import umap\n",
    "import umap.plot\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = 'ERP_Yes_round2_No_t1000000_03032021_173738'\n",
    "data_path = '/home/ntolley/Jones_Lab/sbi_hnn/data/ERP/prerun_simulations/' + save_name + '/'\n",
    "\n",
    "posterior_dict_file = open(data_path + 'posterior_dict_' + save_name + '.pkl', 'rb')\n",
    "posterior_dict = dill.load(posterior_dict_file)\n",
    "posterior_dict_file.close()\n",
    "\n",
    "prior = posterior_dict['posterior']\n",
    "\n",
    "# prior_dict_file = open(data_path + 'prior_dict_' + save_name + '.pkl', 'rb')\n",
    "# prior_dict = dill.load(prior_dict_file)\n",
    "# prior_dict_file.close()\n",
    "\n",
    "# prior_file = open(data_path + 'prior_' + save_name + '.pkl', 'rb')\n",
    "# prior = dill.load(prior_file)   \n",
    "# prior_file.close()\n",
    "\n",
    "params_fname_file = open(data_path + 'params_fname_' + save_name + '.pkl', 'rb')\n",
    "params_fname = dill.load(params_fname_file)\n",
    "params_fname_file.close()\n",
    "\n",
    "dpl_files = sorted(glob.glob(data_path + 'data/dpl*'))\n",
    "theta_files = sorted(glob.glob(data_path + 'data/theta*'))\n",
    "spike_gids_files = sorted(glob.glob(data_path + 'data/spike_gids*'))\n",
    "spike_times_files = sorted(glob.glob(data_path + 'data/spike_times*'))\n",
    "spike_types_files = sorted(glob.glob(data_path + 'data/spike_types*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dpl_preprocessed_file = open(data_path + 'dpl_ERP_preprocessed_100x_downsample.pkl', 'rb')\n",
    "dpl_preprocessed = dill.load(dpl_preprocessed_file)\n",
    "dpl_preprocessed_file.close()\n",
    "dpl, theta, sim_times = dpl_preprocessed['dpl'], dpl_preprocessed['theta'], dpl_preprocessed['sim_times']\n",
    "downsample = dpl_preprocessed['downsample']\n",
    "\n",
    "ERPYes_dpl = np.loadtxt('../../data/ERP/ERPYes_dpl.txt', delimiter=',')[::downsample]\n",
    "ERPNo_dpl = np.loadtxt('../../data/ERP/ERPNo_dpl.txt', delimiter=',')[::downsample]\n",
    "\n",
    "\n",
    "# with open(spike_gids_files[file_idx], 'rb') as f:\n",
    "#     spike_gids = dill.load(f)\n",
    "# unique_gids = np.unique([gid for l in spike_gids for gid in l[0]])\n",
    "# num_sims = len(spike_gids)\n",
    "\n",
    "# with open(spike_times_files[file_idx], 'rb') as f:\n",
    "#     spike_times = dill.load(f)\n",
    "\n",
    "# spike_times_list = []\n",
    "# for gid in unique_gids:\n",
    "#     unit_trains = []\n",
    "#     for sim_idx in range(num_sims):\n",
    "#         gid_mask = np.in1d(spike_gids[sim_idx][0], gid)\n",
    "#         unit_trains.append(np.array(spike_times[sim_idx][0])[gid_mask])\n",
    "#     spike_times_list.append(unit_trains)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ntolley/anaconda3/lib/python3.7/site-packages/nflows/transforms/standard.py:76: DeprecationWarning: Use PointwiseAffineTransform\n",
      "  warnings.warn(\"Use PointwiseAffineTransform\", DeprecationWarning)\n",
      "Neural network successfully converged after 119 epochs.\n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 119\n",
      "        Best validation performance: 82.3223\n",
      "        -------------------------\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "prior.set_default_x(ERPNo_dpl)\n",
    "embedding_net = sbi_functions.model_ann(input_size=dpl.shape[1], output_size=10, layer_size=[200,50])\n",
    "\n",
    "neural_posterior = utils.posterior_nn(model='maf', embedding_net=embedding_net)\n",
    "inference = SNPE(prior=prior)\n",
    "inference = inference.append_simulations(torch.as_tensor(theta).float(), torch.as_tensor(dpl).float(), proposal=prior)\n",
    "density_estimator = inference.train(show_train_summary=True)\n",
    "posterior = inference.build_posterior(density_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Save posterior___\n",
    "posterior_files = {\n",
    "    'posterior': posterior,\n",
    "    'sim_times': sim_times,\n",
    "    'dpl_preprocessed': dpl_preprocessed\n",
    "    }\n",
    "\n",
    "save_file = open(data_path + 'posterior_files_ANN_embedding.pkl', 'wb')\n",
    "dill.dump(posterior_files, save_file)\n",
    "save_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Load posterior___\n",
    "# posterior_file = open(data_path + 'posterior_files_ANN_embedding.pkl', 'rb')\n",
    "# posterior = dill.load(posterior_file)\n",
    "# posterior_file.close()\n",
    "# locals().update(posterior)\n",
    "\n",
    "posterior_file = open('../../data/ERP/prerun_simulations/ERP_Yes_round2_Yes_t1000000_02282021_193946/posterior_files_ANN_embedding.pkl', 'rb')\n",
    "posterior_dict = dill.load(posterior_file)\n",
    "posterior_yes = posterior_dict['posterior']\n",
    "posterior_file.close()\n",
    "\n",
    "posterior_file = open('../../data/ERP/prerun_simulations/ERP_Yes_round2_No_t1000000_03032021_173738/posterior_files_ANN_embedding.pkl', 'rb')\n",
    "posterior_dict = dill.load(posterior_file)\n",
    "posterior_no = posterior_dict['posterior']\n",
    "posterior_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Posterior conditional density p(θ|x) (amortized). Evaluates and samples by default at x=[[-0.5976015329360962, -0.6472906470298767, -0.6329231858253479, -0.5662018656730652, -0.4747260510921478, -0.3943096399307251, -0.35900285840034485, -0.35187214612960815, -0.39160147309303284, -0.4604155421257019, -0.5334329605102539, -0.3224427103996277, 0.02080582082271576, 0.5423483848571777, 0.9065259099006653, 0.8408579230308533, -0.7398633360862732, -3.9326322078704834, -9.06678295135498, -17.116676330566406, -24.708860397338867, -30.873483657836914, -33.55567169189453, -32.4761848449707, -29.418710708618164, -25.787078857421875, -24.482797622680664, -25.654521942138672, -28.094511032104492, -31.020862579345703, -32.70262908935547, -30.429285049438477, -25.961139678955078, -19.27387046813965, -12.327596664428711, -6.530847072601318, -1.5487045049667358, 2.067265510559082, 5.7607245445251465, 8.882918357849121, 11.168972969055176, 12.822458267211914, 13.898996353149414, 14.655091285705566, 15.1610689163208, 15.49838924407959, 15.64673900604248, 15.902533531188965, 16.26132583618164, 16.9844913482666, 18.105268478393555, 19.65256690979004, 21.698488235473633, 24.07568359375, 26.7039737701416, 29.595905303955078, 32.314762115478516, 35.6456413269043, 38.3308219909668, 39.783748626708984, 38.961387634277344, 35.49253463745117, 29.375398635864258, 21.85772132873535, 14.553133010864258, 8.630061149597168, 4.8709187507629395, 3.1377451419830322, 3.2210803031921387]].\n\nThis DirectPosterior-object was obtained with a SNPE-class method using a flow.\nIt allows to .sample() and .log_prob() the posterior and wraps the output of the .net to avoid leakage into regions with 0 prior probability.\n"
     ]
    }
   ],
   "source": [
    "print(posterior_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Drawing 8 posterior samples', max=8.0, style=ProgressStyl…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b3379fe741f4203813718de8ca452d9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Context `x` needed when a default has not been set.If you'd like to have a default, use the `.set_default_x()` method.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-037d099cf77a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mproposal_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposterior_no\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mERPNo_dpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtheta_samples_No\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproposal_no\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mERPNo_dpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# theta_samples_Yes = posterior_yes.sample((num_samples,), x=ERPYes_dpl)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sbi/inference/posteriors/direct_posterior.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape, x, show_progress_bars, sample_with_mcmc, mcmc_method, mcmc_parameters, rejection_sampling_parameters)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mrejection_sampling_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrejection_sampling_parameters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrejection_sampling_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             )\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sbi/utils/sbiutils.py\u001b[0m in \u001b[0;36msample_posterior_within_prior\u001b[0;34m(posterior_nn, prior, x, num_samples, show_progress_bars, warn_acceptance, sample_for_correction_factor, max_sampling_batch_size)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Move to cpu to evaluate under prior.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         )\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mare_within_prior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mare_within_prior\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0maccepted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sbi/inference/posteriors/direct_posterior.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, theta, x, norm_posterior, track_gradients)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_theta_and_x_for_log_prob_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_gradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sbi/inference/posteriors/base_posterior.py\u001b[0m in \u001b[0;36m_prepare_theta_and_x_for_log_prob_\u001b[0;34m(self, theta, x)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# Select and check x to condition on.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_2d_float32_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x_else_default_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_single_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_x_consistent_with_default_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sbi/inference/posteriors/base_posterior.py\u001b[0m in \u001b[0;36m_x_else_default_x\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_x\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m             raise ValueError(\n\u001b[0;32m--> 815\u001b[0;31m                 \u001b[0;34m\"Context `x` needed when a default has not been set.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m                 \u001b[0;34m\"If you'd like to have a default, use the `.set_default_x()` method.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Context `x` needed when a default has not been set.If you'd like to have a default, use the `.set_default_x()` method."
     ]
    }
   ],
   "source": [
    "num_samples = 8\n",
    "proposal_no = posterior_no.set_default_x(ERPNo_dpl)\n",
    "theta_samples_No = proposal_no.sample((num_samples,), x=ERPNo_dpl)\n",
    "# theta_samples_Yes = posterior_yes.sample((num_samples,), x=ERPYes_dpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_No = Parallel(n_jobs=8)(delayed(run_simulator)(theta_samples_No[sim_idx,:], params_fname, prior_dict, sim_idx) for sim_idx in range(num_samples))\n",
    "res_Yes = Parallel(n_jobs=8)(delayed(run_simulator)(theta_samples_Yes[sim_idx,:], params_fname, prior_dict, sim_idx) for sim_idx in range(num_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times = [res_No[sim_idx][1][0] for sim_idx in range(len(res_No))]\n",
    "spike_gids = [res_No[sim_idx][2][0] for sim_idx in range(len(res_No))]\n",
    "spike_types = [res_No[sim_idx][3][0] for sim_idx in range(len(res_No))]\n",
    "spikes = hnn_simnets_functions.tmpSpikes(spike_times, spike_gids, spike_types)\n",
    "spikes_df_No = hnn_simnets_functions.make_spikes_df(spikes, num_trials=len(res_No))\n",
    "\n",
    "spike_times = [res_Yes[sim_idx][1][0] for sim_idx in range(len(res_Yes))]\n",
    "spike_gids = [res_Yes[sim_idx][2][0] for sim_idx in range(len(res_Yes))]\n",
    "spike_types = [res_Yes[sim_idx][3][0] for sim_idx in range(len(res_Yes))]\n",
    "spikes = hnn_simnets_functions.tmpSpikes(spike_times, spike_gids, spike_types)\n",
    "spikes_df_Yes = hnn_simnets_functions.make_spikes_df(spikes, num_trials=len(res_Yes))\n",
    "\n",
    "spikes_df_Yes['detected'] = np.repeat('Yes', len(spikes_df_Yes))\n",
    "spikes_df_No['detected'] = np.repeat('No', len(spikes_df_No))\n",
    "spikes_df_No['gid'] = spikes_df_No['gid'] + np.max(spikes_df_Yes['gid'].values)\n",
    "\n",
    "spikes_df_all = pd.concat([spikes_df_Yes, spikes_df_No])\n",
    "\n",
    "#Add colormap for type\n",
    "type_color = {cell_type:type_idx for type_idx, cell_type in enumerate(np.unique(spikes_df_all['type'].values))}\n",
    "spikes_df_all['color'] = [type_color[cell_type] for cell_type in spikes_df_all['type'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spikes_df = spikes_df_all.groupby('gid').agg(lambda x: tuple(x)).applymap(list).reset_index()\n",
    "# spikes_df['type'] = spikes_df['type'].map(lambda x: x[0])\n",
    "# spikes_df['detected'] = spikes_df['detected'].map(lambda x: x[0])\n",
    "\n",
    "# #Format timestamps columns into list of size num_trials, empty lists inserted on trials where no spikes fired\n",
    "# grouped_ts = []\n",
    "# trial_sim = []\n",
    "# for gid in np.unique(spikes_df['gid'].values):\n",
    "#     gid_ts = []\n",
    "#     gid_trial_idx = 0 \n",
    "#     for trial_idx in range(num_samples):\n",
    "#         if trial_idx in spikes_df['trial'][spikes_df['gid'] == gid].values[0]:\n",
    "#             gid_ts.append(np.array(spikes_df['timestamps'][spikes_df['gid'] == gid].values[0][gid_trial_idx]))\n",
    "#             gid_trial_idx = gid_trial_idx + 1\n",
    "#         else:\n",
    "#             gid_ts.append(np.array([]))\n",
    "#     grouped_ts.append(np.array(gid_ts))\n",
    "#     trial_sim.append(spike_train_functions.vpTrialSimilarityMatrix(gid_ts,0.1).reshape((1,-1)).squeeze())\n",
    "# spikes_df['grouped_ts'] = grouped_ts\n",
    "# spikes_df['trial_sim'] = trial_sim\n",
    "n_neighbors=20\n",
    "min_dist=0.01\n",
    "n_components=2\n",
    "for q in np.linspace(0,1,9):\n",
    "    spikes_df = spike_train_functions.grouped_ts_spikes_df(spikes_df_all, num_samples,q=q)\n",
    "    mapper = umap.UMAP(metric='correlation',n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components).fit(np.stack(spikes_df['trial_sim'].values))\n",
    "    umap.plot.points(mapper,labels = spikes_df['type'].values, theme='fire')\n",
    "    # umap.plot.points(mapper,labels = spikes_df['detected'].values, theme='fire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors=20\n",
    "min_dist=0.01\n",
    "n_components=2\n",
    "mapper = umap.UMAP(metric='correlation',n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components).fit(np.stack(spikes_df['trial_sim'].values))\n",
    "umap.plot.points(mapper,labels = spikes_df['type'].values, theme='fire')\n",
    "umap.plot.points(mapper,labels = spikes_df['detected'].values, theme='fire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap.plot.connectivity(mapper, edge_bundling='hammer')\n",
    "umap.plot.diagnostic(mapper, diagnostic_type='local_dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(sim_times, ERPYes_dpl[::100], 'C0', LineWidth=4)\n",
    "plt.plot(sim_times, ERPNo_dpl[::100], 'C1',LineWidth=4)\n",
    "plt.legend(['Detected', 'Non-Detected'])\n",
    "x_times = np.linspace(0,170,len(res_Yes[0][0]))\n",
    "# for sim_idx in range(len(res_Yes)):\n",
    "#     plt.plot(x_times, res_Yes[sim_idx][0], 'C0', LineStyle='--', alpha=0.5)\n",
    "# for sim_idx in range(len(res_No)):\n",
    "#     plt.plot(x_times, res_No[sim_idx][0], 'C1', LineStyle='--', alpha=0.5)\n",
    "\n",
    "\n",
    "# plt.plot(x_times, res_Yes[0][0], 'C0', LineStyle='--', alpha=0.5)\n",
    "# plt.plot(x_times, res_No[0][0], 'C1', LineStyle='--', alpha=0.5)\n",
    "# plt.legend(['Detected', 'Non-Detected'])\n",
    "\n",
    "plt.plot(x_times, np.vstack(res_Yes[sim_idx][0] for sim_idx in range(len(res_Yes))).transpose(), 'C0', LineStyle='--', alpha=0.5)\n",
    "plt.plot(x_times, np.vstack(res_No[sim_idx][0] for sim_idx in range(len(res_No))).transpose(), 'C1', LineStyle='--', alpha=0.5)\n",
    "\n",
    "plt.title('Inferred ERPs (100000 training sims)')\n",
    "plt.ylabel('Current Dipole')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.xlim([0,175])\n",
    "# plt.ylim([-55,205])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}